<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.101.0"><link rel=canonical type=text/html href=https://www.kubeclipper.io//v1.2/en/docs/><link rel=alternate type=application/rss+xml href=https://www.kubeclipper.io//v1.2/en/docs/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/v1.2/favicons/favicon.ico><link rel=apple-touch-icon href=/v1.2/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/v1.2/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/v1.2/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/v1.2/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/v1.2/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/v1.2/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/v1.2/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/v1.2/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/v1.2/favicons/android-192x192.png sizes=192x192><title>Documentation | Kubeclipper</title><meta name=description content><meta property="og:title" content="Documentation"><meta property="og:description" content="☸️ Manage kubernetes in the most light and convenient way ☸️"><meta property="og:type" content="website"><meta property="og:url" content="https://www.kubeclipper.io//v1.2/en/docs/"><meta property="og:site_name" content="Kubeclipper"><meta itemprop=name content="Documentation"><meta itemprop=description content="☸️ Manage kubernetes in the most light and convenient way ☸️"><meta name=twitter:card content="summary"><meta name=twitter:title content="Documentation"><meta name=twitter:description content="☸️ Manage kubernetes in the most light and convenient way ☸️"><link rel=preload href=/v1.2/scss/main.min.53f5c523adecbae2f6271a40d6b3f66b03402389ec50b0ba967b0d9974dbbe6e.css as=style><link href=/v1.2/scss/main.min.53f5c523adecbae2f6271a40d6b3f66b03402389ec50b0ba967b0d9974dbbe6e.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-00000000-0","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/v1.2/en/><span class="navbar-brand__logo navbar-logo"><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30" viewBox="0 0 200 200" enable-background="new 0 0 200 200"><image id="image0" width="200" height="200" x="0" y="0" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABGdBTUEAALGPC/xhBQAAACBjSFJN AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAABmJLR0QA/wD/AP+gvaeTAAAf 10lEQVR42u2dd3xb1dnHj629l+Ul7504duxMEoeEJCbECSQQIGEWaJukkLJKX6DQlkKgpSGUUUYI o5BNSUoSMiB7D9ux4xlvW7Zs2RrW3sPvH5IlWZZkSdaVLPl8P/7j6t5zj869/umM5zznOVFDQ0MA Agk00aEuACQygcKCIAIUFgQRoLAgiACFBUEEKCwIIkBhQRABCguCCFBYEESAwoIgAhQWBBGgsCCI AIUFQQQoLAgiQGFBEAEKC4IIUFgQRIDCgiACFBYEEaCwIIgAhQVBBCgsCCJAYUEQAQoLgghQWBBE gMKCIAIUFgQRoLAgiACFBUEEKCwIIkBhQRABCguCCFBYEERAh7oAEx2dwSSSa+VqvUytV2oMRByG jEfTSNhEFgmDgj9Lt0BhuYA/qK5uF9VzB5t5Uu6AwmUaDDo6kUXixJAK05mzs2NTYymhLvXEIgrG IHWEL1F/d7rl1I0eX29cXMR5blUBhYAJ9RNMFKCwrAwqtAevdh653i1X692liWcSC9JYyWwSlYil ErFEPNpkMsvVBpXOqNYaRHJtbhK9tCgJFR0V6qcJPVBYQKrS7T7TerKap9QYXCaYlsZcWpyUy6Hl cOies9IZTFyBksMikvCTveqCwgLPbbvUyJW4u3rfgoxNK/NDXcbwY1J33oUy7d+/r3KnqiwO7YnS 3Hl5caEuZlgyeYV15Vb/X3dUuLv6m+V5Dy/KDnUZw5hJKqxmnvSdvVXurr54X+HKOakuLzVJ9Bqj uYCFR0Mblkcm6ev57GiDzmByeemxpTnuVAUAyKBhdjTJ3qsW96qMoX6ICc1krLEOX+c2cgddXlox J/XJ0lwP92KjoxJI6F6l8V/V4lQKdl48fmYsAZoXRjPphFXdLvr4YK3LS9MzWM+vLhgzh6lMXK/S aDSDdpm+XaY/zVOXJBAKWTgaDhXqh5tATLqm8MDlDneXHlqU5Y1tM4UywkbFVxn3tyk+qpWINKYx 7508TC5hafXG+i7XjSAnhjQ9neVNJmkUF8ZPscb0Uc3gtX5NqB9xojC5hFXeKnRnXv/1XVOwGK/a Mio2OpHkogsh15v3tsj/Vi660q8O9YOGnsklrBstQpfn8Tj03NxY7/NJo7qdsZFoTd+3KG4ItaF+ 1hAzuYR15Va/y/PP3J2P9666spDDwHpOsOOW7IULAx1yg3f5RSCTSFjmISBXufBcIOLRi6Yl+JRV PGHs0fQQAN80Spslei/yi0AmkbAGFVqT2cWM+4wstq/OCAkkNA419vhRoTdvq5dsb5CKtJNuwDiJ hCVTua484ugEP3KLJXrVdJqHQINYt6NJFuqnDzaTSFgavetJGBoJ62NOAHjXGtrgyg0/dii8Tx8B TCJhUYmuBcSm+VNjpVJ9az3P8dTHuMpQv4PgMZmE5cYhne5XjRVH9Hk27BeuqkU2Wfryk0hYZje+ skazPz608b4LCwDwaY2kVqwL9ZsIBpE/Cc0Tq45XcK83C9wt5JIq/flPU7HRyVRMj++Wqt3NMmYh M4kc4W8+kh+vvEXw45XOmg6x3uBptC9V+dk85dKxfghLaxz6skGyYRqdQ4rkBRcR2xQeq+x+7T/X K5oFnlUFAOgf9HNqL8lfZUh15k9rpTJ9JBu3IlNYxyu7P/2p3svELb1S/75lPM2ZymD+masK+osJ HpHTFEqUOgYZ19Yn27L/Zgdf7v2Nrb2ymk6xlz4zjrAJKBwK6Pytd67wNZk0zKxYf4wdE58IERZP pEyKIQMANu+90SvyqiZAoaKyOfSizJiiDFYym+zf95KxKN04/PtO9aihsCYuYoXWYknY/nOjZ1UR 8egZWewpyYzUOHJhGouIG+/jUzDR4nEIi68yVgo0EamtsBdWv0R9uqbvgZL09w7U/FLZ7TINHoua msqcPyVuaRGHQvDHHOoOFh7VNT7fmB/blUlkjH9WsYlMeD/PyWrevvNt76+f9+2pZpeqYlBwS6Zz Hrw9M4aKR6IATNx4Rz9Kg/mLeumLRUwqNqIGUmEsrHN1ff/8b3XZ7BSzGfxwoX10gsVFnNfXzUC0 DNhAxF4b1JoaBnXz4iOqQQzXX4lAqtl2pAGHRd03P/1qk7NfaFQUWLco66U105EuhhdOWV5xqS/S 3OTDssYSK7Sv7ygXybUvry1Oj6O+s2/EYvm8ZMb6sil+mA/8AB2gtao8pbFerJvGwgWhzMEh/IRl HgLvfF/dyZenxJGXFSd1DigcJwHn5sW988ScoBUmUMICAJQPaCJJWOHXFO4601LbLgIAzMuLBwA4 2kLzUxl/WlcchDLY4j4EqikEALRI9cIIWvIaZsKq7RTvOt1iOV5cmAgAqGgRAABQ0VEP35H9wcYF 5KCE0uscsKoZE7gaS2Mc+qpRqjWZg1D+IBBOTaHOYPrwYJ3FrYoTQ8pKpAEA6rmDWAzq9YdmlEyN D1pJJEqrQ0Rggxn1q4wNYv3MWEQsI0EmnGqsG22iboG1O5WbRLccaPWm0mJOMFUFAOAPWu37Aexj WaiLFDfAcBLW9+fbbMd5yXTLAQGH+tXSXP8y9JuOfqu+UVEBFlaHTG+MiMYwbIT19YlbDQ5BraZn xFgOnl1VgJBV3R0mk9lWEoNfbs0ekOnNzdJIqLTCQ1giuXbv2TbHM5nxVMvBnBwfYi4EBKFcK5Zb //dGBGJOt0fEgovwEFZFq8DxY14KI4SF6RpQGIxWu4DBFHhhjXNWe4IQHsI6ep3r+HHelFCGyL7c 2G8cNgroA90UAgC4CkMEGB3CQFgDUk1Tj9TxzPT0mFAVxmQeqmwVoofnnvUI1FhGM2gJ/1AiYSCs Wz3OAf5poVvfUtEqEEo1GLQ1cANCIzhB+Jvgw0BYN9tFTmdoxEA66/nEkfJuAAB6eCon4KNCC+Lw j04TBsKqHiUsAjY0EwatfbJrjf0AACwawaYQANAX/kHkw0BYfWJnN3a5JjTjptpOseXAFk8LoRpr ENZYSFPZJhxtKpKpQmNCvNxo9SikEq3CQmJUCABQ6M1aZOrCoDHRhXXclSd750AIYk31iJR1HdYa i0mx2voRqlqGAGiRhvfAcKILq6vfhYauNwt8z2m81HUO2uoQ2+hBpkfK4NStDO9u1kQXllDmIiT/ jRZB8LfvvFDfZzu2xXCTIxZ/oVsBayzEUOuMaq2LH65Mpe8RBTU63g+X2isdYsQnx5IBAL0qI3Jx PTpl4T2xM6GFpdK6bQ7qusRBK8bNDtEXRxsdz6THUQAAtyQIjiH0piFDOM/rTGhh4TBui3erWxq0 Yhy61uV0JoFBBAB0K5DtBpnCebvuCS0skvvYCn7HHvIVsUJb1TpioxQqCUvAoQEAPUpkWyv/YlhO ECa0sFCo6Bg3Qdg7+HKuMBhGh+9OtTi1yAWpTACAymgeRHhGDyHra3CY0MICHmNlV7eJfMnJH/gS 9bFyrtPJzEQqAECmQ7wHFMaymvjCKsp0u6D5TE0v0t9+6Grn6JOW1UFBmHXBhvOWwBNdWCtnpbi7 1MiV7He/Xer4OXi183+XnYWFQUdPTWEAADrliNuZsNET/b/jgYle9HgGMY7htjXcdqThZgcidodf qno+OVxvHtXLWTk3lU7CAQDaEbYzYaIB1s1uPcZw8C+d6MICAKTGUjxc/eFiu9c5+cDO4fXWTiyf mWw54KuRtTUQ3JtawmKBWBgIq9Bj3JjqNiFXEGAr/O6zrS5jdCfFkLMSaAAAkcaoNSLbtyagXXew jlV2jz/CZRAIA2F5XuWsN5q3Hqg2BO5H/P3F9p2nm11empnNthx0IryQhoiOWpBAdDqp1Bre2FXh 3z4awScMhJXMJrM9bil4q1t6panf6/w8UdEq/PJYo9GNL9TcPOsaRqRdD56YQl+Y6CysHaeaLzf0 21bqTnDCQFgAgPzUMRYSbj/W2C0cb4Mokms/Oljr7iqViMlPYVqO+SqkaixsdNSD2ZS8UXtOlzcL /ne5Mz+NmZ1IReirA0t4CGtNSYbnBAMSzXOfX7J5ePqBTK1/+eurHrY/uWtWCgmPBgAYzIjMEkZH galM3IvFzNGN4MGrna99e51CxLy2bgYW7cOm6CEkPIQ1NZnx4KJMz2mUGsPmPTfK/fIB5EvUL391 tdv9IACHQa2cbbWodcp1ukD7DbPwqGenMzZOoyeSRnTM+yXql7+59snhegBA2awU/3YZDgnhISwA wMblU9ljvVajyfznHeUmH6fYOvrlj2853e5xl5S7b0uz7HwBELBgzU8kvFTMzKA6N39DALyzr8o2 BV5anBTY70WUsBEWAODuOaljpjGbh+56/ci52j4v8gMAAK5A8efvyj2nYVJwDy2015etgfNGz6Rh XyhirsuikkZZrVr7ZH/6z7Vb3dbFuoUZrIz48OhdWQgDi4iNBxZknL7Za4u95oG3997giVSPLcn2 kMZgNJ+6ydt+vFGhHqMGWj0vnUG2hp3tURrHH7QDh4rKpmMXJBKnMFysvFVpDduP3zrqMPmNio7a WDYVmZeKFOFUY+EwqIfG6mnZ+PZk02gHPUeOVXa/f6BmTFUBABYWJNiOz/epxtm/YuBRmwoZ6/Pp LlUFAHjn++qjI10qZmSzbREMw4VwqrEAACVT45PZ5B7vLAvbjjZUt4vWL5/CYZFGX119W9q8vLir t/rP1/Nr3U84FmXGJA/3ruR6c63QT/skFRs9Ixafx8ClU9B4V6FLjSZzVbto77m2us4RhSHg0E+W Bjtk4fiJGgo3/9ceoerV/1wdkGi8TE/Co39915QVs1Iw7iPRqrSGuq7BE1W8Jp5EMDLnz35/ew6H bjm+1q/Z2+LDTojoaJBCwWTTsJl0bBbV0/YojT2Sjw7WtffJnM6zafi3fjUnO5EWzDccEMJPWAAA sUL76jfXO/t9+B9TidhlM5PWLcyy9ZbcodYZO/rlTT1S/qCKRsL9ammO7dKndRIPAYbI2Og4AoqJ RzHxKA4JzSagYwgozz5VCo3hSDn3XG3faEkBALAY1LZnF6b4u5diaAlLYQEA6rmDL2y77OtdiSzS 20/M8ftf9WGNPaBSVBSgYqNZeBSHhI4hoNh4NBHtm19er1j1lx3lHoxnaxdmbgi3Prv9/YSpsAAA nx2pH+2INyYkPHp6RsyyGcnzpsShQuGiqdDoLzf2X2sS1HSIPAwdls1I3nRPPiko+yEgQRgLCwBw spr32U/1Cr+CzySxyQVpzNk5sTOz2Ja5GkTpFiou1POrWkUtvVLtWOtc/++BoruGHb/ClPAWFgDg 8q3+N3ZUjCcHFhVfNjtlxeyUWFrgJ0z0BlN5q+B4Je/6LW/nMZfNTH75gSIEXlVQCXthAQC+O9Xs zuHTe9CoqPR4akE6KyOemhpLTo+j4P0K7yZT6wckaq5AKZBq2vpkVW1CD+u5R5OfyvzHU3PDwpXP M5EgLADA7rOtO0+3BNYZnEbCxjEIyWwyjYgj4tAEHIpMwKBGLnBQqPUSpU6hNsg1eqFM0y1QjtnM uYNKwv5qae7K2Z7MImFEhAgLAHCrR/LWnhtCqbf2rQlFVBT414aSgjRmqAsSuCeKGGEBAHpEyjd3 VXaFIizbeJiaynjqzrzizPBwDfWSiBIWAECjM15vEew529rB98F8GioSmMRnVxfOyWGHuiCBJ9KE ZcFgNO+/1L73fJval45zMGFQcGWzUh5alBUB/XSXRKawLLT0yj4+XNfULRl/VoFlSXHSKw8UhcQ8 GzQiWVgWKloEu862NnQNjj+rcYLFoPKS6WWzUpZM50S2qsBkEJYFnkh5vVlwvLLbZbRcpIljEMtm JZfNTmFRImFbXm+YLMKy8d3p5p2nxmtN9Z7cZPq989MX5ifgMOGxuiZQTDphAQCUWkM7X17dLmrm Sdv6ZBJFgNcWE3HognRmXhKjIJ05LZWJRkWCwdNXJqOwnOgRKTv7FV39inquuLVPrlD7tlYiOgow qYREFjErgZbFoeVwaBwWCTMpxeQIFJYzJvPQoELLl2gkCq1Ka9QbzXqjyWgym0xDaFQUBo1Co6Lx WBSTgqORsDQiNoaKn5x1kmegsCCIAH9qEESAwoIgAhQWBBGgsCCIAIUFQQQoLAgiQGFBEAEKC4II 3nqZbdlXrRye63ikNCcvZURQULlK//5/qx1NrUtmJs3IZtt2IvWeXSebW3qkluPFxZzFQYw2ptQY zlbzrt8aUGuNWr0phoaPZxILMmNud4g2Y6OqRXjkapft46N35mQ6RFjoESjpZCzF98ePGLwV1rnq 3n6xynJ8z/x0p6tfHm386XKX7ePcqXF3TOf4V6CWHumRK9asODGkoAlLrtavf+9s67CmHXl0We5L a4ucTvaKVAcv2jdcWb3A/k4+PVj39ZFGAMCHz92+sDAxOOWfaHjfFLqd+dlzuvXAuTbbRwYF96fH Zob6uXyjokngTlUAgN0nmle9dvTUDZ43WXULFLtOWMPEf/hDTaifLGR473Dt2uPx3T1V/z3TavuI xaA+fn5hisdNSiYanx+q//KnBs9peALla9uvKB6bdd/tY8Rvbu+V6YaXFgokajBZ8V5YLmqsLw43 OKoKAPD2b+bmh9XiuJOVPY6qwuNQRVnsggxWDA2vUBsausTnb/ZZtmoymob+vqsSRIH7FnjS1uLi pLVLsvafa6eSsL9ZGa6xYsaP/0tE2nplXxyudzzz/u8XLC7ys2sVKj47WOf48S9PzC4bGUJ358nm D76/aTk2mYY2f1tRmMHK9BgJ7dVHZr7wQBEeO7lcRp3wsymUKXVvfHPd8czv1xQ4qUqh1juG6UmM cY7X2CdSebhqycGShoRHU4g477fvM5nM3QJlW6+MRMDEMQhJbLJLz+DPD9VzHVzg19+TXzYqMPPj d+YKJRrHtRgXa/kehMUdUDhudzM9M2b0q7BBwKHpZFyUm3UVju/HBgoVRSfjfHJ0VmoM3AEFlYiN oeEJwVpt5k9TWN81+NJnl5QOb+rh0uxfr3Cu9pu6pRu3nrUcz8hhf/XyEqcEd796xHZc9dW60V+5 51TrnlP2pjYriXbXnJRHS3M8hOs4W83bd7q1vnNQo7OvKCTi0bflx/9u1bQsjl0Q1a1Cx0awIIO1 cdU0l3n+YdSQ0APdAsXzH120HJPwmIufrAEAyNX6e1496jI9EY/OTqIXZcU8UprjFMj+r99cr2oR urwrlkHMS6E/tix3Vm6su5KcqOz+34UObr9CIFFbLEFRUYDDJq9bkv1oaY5jyhWv/NQvtnYHD76z YlChu1TXV9ks6OIr5Cr92iVZrz7i82jMnxrr8KUOR1UVZMU8u2a6r1/sB208WRuvrqFr8F/PLHCZ 4Ew174+fugjzp9Yaz9zgXWvov/TJ/baTTusN1yzKRHJFltus1VpjTZuopk106gbv/U0lOd5FRxZI 1AKJ+kJN38qStM1PzR2d4Ofy7te2X3U6OTQEeALl+/uqL9byt/1hkcuc//z1tfqOEUvl/Fv064/l 3bH5KMhkfbCpJJj9iXNVvWv+crxrVADShq7Bt771FChLrTU6jv8bOke8vhnIrnMf2023V6h88h+n vz/b6kVudo5e7tozatFRQ9fgu7tveLirvLF/+xHXA2EnVfnNuEaFSbHkDzYtYCK2Vo5MwJCJGACA UKoxOYRX7+LLX/zk0o7XSykEq2n7Rotg/ZaztgQUIvblR4pzkugCqeb4Ne6xa9aw6Tt+aVoyM6kw gwUA4DrEDklLpCYHMYZsPMu6DZNEodM5hD3S6oz/3F2VFk+ZOyXe+9y27qsWyTTP3W9tNCqbBRve s78KDpv8u9X5llfx48WOM8PWuK9+alw2KzkNsd0uxtWVe/3xWUwqgiswH70zx9LvEUo1P1d0f3Go 3lYtc/sVl2r5ZXOtfe0jV0ZE3H97/dzbCxIBANlJ9JJpCY1cSddwjJCbrUKLsBw7YdnBDc9/7J/3 WA4MRvO+M60f/Pem49U9p1qtwnJoP994as7qknQAgFytP1PN2/lLc2efvc7ef759/d35lo750av2 V5HJof3w5nLbMxZlxVyt77c8uNFkPlPV++sVboVFJmBWzk+jkLCJLCLwHe+bQudewrI5KXOnxPl7 t2+w6YTH78y99Mn9Cx0Gnl8ctlfml+rsm+fcXZJuUZWNVSVptuMLNdaUOoM9SlssIzS7amHQ0Y8v y636at36e/JtJy/W9Fk3jHXVflKJ2HtLMg68Vbbnr8tsJ5Vqw6HhOL9nquwzBL9fU+B4LwmPuWt4 DzMAQHOP66gWpbOTf9m66sK/17zy8IxnVk27d6w9/Vzif411+kbPiQrOMoeCBoGHl2ZfuNlrOeYJ lL0iJSeGLJZrxTKtLY1CpXcysNU7dKdUWuuwg4Cz9wt5gd5V2leeXJ6351SzSmOtRNv6ZFNSxtj7 My+FsWxOyonybsvHmjbRQ0uyW3qkjusiL9bym7gj1NMjtHcARFLt6GyfKMt7/v4ADMX8F5bJNPTm txVsOrE4O3gRw2blxlKIGItNyDw0VNEs5MSQnTry52/2nh8W32hsIZapJLvrwY0mgcFoDmGMRgIO nZZAbRjuOHf2yccUFgBgZg7bJqxBhRYA0CceYfr63/l2D7dLVS6WgD+4KCsgTzSuV6nRGd8ca0+2 wIKKjnLsD1lMiEJXvzx3mId3M0x36LcqNQanf0nwkavsNQ2dggNg7P6D0iEOucVkqtb5YBrQ6PwM l+oN/ggrwaE3192vWPu3n7lBjM7ouLsuk4IDw+/UAg6DimcRPfyRCdaQ/FNG7jPt2DUJPp18OV9k f66MBCoAY9soqlvt5lPrKGrCrD72pyncdF/h4cud5bcGLB/beLKn/3Xum1eWxjNHDB+oJPuuCtxR wYPaeu27x1hsCt7Q1C1xnOgoyGABADhs+3SQzmDatKZw5dyxt8xcUJjIouFtnbOdJ5rvmZ8W4yrU ++gJGZcTUP4hlGrO1/R9c7TRFvI5O4nu9CZHwxerdp9quVTLt51ZPifF6Z0DAPZvLrNqNOj4Y8di 0wnbXrrjqXdP17SJLGf6xeqt+6q3PlPieIPjBIVYpm3sGpzq4Phwc/heAECM15H7dw67OgEAWDS8 xZPCyQR1uY7vjbBi6YQNq/L/sdNqSJQqdFv2Vm/53fzRKV/89FJVs71ueGJ53vMPjKt7+/nw2KK5 R3q9oV83MoJ32W0uCt8nVlU2CwAAMpX+3M3eo8O+kBbimMTbpsYDABJZI15FV788VMLyv4/1xpOz 6Q47aZ2p4m3eUaHR29t4JgWfHGd/zh0nmm2VTUWzYNeJJtulgnSvPG32n287fs1upCketpUTcOjk WPsX/XK9+9g1rjcZPrgoqzCTZft4qrLn04N1jju4iuXaLfuqHVUVzyKtXTLe7u2Xhxssfxeqe51U xaYTVsxNcXnLhvfObnjv7P99dtlJVQCAB++wFiktnhJDs1sWd51otlougo7/o8K0eOq/n1+4YesZ Wx/wxwsdYpn2w2dvt6W5f2GmbRblRHn3ifLu1HiKUmNwtA4AANa62WP38OXOimYBAEAg0QgkGr3B /j+gEDEvOlQb996e8e8DtZbjoaGhzTsqqtuEZXNTSXgMHovS6o0anYknVF6q4xekMx+9076v5Lsb 5z/69gmJ3Do++vpI49dHGuOYRDYdL1cbegVKx63LE2JIn/9hUQIzYO2gE6Wzkp+7vzCW4ZtBcssz JaUzrA7c0dFRDy7O+vygtUa82Sp64I3jS2ckLZmRxKYT6CScSK7lCZWdfHmfSDW/IOE27y2RPjIu y3t+OvPt3972yhdXjcM/iws1fW9+V/7GE3MsHx8pzRFItXtO2tsvp84WhYjZ8nSJO99AvljNF7tw wiQTMB89tzDBYd/UR0tztHrTjl+aLBWATm86cK79wDkXg+30+BHerfFM4vaXFr+87UqnQ/jugUH1 wKDz96bEUb744x1xPv7XvWRKKuPpewsWuFq14Q4aGbd2cdaqknTOyA7fw0tz6jrEtu5Xz4Dy2+NN 3x5vGp1DEZJ2ovF65ywuTnp/04LnP7pgO3PoYufSGUkLChIBAGhU9B/XFeEw0f85dsvl7VufWTA7 L9bL77KQnkA9sLnM6SQWg3p69TQ8DvXv/bW+PkImh3Zgc9njfz/Z4H7+lUHFb3l6fqBUVTTciLOo +OLsmGWzUhzbL8+QCZiFxZwlxZySaa7DT5IJmI+fW7hh69nKJoHnrBznHgJOANy+bi9IeGFt0YcO E17v7q56fxMhN9k6nv/tyqkEHGrf6dZBud0il55I3bgq3ydV4bCo0pnJv1s9zV2Cp5ZPIWLRJyt7 GroGda72tIljEjLc+Oh9/OzCzw/VHb3K1Yw0BcXQ8b9dmb/ithQyIWBrub4Z5Zo2Jra5Qi/558b5 nx+qO3aN687phc0gsL1Wsx94G3jtkMOWk7NyYzmjxtsVtt/HsFkvJ4lGI9l79+YhwBMqZEo9Bh3N phNYbmavK5oEo22VJDyaQsROSWV4uVBRozN28OWdfHn/oBqHiWZQ8FQSNp5JHNPbSaHRN3ZJVFqD Tm9iUvFxDGISm+QyYF97n8xx84uCdJbFRsAdUDha9SzLv3pFSkdHP5dejaP57ZYzNkc/X4Vlew88 oUoo0/SKlIMyLYmAYVBwDAo+J4nuWEfuPtlss7U+UpoTkOWQMKJfMAiVsEIIXGIPQQQoLAgiwKYw GMjV+qZuqe3jHO+GLOUOwzpODIkTuHmkIACFBUEE2BRCEAEKC4IIUFgQRIDCgiACFBYEEaCwIIgA hQVBBCgsCCJAYUEQAQoLgghQWBBEgMKCIAIUFgQRoLAgiACFBUEEKCwIIkBhQRABCguCCFBYEESA woIgAhQWBBGgsCCIAIUFQQQoLAgiQGFBEAEKC4IIUFgQRIDCgiACFBYEEaCwIIgAhQVBBCgsCCL8 P3O4Ve1Jph3vAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIyLTA4LTE3VDA5OjM3OjA1KzAwOjAw/6HZ 9gAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMi0wOC0xN1QwOTozNzowNSswMDowMI78YUoAAAAASUVO RK5CYII="/></svg></span><span class=navbar-brand__name>Kubeclipper</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/v1.2/en/docs/><span class=active>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/v1.2/en/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/v1.2/en/community/><span>Community</span></a></li><li class="nav-item dropdown mr-4 d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>1.2</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/>vlatest (latest)</a>
<a class=dropdown-item href=/v1.3>v1.3</a>
<a class=dropdown-item href=/v1.2>v1.2</a>
<a class=dropdown-item href=/v1.1>v1.1</a></div></li><li class="nav-item dropdown mr-4 d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/v1.2/docs/>简体中文</a></div></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/v1.2/offline-search-index.c9f02b03ed72bfd1149025cc3defddce.json data-offline-search-base-href=/ data-offline-search-max-results=25></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/v1.2/en/docs/>Return to the regular view of this page</a>.</p></div><h1 class=title>Documentation</h1><ul><li>1: <a href=#pg-6e17e09fffc1050f46600282def85180>Overview</a></li><ul></ul><li>2: <a href=#pg-93aadc1aba179e6928539400a09b9e4e>Getting Started</a></li><ul><li>2.1: <a href=#pg-3790836eb569fb079bcb4f37fd87bd84>Deploying AIO</a></li><li>2.2: <a href=#pg-45c14578741098628f1d483b1891e15d>Create k8s clusters offline using the kubeclipper platform</a></li></ul><li>3: <a href=#pg-a07813ac798dd2637717ce2e67c448bd>Deployment docs</a></li><ul><li>3.1: <a href=#pg-c350c8cb338ccbf5a884d981eba290a6>Deploy HA</a></li></ul><li>4: <a href=#pg-8dbd4e302cd86a4d0f71f71ce3b300de>Tutorials</a></li><ul><li>4.1: <a href=#pg-502f2b1bbafe2aca0d506e0d2b495a3d>Cluster management</a></li><li>4.2: <a href=#pg-f8b869abb7ea8ad8dbef714007033263>Node & Zone Management</a></li><li>4.3: <a href=#pg-9db4787abe05db7c233072bf3fa9f94e>Access control</a></li></ul><li>5: <a href=#pg-8efbf7499fe9c7bde8d2c1bb7ff6ee3c>Contribution Guidelines</a></li><ul></ul></ul><div class=content></div></div><div class=td-content><h1 id=pg-6e17e09fffc1050f46600282def85180>1 - Overview</h1><div class=lead>Manage kubernetes in the most light and convenient way ☸️</div><h2 id=what-is-kubeclipper>What is KubeClipper?</h2><p>KubeClipper aims to provide easy-to-use, easy-to-operate, lightweight, product-grade kubernetes multi-cluster full lifecycle management service, freeing operation and maintenance engineers from complicated configuration and obscure command lines to achieve one-stop management of multi-K8 s clusters across regions and infrastructure.</p><h2 id=why-do-i-want-kubeclipper>Why do I want KubeClipper?</h2><p>In the cloud-native era, Kubernetes has undoubtedly become the de facto standard for container orchestration. Although there are many tools to assist in the installation and management of K8S clusters, it is still very complicated to build and operate a production-level K8S cluster. In the process of a large number of services and practices, 99cloud has precipitated an extremely lightweight and easy-to-use graphical interface Kubernetes multi-cluster management tool - KubeClipper.</p><p>Under the premise of being fully compatible with native Kubernetes, KubeClipper is repackaged based on the kubeadm tool widely used by the community, providing rapid deployment of K8S clusters and continuous full life cycle management (installation, uninstallation, upgrade, scaling) in the enterprise&rsquo;s own infrastructure. It supports multiple deployment methods such as online, proxy, and offline, and also provides rich and scalable management services for CRI, CNI, CSI, and various CRD components.</p><p>Compared with the existing K8S lifecycle management tools such as Sealos, KubeKey, Kubeasz, KubeOperator, and K0S, KubeClipper is more open and native, lightweight, convenient, stable and easy to use.</p><ul><li><a href=/docs/getting-started/>Getting Started</a>: Get started with $project</li><li><a href=/docs/examples/>Examples</a>: Check out some example code!</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-93aadc1aba179e6928539400a09b9e4e>2 - Getting Started</h1><div class=lead>Quickly build the experience platform function</div></div><div class=td-content><h1 id=pg-3790836eb569fb079bcb4f37fd87bd84>2.1 - Deploying AIO</h1><div class=lead>Deploying the AIO environment</div><p>For users who are new to KubeClipper and want to get started quickly, it is recommended to use the All-in-One installation mode, which can help you quickly deploy KubeClipper with zero configuration.</p><h2 id=deploy-kubeclipper>Deploy KubeClipper</h2><h3 id=download-kcctl>Download kcctl</h3><p>KubeClipper provides a command line tool 🔧 kcctl to simplify operation and maintenance. You can download the latest version of kcctl directly with the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># The latest distribution is installed by default</span>
</span></span><span style=display:flex><span>curl -sfL https://oss.kubeclipper.io/kcctl.sh <span style=color:#000;font-weight:700>|</span> bash -
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Install the specified version</span>
</span></span><span style=display:flex><span>curl -sfL https://oss.kubeclipper.io/kcctl.sh <span style=color:#000;font-weight:700>|</span> <span style=color:#000>KC_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span>v1.2.1 bash -
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>#If you are in China, you can use cn environment variables during installation, in this case we will use registry.aliyuncs.com/google_containers instead of k8s.gcr.io</span>
</span></span><span style=display:flex><span>Curl -sfL https://oss.kubeclipper.io/kcctl.sh <span style=color:#000;font-weight:700>|</span> <span style=color:#000>KC_REGION</span><span style=color:#ce5c00;font-weight:700>=</span>cn bash -
</span></span></code></pre></div><blockquote><p>You can also download the specified version from the [GitHub Release Page] ( <a href=https://github.com/kubeclipper/kubeclipper/releases>https://github.com/kubeclipper/kubeclipper/releases</a> ) .</p></blockquote><p>Check if the installation was successful with the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>Kcctl version
</span></span></code></pre></div><h3 id=start-installation>Start installation</h3><p>In this quickstart tutorial, you only need to execute one command to install KubeClipper with a template like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>Kcctl deploy <span style=color:#ce5c00;font-weight:700>[</span>--user root<span style=color:#ce5c00;font-weight:700>]</span> <span style=color:#ce5c00;font-weight:700>(</span>--passwd SSH_PASSWD <span style=color:#000;font-weight:700>|</span> --pk-file SSH_PRIVATE_KEY<span style=color:#ce5c00;font-weight:700>)</span>
</span></span></code></pre></div><p>If you use the ssh passwd method, the command is as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>Kcctl deploy --user root --passwd <span style=color:#000>$SSH_PASSWD</span>
</span></span></code></pre></div><p>The private key is as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>Kcctl deploy --user root --pk-file <span style=color:#000>$SSH_PRIVATE_KEY</span>
</span></span></code></pre></div><blockquote><p>You only need to provide the ssh user and ssh passwd or ssh private key to deploy KubeClipper natively.</p></blockquote><p>After executing this command, Kcctl will check your installation environment, and if the conditions are met, it will enter the installation process. After printing the following KubeClipper banner, the installation is complete.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Console data-lang=Console><span style=display:flex><span><span style=color:#000;font-style:italic> _ __ _ _____ _ _ 
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>| | / / | | / __ \ ( _)
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>| |/ / _ _ | |__ ___| / \/ | _ _ _ __ _ __ ___ _ __
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>| \| | | | &#39; _\/_ \ | | | | &#39; _\ | &#39;_\/_ \ &#39;__|
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>| |\ \ | _ | | | _ ) | __/ \__/\ | | | _ ) | | _ ) | __/ |
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>\ _ |\ _ /\__, _ | _ .__/ \___|\____/ _ | _ | .__/| .__/ \___| _ |
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>| | | |
</span></span></span><span style=display:flex><span><span style=color:#000;font-style:italic>| _ | | _ |
</span></span></span></code></pre></div><blockquote><p>You can also deploy the master version of KubeClipper to experience the latest features</p><ol><li>Install kcctl</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -sfL https://oss.kubeclipper.io/kcctl.sh <span style=color:#000;font-weight:700>|</span> <span style=color:#000>KC_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span>master bash -
</span></span></code></pre></div><ol start=2><li>Set environment variables on the installation server</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>KC_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span>master
</span></span></code></pre></div><ol start=3><li>Deploy KubeClipper AIO environment</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kcctl deploy
</span></span></code></pre></div></blockquote><h3 id=login-to-console>Login to console</h3><p>After the installation is complete, open a browser and visit http://$IP to enter the KubeClipper console.</p><p><img src=/images/docs-quickstart/console-login.png alt=console></p><p>You can use the default account password " admin/Thinkbig1 " to log in.</p><blockquote><p>You may need to configure port forwarding rules and open ports in security groups for external users to access the console.</p></blockquote><h2 id=create-k8s-cluster>Create k8s cluster</h2><p>After successful deployment you can create a k8s cluster using the ** kcctl tool ** or via the ** console ** . Use the kcctl tool to create it in this quickstart tutorial.</p><p>First, use the default account password to log in and obtain the token, which is convenient for subsequent interaction between kcctl and kc-server.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>Kcctl login -H http://localhost -u admin -p Thinkbig1
</span></span></code></pre></div><p>Then create a k8s cluster with the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span><span style=color:#000>NODE</span> <span style=color:#ce5c00;font-weight:700>=</span> $ <span style=color:#ce5c00;font-weight:700>(</span>kcctl get node -o yaml <span style=color:#000;font-weight:700>|</span> grep ipv4DefaultIP: <span style=color:#000;font-weight:700>|</span> sed<span style=color:#4e9a06>&#39;s/ipv4DefaultIP : //&#39;</span><span style=color:#ce5c00;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Kcctl create cluster --master <span style=color:#000>$NODE</span> --name demo --untaint-master
</span></span></code></pre></div><p>It takes about 3 minutes to complete the cluster creation, or you can use the following command to view the cluster status</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>Kcctl get cluster -o yaml <span style=color:#000;font-weight:700>|</span> grep status -A5
</span></span></code></pre></div><blockquote><p>You can also go to the console to view the real-time log.</p></blockquote><p>Entering the Running state means that the cluster installation is complete, you can use the kubectl get cs command to view the cluster health.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-45c14578741098628f1d483b1891e15d>2.2 - Create k8s clusters offline using the kubeclipper platform</h1><div class=lead>How to create a k8s cluster offline using the KC platform</div><h2 id=1-go-to-the-creation-screen>1. Go to the creation screen</h2><p>Log in to the <code>Kubeclipper</code> platform and click the button as shown in the figure to enter the cluster creation interface</p><p><img src=/images/docs-quickstart/cluster-begin.png alt></p><h2 id=2-configure-cluster-nodes>2. Configure cluster nodes</h2><p>Follow the text prompts to complete the steps of entering the cluster name and selecting nodes</p><p>Note: The number of master nodes cannot be an even number.</p><p><img src=/images/docs-quickstart/cluster-node-config.png alt></p><h2 id=3-configure-cluster>3. Configure cluster</h2><p>This step is used to configure the cluster network and components such as the database and container runtime</p><p>Select offline installation and fill in the address of the image repository you have built first</p><p><img src=/images/docs-quickstart/cluster-config.png alt></p><h2 id=4-configure-cluster-storage>4. Configure cluster storage</h2><p>Select nfs storage and follow the text prompts to fill in the appropriate fields</p><p><img src=/images/docs-quickstart/cluster-storage-config.png alt></p><h2 id=5-installation-completed>5. Installation completed</h2><p>Complete all configurations to confirm installation</p><p><img src=/images/docs-quickstart/cluster-finish.png alt></p><p>Installation is successful and the cluster is up and running</p><p><img src=/images/docs-quickstart/cluster-successful.png alt></p></div><div class=td-content style=page-break-before:always><h1 id=pg-a07813ac798dd2637717ce2e67c448bd>3 - Deployment docs</h1><div class=lead>Deploying the sample</div></div><div class=td-content><h1 id=pg-c350c8cb338ccbf5a884d981eba290a6>3.1 - Deploy HA</h1><div class=lead>deploy a high available kubeclipper by some simple cmd.</div><p>The purpose of this document is to deploy an HA KubeClipper with a simple operation.</p><blockquote><p>If you just want a simple experience, please refer to <a href=https://github.com/kubeclipper/kubeclipper#quick-start>QuickStart</a> to deploy AIO environment.</p></blockquote><h2 id=preparations>Preparations</h2><p>You only need to prepare a host with reference to the following requirements for machine hardware and operating system: Preparations</p><p>HA Deploy Recommend:</p><ul><li>Kubeclipper uses etcd as backend storage. In order to ensure high availability, it is recommended to use 3 nodes and above for deployment.</li><li>At the same time, the production environment recommends that the server node and the agent node be separated to avoid acting as both the server node and the agent node at the same time.
Node planning:</li></ul><h2 id=deploying-kubeclipper>Deploying KubeClipper</h2><h3 id=download-kcctl>Download kcctl</h3><p>KubeClipper provides command line tools 🔧 kcctl to simplify operation and maintenance work. You can directly download the latest version of kcctl with the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -sfL https://oss.kubeclipper.io/kcctl.sh <span style=color:#000;font-weight:700>|</span> sh -
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># In China, you can add cn env, we use registry.aliyuncs.com/google_containers instead of k8s.gcr.io</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn sh -</span>
</span></span></code></pre></div><blockquote><p>You can also download the specified version on the <a href=https://github.com/kubeclipper/kubeclipper/releases>GitHub Release Page</a>.</p></blockquote><p>Check if the installation is successful with the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kcctl version
</span></span></code></pre></div><h3 id=get-started-with-installation>Get Started with Installation</h3><p>All you need to do is execute a command to install KubeClipper, whose template looks like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kcctl deploy  <span style=color:#ce5c00;font-weight:700>[</span>--user root<span style=color:#ce5c00;font-weight:700>]</span> <span style=color:#ce5c00;font-weight:700>(</span>--passwd SSH_PASSWD <span style=color:#000;font-weight:700>|</span> --pk-file SSH_PRIVATE_KEY<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#ce5c00;font-weight:700>(</span>--server SERVER_NODES<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#ce5c00;font-weight:700>(</span>--agent AGENT_NODES<span style=color:#ce5c00;font-weight:700>)</span>
</span></span></code></pre></div><p>If you use the ssh passwd method, the command is as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kcctl deploy --user root --passwd <span style=color:#000>$SSH_PASSWD</span> --server SERVER_NODES --agent AGENT_NODES
</span></span></code></pre></div><p>The private key method is as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kcctl deploy --user root --pk-file <span style=color:#000>$SSH_PRIVATE_KEY</span> --server SERVER_NODES --agent AGENT_NODES
</span></span></code></pre></div><blockquote><p>You only need to provide ssh user and ssh passwd or ssh private key to deploy KubeClipper on the corresponding node.</p></blockquote><p>This tutorial uses the private key to deploy, the specific commands are as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kcctl deploy --server 192.168.10.110,192.168.10.111,192.168.10.112 --agent 192.168.10.113,192.168.10.114,192.168.10.115 --pk-file ~/.ssh/id_rsa --pkg https://oss.kubeclipper.io/release/v1.1.0/kc-amd64.tar.gz
</span></span></code></pre></div><blockquote><p>This command shows kubeclipper platform will has 3 server node and 3 agent node.</p></blockquote><blockquote><p>You can visit the <a href=https://github.com/kubeclipper/kubeclipper/releases>GitHub Release Page</a> to view the current KubeClipper release version and modify the version number in the pkg parameter.</p><p>For example, after the v1.2.0 release you can specify &ndash;pkg as the <a href=https://oss.kubeclipper.io/release/v1.2.0/kc-amd64.tar.gz>https://oss.kubeclipper.io/release/v1.2.0/kc-amd64.tar.gz</a> to install the v1.2.0 version.</p></blockquote><p>After you runn this command, kcctl will check your installation environment and enter the installation process, if the conditions are met.
After printing the KubeClipper banner, the installation is complete.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span> / /     <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>        /  __ <span style=color:#4e9a06>\ </span><span style=color:#ce5c00;font-weight:700>(</span>_<span style=color:#ce5c00;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>/ / _   _<span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>__   ___<span style=color:#000;font-weight:700>|</span> /  <span style=color:#4e9a06>\/</span> <span style=color:#000;font-weight:700>|</span>_ _ __  _ __   ___ _ __
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>|</span>    <span style=color:#4e9a06>\|</span> <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span> <span style=color:#4e9a06>&#39;_ \ / _ \ |   | | | &#39;</span>_ <span style=color:#4e9a06>\|</span> <span style=color:#4e9a06>&#39;_ \ / _ \ &#39;</span>__<span style=color:#000;font-weight:700>|</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span><span style=color:#4e9a06>\ </span> <span style=color:#4e9a06>\ </span><span style=color:#000;font-weight:700>|</span>_<span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>_<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#000;font-weight:700>|</span>  __/ <span style=color:#4e9a06>\_</span>_/<span style=color:#4e9a06>\ </span><span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>_<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>_<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#000;font-weight:700>|</span>  __/ <span style=color:#000;font-weight:700>|</span>
</span></span><span style=display:flex><span><span style=color:#4e9a06>\_</span><span style=color:#000;font-weight:700>|</span> <span style=color:#4e9a06>\_</span>/<span style=color:#4e9a06>\_</span>_,_<span style=color:#000;font-weight:700>|</span>_.__/ <span style=color:#4e9a06>\_</span>__<span style=color:#000;font-weight:700>|</span><span style=color:#4e9a06>\_</span>___/_<span style=color:#000;font-weight:700>|</span>_<span style=color:#000;font-weight:700>|</span> .__/<span style=color:#000;font-weight:700>|</span> .__/ <span style=color:#4e9a06>\_</span>__<span style=color:#000;font-weight:700>|</span>_<span style=color:#000;font-weight:700>|</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>   <span style=color:#000;font-weight:700>|</span> <span style=color:#000;font-weight:700>|</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>|</span>_<span style=color:#000;font-weight:700>|</span>   <span style=color:#000;font-weight:700>|</span>_<span style=color:#000;font-weight:700>|</span>
</span></span></code></pre></div><h3 id=login-console>Login console</h3><p>When deployed successfully, you can open a browser and visit http://$IP to enter the KubeClipper console.</p><p><img src=/images/docs-quickstart/console-login.png alt=console></p><p>You can log in with the default account password <code>admin/Thinkbig1</code>.</p><blockquote><p>You may need to configure port forwarding rules and open ports in security groups for external users to access the console.</p></blockquote></div><div class=td-content style=page-break-before:always><h1 id=pg-8dbd4e302cd86a4d0f71f71ce3b300de>4 - Tutorials</h1><div class=lead>User manual</div></div><div class=td-content><h1 id=pg-502f2b1bbafe2aca0d506e0d2b495a3d>4.1 - Cluster management</h1><div class=lead>A short lead description about this content page. It can be <strong>bold</strong> or <em>italic</em> and can be split over multiple paragraphs.</div><h2 id=create-a-kubernetes-cluster><strong>Create a kubernetes cluster</strong></h2><p>You can create a kubernetes cluster through the wizard-style page, and install the required plugins such as CNI and CSI. You can also save the cluster template in advance, and create a cluster quickly after selecting the template.</p><h2 id=prepare-to-create-a-cluster><strong>Prepare to create a cluster</strong></h2><ol><li><p>You need to have enough available nodes. To add nodes, refer to "Add Nodes".</p></li><li><p>Prepare the image or binary files of K8S, CRI, calico, CSI and other plug-ins that need to be installed. You can choose online/offline according to the network environment of the platform, and then choose the recommended K8S version on page. You can also upload the image required for deployment to your own image repository in advance, and specify the image repository during deployment. For more installation configuration, refer to "Cluster Configuration Guide".</p></li></ol><h2 id=create-a-single-node-experimental-cluster><strong>Create a single-node experimental cluster</strong></h2><ol><li><p>Click "Cluster Management" > "Cluster" to enter the cluster list page, and click the "Create Cluster" button in the upper left corner.</p></li><li><p>Enter the "Node Configuration" page of the Create Cluster Wizard page. Fill in the "Cluster Name", such as "test", without selecting "Cluster Template". Select an available node, add it as a control node, and remove the taint from the master node in the taint management list. Click the "Next" button.</p></li></ol><p><img src=/images/docs-tutorials/select-node.png alt></p><ol start=3><li><p>Enter the "Cluster Configuration" page of the Create Cluster Wizard page. Select "Offline Installation", no need to specify "Mirror Repository", retain the default values for other configurations, click the "Quick Create" button, jump to the configuration confirmation page, and click the "OK" button.</p></li><li><p>The experimental cluster of a single node is created. You can view the cluster details on the cluster details page, or click the "ViewLog" button to view the real-time log during the cluster creation process.</p></li></ol><h2 id=create-a-cluster-using-a-mirror-repository><strong>Create a cluster using a mirror repository</strong></h2><p>If you create a cluster that contains large images, it is recommended that you upload all images to a specific image repository, the creating process will be faster and smoother.</p><ol><li><p>Add a mirror repository. Click "Cluster Management" > "Mirror Repository" to enter the mirror repository list page, and click the "Add" button in the upper left corner. Enter the IP address of the repository where the mirror is stored in the pop-up window of adding a mirror repository, and click the "OK" button.</p></li><li><p>Create a cluster. Click "Cluster Management" > "Cluster" to enter the cluster list page, and click the "Create Cluster" button in the upper left corner. Configure the cluster nodes as needed. In the "Mirror Repository" of the "Cluster Configuration" page, select the mirror repository added in the first step, and create the cluster after completing other configurations of the cluster as needed.</p></li></ol><h2 id=create-a-cluster-using-the-cluster-template><strong>Create a cluster using the cluster template</strong></h2><p>You can use cluster templates to simplify the cluster creation process.</p><ol><li><p>Add a template. There are two ways to save a template. You can add a cluster template on the "Cluster Management" > "Template Management" page, and select the template when creating a new cluster. You can also save the existing cluster configuration as a template by clicking "More" > "Save as Template" in the cluster operation, so as to create a K8S cluster with the same configuration as the former cluster.</p></li><li><p>Create a cluster. Click "Cluster Management" > "Cluster" to enter the cluster list page, click the "Create Cluster" button in the upper left corner, enter the cluster creation page, fill in the "cluster name", such as "demo", select the cluster template saved in the first step, Add the required nodes, click the "Quick Create" button in the lower right corner, jump to the "Configuration Confirmation" page, after checking the template information, click the "OK" button to create a cluster.</p></li></ol><h2 id=cluster-configuration-guide><strong>Cluster Configuration Guide</strong></h2><h3 id=node-configuration-steps><strong>Node configuration steps</strong></h3><p>On the node configuration page, you can configure the node as follows:</p><ul><li><p>Region: The region to which the cluster belongs. When adding a node, a physical or logical region can be specified for the node. The K8S cluster created by the node under this area also belongs to this region. Creating a cluster using multiple regional nodes is not supported.</p></li><li><p>Control Nodes: Specify an odd number of control nodes for the cluster. The production environments generally use 3 control nodes to achieve high availability.</p></li><li><p>Worker nodes: Add worker nodes to the new cluster according to the business size.</p></li><li><p>Taint management: You can configure taint for added nodes, kubeclipper will automatically add no schedule taint to the control nodes, and you can also make changes as needed.</p></li><li><p>Node Labels: You can configure labels for added cluster nodes as needed.</p></li></ul><p>You can configure the required nodes according to your business needs. If you need to create a non-highly available experimental cluster, you can also add only one control node, and remove the taint automatically added for the control node. For details, see "Creating a Single-Node Experimental Cluster".</p><h3 id=cluster-configuration-steps><strong>Cluster configuration steps</strong></h3><p>On the cluster configuration page, you can configure the cluster as follows:</p><p>Installation method and mirror repository:</p><table><thead><tr><th>Page configuration</th><th>Configure Package/Image Sources</th></tr></thead><tbody><tr><td><strong>Online</strong> (public network environment)<strong>Mirror repository</strong> is empty</td><td>Configuration package source: Download from kubeclipper.io.Image pull method: The image is pulled from the official image repository by default, such as k8s image pulled from k8s.gcr.io, calico pulled from docker.io.</td></tr><tr><td><strong>Online</strong> (public network environment)<strong>Mirror repository</strong> specification</td><td>Configuration package source: Download from kubeclipper.io.Image pull method: Pull from the filled mirror repository. The components will inherit the repository address by default. Please ensure that the repository has the related component images. You can also set an independent mirror repository for a specific component, and the component image will be pulled from this address.</td></tr><tr><td><strong>Offline</strong> (intranet environment)<strong>Mirror repository</strong> is empty</td><td>Configuration package source: Download from the local kubeclipper cluster server node, you can use the &ldquo;kcctl resource list&rdquo; command to check the available configuration packages, or use the &ldquo;kcctl resource push&rdquo; command to upload the required configuration packages.Image pull method: Download from the local kubeclipper cluster server node. CRI will import the image after downloading. You can use the &ldquo;kcctl resource list&rdquo; command to check the available image packages, or use the &ldquo;kcctl resource push&rdquo; command to upload the required image packages.</td></tr><tr><td><strong>Offline</strong> (intranet environment)<strong>Mirror repository</strong> specification</td><td>Configuration package source: Download from the local kubeclipper cluster server node, you can use the &ldquo;kcctl resource list&rdquo; command to check the available configuration packages, or use the &ldquo;kcctl resource push&rdquo; command to upload the required configuration packages.Image pull method: Pull from the filled mirror repository. The components will inherit the repository address by default. Please ensure that the repository has the related component images. You can also set an independent mirror repository for a specific component, and the component image will be pulled from this address. kubeclipper provides the Docker Registry and uses the kcctl registry command for management. You can also use your own image repositories.</td></tr></tbody></table><ul><li><p>K8S version: Specify the cluster K8S version. When you choose to install offline, you can choose from the K8S version of the configuration package in the current environment; when you choose to install online, you can choose from the officially recommended version of kubeclipper.</p></li><li><p>ETCD Data Dir: You can specify the ETCD data directory, the default is /var/lib/etcd.</p></li><li><p>CertSANs: The IP address or domain name of the k8s cluster ca certificate signature, more than one can be filled in.</p></li><li><p>Container Runtime: According to the specified K8S version, the default container runtime is Docker for K8S version before v1.20.0, the default container runtime is Contianerd after v1.20.0; Docker is not supported after v1.24.0.</p></li><li><p>Container Runtime version: Specify the containerd/docker version. As with K8S, when you choose to install offline, you can choose from the version of the configuration package in the current environment; when you choose to install online, you can choose from the officially recommended version of kubeclipper.</p></li><li><p>Containerd data Path: The "root dir" in the config.toml configuration can be filled in. The default is /var/lib/containerd.</p></li><li><p>Docker data Path: The "root dir" in the daemon.json configuration can be filled in . The default is /var/lib/docker.</p></li><li><p>Containerd image repository: The repository address where the containerd image is stored, the "registry.mirrors" in the config.toml configuration, more than one can be filled in.</p></li><li><p>Docker image repository: The repository address where the Docker image is stored, the insecure registry in the daemon.json configuration, more than one can be filled in.</p></li><li><p>DNS domain name: The domain name of the k8s cluster, the default is cluster.local.</p></li><li><p>Worker load IP: Used for load balancing from worker nodes to multiple masters, a single master does not need to be set.</p></li><li><p>External access IP: You can fill in a floating IP for user access, which can be empty.</p></li></ul><h3 id=cni-configuration><strong>CNI configuration</strong></h3><p>The current version kubeclipper only supports Calico as cluster CNI.</p><p>Calico divides the pod CIDR set by users into several blocks (network segments), dynamically allocates them to the required nodes according to business requirements, and maintains the routing table of the cluster nodes through the bgp peer in the nodes.</p><p>For example: container address pool: 172.25.0.0/16, dynamically allocated network segment pool: 172.25.0.0 - 172.25.255.192 (172.25.0.0/26 i.e. 10 bits), the number of dynamically allocated network segments: 1023, the number of pods per network segment: 61 (193-254), the total number of pods is 1023 * 61 = 62403, the relative maximum number of nodes (according to the 200 service pod as the reference value): 312.</p><p>Clusters larger than 50 nodes are currently not recommended. Clusters larger than 50 nodes are recommended to manually configure route reflection to optimize the stability of routing table maintenance for nodes in the cluster.</p><p>To use Calico as the cluster CNI, you need the following configuration:</p><ul><li><p>Calico mode: 5 network modes are supported:</p><ul><li>Overlay-IPIP-All: Use IP-in-IP technology to open up the network of pods of different nodes. Usually, this method is used in the environment where the underlying platform is IaaS. Of course, if your underlying network environment is directly a physical device, it is also completely can be used, but the efficiency and flexibility will be greatly reduced. It should be noted that you need to confirm that the underlying network environment (underlay) supports the IPIP protocol. (The network method using overlay will have a certain impact on network performance).</li><li>Overlay-Vxlan-All: Use IP-in-IP technology to open up the network of pods of different nodes. Usually, this method is used in the environment where the underlying platform is IaaS. Of course, if your underlying network environment is directly a physical device, it is also completely can be used, but the efficiency and flexibility will be greatly reduced. In theory, it can run on any network environment. Usually, we will use it when the underlying environment does not support the IPIP protocol. (The network method using overlay has a certain impact on network performance).</li><li>BGP : Use IP-in-IP technology to open up the network of pods of different nodes. Usually this method is used in a bare metal environment. Of course, if the Iaas platform supports BGP, it can also be used. In this mode, the IP communication of pods is accomplished by exchanging routing tables among nodes in the cluster. If you need to manually open up the pod network between multiple clusters, you need to pay attention that the addresses you assign should not conflict.</li><li>Overly-IPIP-Cross-Subnet: Use IP-in-IP technology to open up the network of pods of different nodes. Usually this method is used in the environment where the underlying platform is IaaS . It should be noted that you need to confirm the underlying network environment (underlay) supports the IPIP protocol. The difference with Overlay-IPIP-All is that if two upper Pods of different nodes in the same network segment communicate with each other through the routing table, the efficiency of upper Pods of different nodes in the same network segment can be improved.</li><li>Overly-Vxlan-Cross-Subnet: The logic is similar to that of Overly-IPIP-Cross-Subnet.</li></ul></li><li><p>IP version: The IP version can be specified as IPV4 or IPV4 IPV6 dual stack.</p></li><li><p>Service subnet: Fill in the service subnet CIDR, v4 defaults to: 10.96.0.0/16, v6 defaults to fd03::/112, note that the Service network must not overlap with any host network.</p></li><li><p>Pod CIDR: Fill in the pod subnet CIDR, v4 default: 172.25.0.0/24, v6 default is fd05::/120, note that the Pod network must not overlap with any host network.</p></li><li><p>The bottom layer of the pod network:</p><ul><li>First-found (default): The program will traverse all valid IP addresses (local, loop back, docker bridge, etc. will be automatically excluded) according to ipfamily (v4 or v6). Usually, if it is a multi-network interface card, it will exclude the default gateway. The network interface card ip other than the gateway will be used as the routing address between nodes.</li><li>Can-reach: Set the routing address between nodes by checking the reachability of the domain names or IP addresses.</li><li>Interface: Get all network interface card device names that satisfy the regular expression and return the address of the first network interface card as the routing address between nodes.</li></ul></li><li><p>MTU: Configure the maximum transmission unit (MTU) for the Calico environment. It is recommended to be no larger than 1440. The default is 1440. See <a href=https://docs.projectcalico.org/networking/mtu>https://docs.projectcalico.org/networking/mtu</a> for details.</p></li></ul><h3 id=storage-configuration><strong>Storage configuration</strong></h3><p>The current version of Kubeclipper supports NFS as external storage types.</p><ul><li><strong>Connect to NFS storage</strong></li></ul><p>For NFS type external storage, you need to set the following:</p><table><thead><tr><th>Field</th><th>Function description</th><th>description/optional</th></tr></thead><tbody><tr><td>ServerAddr</td><td>ServerAddr, the service address of NFS</td><td>Required</td></tr><tr><td>SharedPath</td><td>SharedPath, the service mount path for NFS</td><td>Required</td></tr><tr><td>StorageClassName</td><td>StorageClassName, the name of the storage class</td><td>The default is nfs-sc, the name can be customized, and it cannot be repeated with other storage classes in the cluster</td></tr><tr><td>ReclaimPolicy</td><td>ReclaimPolicy, VPC recovery strategy</td><td>Delete/Retain</td></tr><tr><td>ArchiveOnDelete</td><td>ArchiveOnDelete, whether to archive PVC after deletion</td><td>Yes/No</td></tr><tr><td>MountOptions</td><td>MountOptions, the options parameter of NFS, such as nfsvers = 4.1</td><td>Optional, you can fill in several</td></tr><tr><td>Replicas</td><td>Replicas, number of NFS provisioners</td><td>Default is 1</td></tr></tbody></table><p>By default, multiple NFS storage types can be connected. Click the "Continue to add" button below to add another NFS storage. Note that the storage class name cannot be repeated.</p><p>After setting up the external storage, the card below will show the storages you have enabled. You can choose a storage class as the default storage. For PVCs that do not specify a specific StorageClass, the default storage class will be used.</p><h2 id=cluster-operation-log-view><strong>Cluster operation log view</strong></h2><p>On the cluster details page, click the "operation log" tab to view the cluster operation log list. Click the "View Log" button on the right side of an operation log to view the detailed logs of all steps and nodes in the pop-up window. Click the step name on the left to view the detailed log output of the execution steps.</p><p>During the execution of cluster operations, click View Log, you can view real-time log updates to trace the operation execution. For tasks that fail to execute, you can also view the log to find the execution steps and nodes marked with red dots, quickly locate errors, and troubleshoot the cause of operation failure.</p><p><img src="https://zhc3o5gmf9.feishu.cn/space/api/box/stream/download/asynccode/?code=YmM4ZjUzODc3MThmZWIxNTVmODUzZmI1YzMzNzAxYTVfOVJ3QURVS2RnOWJrRTJiRHBPOWpDZEdpMWJZRU4yWm5fVG9rZW46Ym94Y25Xc3VmcE52dE1LNGJRRlRvTk9GTEtnXzE2NjA2MzQzNzE6MTY2MDYzNzk3MV9WNA" alt></p><h2 id=access-cluster-kubectl><strong>Access cluster kubectl</strong></h2><p>You can access the kubectl of the running cluster, click "More" > "Connect Terminal" in the cluster operation, and you can execute the kubectl command line operation in the cluster kuebectl pop-up window.</p><h2 id=cluster-plugin-management><strong>Cluster plugin management</strong></h2><p>In addition to installing plugins when creating a cluster, you can also install plugins for a running cluster. Taking the installation of storage plugins as an example, click the "More" > "Add Storage Item" button in the cluster operation to enter the Add Storage Item page. You can install NFS plugins for the cluster. The installation configuration is the same as the configuration in cluster creation.</p><p>For installed plugins, you can view the plugin information on the cluster details page. You can click the "Save as Template" button in the upper right corner of the plugin card to save the plugin information as a template. You can also uninstall the cluster plugin by clicking the "Remove" button in the upper right corner of the plugin card.</p><h2 id=cluster-node-management><strong>Cluster node management</strong></h2><p>On the "Nodes" list page of the cluster detail page, you can view the list of nodes in the current cluster, their specifications, status and role information.</p><h3 id=add-cluster-node><strong>Add cluster node</strong></h3><p>When the cluster load is high, you can add nodes to the cluster to expand capacity. Adding nodes does not affect the running services.</p><p>On the cluster details page, under the Node List tab, click the "Add Node" button on the left, select the available nodes in the pop-up window, set the node labels, and click the "OK" button. The current version only supports adding worker nodes.</p><h3 id=remove-cluster-node><strong>Remove cluster node</strong></h3><p>On the cluster details page, under the Node List tab, you can remove a node by clicking the "Remove" button on the right of the node. The current version only supports removing worker nodes.</p><p>Note: To remove cluster nodes, you need to pay attention to security issues in production to avoid application interruptions.</p><h2 id=cluster-version-upgrade><strong>Cluster version upgrade</strong></h2><p>If the cluster version does not meet the requirements, you can upgrade the K8S version for the cluster. Similar to creating a cluster, you need to prepare the configuration package required for the cluster version and the K8S image of the target version and upload it to the specified location. For details, see "Preparing to Create a Cluster".</p><p>Click the "More" > "Cluster Upgrade" button of the cluster operation. In the cluster upgrade pop-up window, select the installation mode and mirror repository, and select the target version of the upgrade. The installation method of the upgrade and the configuration of the K8S version are the same as those of creating a cluster. For details, please refer to "Cluster Configuration Guide".</p><p>Cluster upgrades can be performed across minor versions, but upgrades skipped over later versions are not supported. For example, you can upgrade from v1.20.2 to v1.20.13, or from v1.20.x to v1.21.x, but not from v1.20.x to v1.22.x. For version 1.23.x, upgrading to version 1.24.x is not currently supported.</p><p>The cluster upgrade operation may take a long time. You can view the operation log on the cluster details page to track the cluster upgrade status.</p><h2 id=cluster-backup-and-recovery><strong>Cluster Backup and Recovery</strong></h2><p>The backup of K8S cluster by KubeClipper mainly backs up ETCD database data, and k8s resource object, such as namespaces, deployments, configMaps. The files and data generated by the resource itself are not backed up. For example, the data and files generated by the mysql pod will not be backed up. Similarly, the files under the PV object of the file class are not backed up, only the pv object is backed up. The backup function provided by KubeClipper is hot backup, which does not affect cluster usage during backup. While KubeClipper is not against backing up during the "busy period" of the cluster, it also strongly disapproves of backing up during the "busy period" of the cluster.</p><h3 id=create-a-backup-point><strong>Create a backup point</strong></h3><p>Before performing a backup, you need to set a backup point for the cluster, that is, set the storage location of the backup files. The storage type of the backup point can be FS storage or S3 storage . The following are node local storage , NFS storage and MINIO storage as examples:</p><ul><li><h3 id=node-local-storage-only-for-single-node-experimental-clusters><strong>Node local storage (only for single-node experimental clusters):</strong></h3></li></ul><ol><li><p>Create a storage directory. Connect to the cluster master node terminal (see Connect Nodes Terminal) and use the mkdir command to create the "/root/backup" directory in the master node.</p></li><li><p>Create a backup point. Click "Cluster Management" > "Backup Point" to enter the backup point list page, click the "Create" button in the upper left corner, in the Create Backup Point pop-up window, enter "Backup Point Name", such as "local", select "Storage Type" as "FS", fill in "Backup Path", such as "/root/backup".</p></li><li><p>Set up a cluster backup point. When creating a cluster, select "Backup Point" as "local" on the "Cluster Configuration" page, or edit an existing cluster and select "local" in the "Backup Point" pop-up.</p></li></ol><p>Note: Using a local node to store backup files does not require the introduction of external storage. The disadvantage is that if the local node is damaged, the backup files will also be lost, so it is strongly disapproved in a production environment .</p><ul><li><strong>NFS：</strong></li></ul><ol><li><p>Prepare NFS storage. Prepare an NFS service and create a directory on the NFS server to store backup files, such as "/data/kubeclipper/cluster-backups".</p></li><li><p>Mount the storage directory. Connect the cluster master node terminal (see Connect node Terminal), use the mkdir command to create the "/data/kubeclipper/cluster-backups" directory in each master node, and mount it to the /data/kubeclipper/cluster-backups directory of the NFS server. Command example: mount -t nfs {NFS_IP}:/data/kubeclipper/cluster-backups /opt/kubeclipper/cluster-backups -o proto = tcp -o nolock.</p></li><li><p>Create a backup point. Click "Cluster Management" > "Backup Point" to enter the backup point list page, click the "Create" button in the upper left corner, in the Create Backup Point pop-up window, enter "Backup Point Name", such as "nfs", select "Storage Type" as "FS", fill in "Backup Path" as "/opt/kubeclipper/cluster-backups".</p></li><li><p>Set up a cluster backup point. When creating a cluster, select "Backup Point" as "nfs" on the "Cluster Configuration" page, or edit an existing cluster and select "nfs" in the "Backup Point" pop-up.</p></li></ol><ul><li><strong>MINIO：</strong></li></ul><ol><li><p>Prepare MINIO storage. Build MINIO services, refer to the official website <a href=https://docs.min.io/docs/minio-quickstart-guide.html>https://docs.min.io/docs/minio-quickstart-guide.html</a> for the deployment process, or use existing MINIO services.</p></li><li><p>Create a backup point. Click "Cluster Management" > "Backup Point" to enter the backup point list page, click the "Create" button in the upper left corner, in the Create Backup Point pop-up window, enter "Backup Point Name", such as "minio", select "Storage Type" as "S3", fill in "bucket name", such as "kubeclipper-backups", the bucket will be automatically created by kubeclipper, fill in the IP and port number of the MINIO storage service in the first step in "Endpoint", fill in the service username and password, click the "OK" button.</p></li><li><p>Set up a cluster backup point. When creating a cluster, select "backup point" as "minio" on the "Cluster Configuration" page, or edit an existing cluster and select "minio" in the "Backup Point" pop-up.</p></li></ol><p>You can view the list and details of all backup points on the "Backup Points" page of "Cluster Management" and do the following:</p><ul><li><p>Edit: Edit the backup point description, and the username/password of the S3 type backup point.</p></li><li><p>Delete: Delete the backup point. If there are backup files under the backup point, deletion is not allowed.</p></li></ul><h3 id=cluster-backup><strong>Cluster backup</strong></h3><p>You can back up your cluster ETCD data by clicking the "More" > "Cluster Backup" button in the cluster operation.</p><p>You can view all backup files for the current cluster under the Backup tab on the cluster details page, and you can also perform the following operations for backups:</p><ul><li><p>Edit: Edit the backup description.</p></li><li><p>Restore: Performs a cluster restore operation to restore the cluster to the specified backup state.</p></li><li><p>Delete: Deletes the backup file.</p></li></ul><h3 id=scheduled-backup><strong>Scheduled backup</strong></h3><p>You can also create a timed backup for the cluster, click the "More" > "Scheduled Backup" button in the cluster operation, in the timed backup pop-up window, enter the timed backup name, execution type ( repeat / only once) and execution time, and set the number of valid backups for repeated timed backups, and click the "OK" button.</p><p>kubeClipper will perform backup tasks for the cluster at the execution time you set, and the backup file will be automatically named "Cluster Name - Timed Backup Name - Random Code". For repeated timed backups, when the number of backup files exceeds the number of valid backup files, kubeClipper will automatically delete the later backup files.</p><p>After the scheduled backup is added, you can view the scheduled backup information on the "Scheduled Backup" tab of the cluster details page, and you can also view the backup files generated by the scheduled backup on the "Backup" tab.</p><p>For scheduled backup tasks, you can also perform the following operations:</p><ul><li><p>Edit: Edit the execution time of the scheduled backup task and the number of valid backups for repeated scheduled backups.</p></li><li><p>Enable/Disable: Disabled scheduled backup tasks are temporarily stopped.</p></li><li><p>Delete: Deletes a scheduled backup task.</p></li></ul><h3 id=cluster-backup-restore><strong>Cluster Backup Restore</strong></h3><p>If you perform restore operation while the cluster is running, KubeClipper will perform overlay recovery on the cluster, that is, backup the ETCD data in the file, overwriting the existing data .</p><p>You can click the "Restore" button on the right side of the backup under the Backup tab of the cluster details page; or click the "More" > "Restore Cluster" button in the cluster operation, and select the backup to be restored in the Restore Cluster pop-up window. The current cluster can be restored to the specified backup state.</p><p>Note: After the K8S version of the cluster is upgraded, it will no longer be possible to restore the backup to the pre-upgrade version.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f8b869abb7ea8ad8dbef714007033263>4.2 - Node & Zone Management</h1><div class=lead>A short lead description about this content page. It can be <strong>bold</strong> or <em>italic</em> and can be split over multiple paragraphs.</div><p>On the "Node Information" page, you can view the list of all nodes managed in the platform, node specifications, status and other information. Click the node name to enter the node details page, you can view detailed node basic information and system information.</p><p><img src=/images/docs-tutorials/node-info.png alt></p><p>The node status in KubeClipper represents the management status of the node by kc-gent. Under normal circumstances, the node status is displayed as "Ready". When the node is out of contact for 4 minutes (within 10s of the error time), the status will be updated to "Unknown". Nodes with unknown status cannot perform any operations, nor can they create clusters or add/remove nodes for clusters.</p><h2 id=add-node><strong>Add node</strong></h2><p>When deploying KubeClipper, you can add the initial server nodes which are used to deploy KubeClipper's own services, and agent nodes which are used to deploy K8S clusters. In a KubeClipper environment for experimentation or development, you can add a server node as an agent node at the same time. However, if it is used in a production environment, it is recommended not to reuse the server node as an agent node.</p><p>You can also use the kcctl join command to add agent nodes to KubeClipper, and mark a region for each agent node. The region can be a physical or logical location. You can use nodes in the same region to create a K8S cluster, but you cannot use nodes across regions to create a cluster. Nodes in unmarked regions belong to the default region. For details, see "Kcctl Operation Guide".</p><p>Command line example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Plaintext data-lang=Plaintext><span style=display:flex><span>kcctl join --agent beijing:1.2.3.4 --agent shanghai:2.3.4.5
</span></span></code></pre></div><h2 id=remove-node><strong>Remove node</strong></h2><p>When you no longer need some nodes, you can use the kcctl drain command to remove nodes from the platform. See "Kcctl Operation Guide" for details.</p><p>Command line example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Plaintext data-lang=Plaintext><span style=display:flex><span>kcctl drain --agent 192.168.10.19
</span></span></code></pre></div><h2 id=connect-terminal><strong>Connect Terminal</strong></h2><p>On the node list page, you can click the "Connect Terminal" button on the right side of the target node, enter the node port and username password information in the pop-up window, access the node SSH console and execute the command.</p><p><img src=/images/docs-tutorials/node-terminal.png alt></p></div><div class=td-content style=page-break-before:always><h1 id=pg-9db4787abe05db7c233072bf3fa9f94e>4.3 - Access control</h1><div class=lead>A short lead description about this content page. It can be <strong>bold</strong> or <em>italic</em> and can be split over multiple paragraphs.</div><h2 id=create-user><strong>Create user</strong></h2><p>After installing KubeClipper, you need to create a user for the desired role. Initially, the system has only one user, admin, by default, with the platform administrator role.</p><p>Click "Access Control" > "Users" to enter the user management page, click the "Create User" button in the upper left corner, fill in the user name, password, mobile phone number, email and other information in the pop-up window, specify the user role, and click the "OK" button. The four built-in roles in the system are as follows:</p><ul><li><p>Platform administrator: have platform configuration, cluster management, user management and other platform viewing and operation rights.</p></li><li><p>Cluster Administrator: Have all cluster management rights.</p></li><li><p>User Administrator: Have all user management rights.</p></li><li><p>Platform read-only users: have platform viewing rights.</p></li></ul><p>After the user is created, you can view the user details and login logs on the user details page and do the following:</p><ul><li><p>Edit: Edit user alias, role, mobile phone number, email information.</p></li><li><p>Edit Password: Edit the user login password.</p></li><li><p>Delete: Delete the user.</p></li></ul><h2 id=create-a-custom-role><strong>Create a custom role</strong></h2><p>In addition to system built-in roles, you can also create custom roles to meet business needs.</p><p>Click "Access Control" > "Roles" to enter the role management page. You can click the "Create Role" button in the upper left corner to create a custom role.</p><p>On the Create Role page, you need to fill in the role name and description, and check the permissions required to customize the role. Some permissions depend on other permissions. When these permissions are selected, the dependent permissions will be automatically selected.</p><p>After creating a custom role, you can view the basic role information, role permission list, authorized user list on the role details page, and perform the following operations for the custom role:</p><ul><li><p>Edit: Edit the custom role alias.</p></li><li><p>Edit permissions: Edit permissions under the custom role.</p></li><li><p>Delete: To delete a custom role, make sure that no user is using the role to be deleted.</p></li></ul><h2 id=access-to-external-users><strong>Access to external users</strong></h2><p>KubeClipper can log in using external users via the OIDC protocol .</p><p>First, the platform administrator needs to log in to the platform server node and insert the following information under authentication in the kubeclipepr-server.yaml file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Plain data-lang=Plain><span style=display:flex><span>oauthOptions:
</span></span><span style=display:flex><span>    identityProviders:
</span></span><span style=display:flex><span>    - name: keycloak
</span></span><span style=display:flex><span>      type: OIDC
</span></span><span style=display:flex><span>      mappingMethod: auto
</span></span><span style=display:flex><span>      provider:
</span></span><span style=display:flex><span>        clientID: kc
</span></span><span style=display:flex><span>        clientSecret: EErn729BB1bKawdRtnZgrqj9Bx0]mzUs
</span></span><span style=display:flex><span>        issuer: http://172.20.163.233:7777/auth/realms/kubeclipper
</span></span><span style=display:flex><span>        scopes:
</span></span><span style=display:flex><span>        - openid
</span></span><span style=display:flex><span>        - email
</span></span><span style=display:flex><span>        redirectURL: http://{kc-console-address}/oatuh2/redirect/{IDP-Name}
</span></span></code></pre></div><p>Under "provider", you need to fill in the clientID , clientSecret , and issuer information of your OAuth2 service, taking keycloack as an example, as shown in the figure below.</p><p>RedirectURL example: http://172.0.0.90/oauth2/redirect/keycloack</p><p><img src=/images/docs-tutorials/keycloak-client.png alt></p><p><img src=/images/docs-tutorials/keycloak-client2.png alt></p><p>OAuth2 users can access and use the KubeClipper platform by following these steps:</p><ol><li><p>Click the "OAuth2 Login" button on the login page, enter the OAuth2 login page, enter the username and password to log in, enter the KubeClipper platform. When logging in for the first time, you will not be able to access the platform because you have not been granted any permission.</p></li><li><p>The platform administrator or other user with user management rights log in to KubeClipper, find the target OAuth2 user on the user management page, and set the user role by editing the user information.</p></li><li><p>The OAuth2 user repeats the first step, logs in to KubeClipper, and can access the platform normally and perform operations within the role permissions.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-8efbf7499fe9c7bde8d2c1bb7ff6ee3c>5 - Contribution Guidelines</h1><div class=lead>How to contribute to the docs</div><p>Please check <a href=https://github.com/kubeclipper/community>KubeClipper Community</a></p></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/kubeclipper/kubeclipper aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2025 KubeClipper All Rights Reserved</small>
<small class=ml-1><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></small></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/v1.2/js/main.min.91798a335c881f1b6b805085ba4aa22d1dbd2b0b18d105d05189fa104ddae350.js integrity="sha256-kXmKM1yIHxtrgFCFukqiLR29KwsY0QXQUYn6EE3a41A=" crossorigin=anonymous></script></body></html>