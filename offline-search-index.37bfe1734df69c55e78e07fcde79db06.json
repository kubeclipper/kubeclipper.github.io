[{"body":"For users who are new to KubeClipper and want to get started quickly, it is recommended to use the All-in-One installation mode, which can help you quickly deploy KubeClipper with zero configuration.\nDeploy KubeClipper Download kcctl KubeClipper provides a command line tool ğŸ”§ kcctl to simplify operation and maintenance. You can download the latest version of kcctl directly with the following command:\n# The latest distribution is installed by default curl -sfL https://oss.kubeclipper.io/kcctl.sh | bash - # Install the specified version curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=v1.3.1 bash - #If you are in China, you can use cn environment variables during installation, in this case we will use registry.aliyuncs.com/google_containers instead of k8s.gcr.io Curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn bash - You can also download the specified version from the [GitHub Release Page] ( https://github.com/kubeclipper/kubeclipper/releases ) .\nCheck if the installation was successful with the following command:\nKcctl version Start installation You can use â€˜kcctl deployâ€™ to quickly install and deploy KubeClipper. kcctl uses SSH to access the target node where KubeClipper is finally deployed, so you need to provide SSH access credentials, and the following way to pass the credentials:\nKcctl deploy [--user \u003cusername\u003e] [--passwd \u003cpassword\u003e | --pk-file \u003cprivate key path\u003e] Exampleï¼š\n# Use the private key kcctl deploy --user root --pk-file /root/.ssh/id_rsa # Use a password kcctl deploy --user root --passwd password Execute the â€˜kcctl deployâ€™ command kcctl will check your installation environment and will automatically enter the installation process if the conditions are met. If you see the following KubeClipper banner, the installation is successful.\n_ __ _ _____ _ _ | | / / | | / __ \\ (_) | |/ / _ _| |__ ___| / \\/ |_ _ __ _ __ ___ _ __ | \\| | | | '_ \\ / _ \\ | | | | '_ \\| '_ \\ / _ \\ '__| | |\\ \\ |_| | |_) | __/ \\__/\\ | | |_) | |_) | __/ | \\_| \\_/\\__,_|_.__/ \\___|\\____/_|_| .__/| .__/ \\___|_| | | | | |_| |_| You can also deploy the master version of KubeClipper to experience the latest features (the master version is not rigorously validated and may contain unknown bugs that affect the experience)\nInstall the master version kcctl curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=master bash - Set environment variables on the installation server export KC_VERSION=master Deploy KubeClipper AIO environment kcctl deploy Login to console After the installation is complete, open a browser and visit â€˜http:â€™ to enter the KubeClipper console. (Usually kc-server IP is the IP of the node where you deploy kubeClipper)\nYou can use the default account password \" admin/Thinkbig1 \" to log in.\nYou may need to configure port forwarding rules and open ports in security groups for external users to access the console.\nCreate kubernetes cluster After successful deployment you can create a kubernetes cluster using the ** kcctl tool ** or via the ** console ** . Use the kcctl tool to create it in this quickstart tutorial.\nFirst, use the default account password to log in and obtain the token, which is convenient for subsequent interaction between kcctl and kc-server.\nkcctl login -H http://\u003ckc-server ip address\u003e:8080 -u admin -p Thinkbig1 Then create a Kubernetes cluster with the following command:\nNODE = $ (kcctl get node -o yaml | grep ipv4DefaultIP: | sed's/ipv4DefaultIP : //') Kcctl create cluster --master $NODE --name demo --untaint-master It takes about 3 minutes to complete the cluster creation, or you can use the following command to view the cluster status\nKcctl get cluster -o yaml | grep status -A5 You can also go to the console to view the real-time log.\nThe cluster installation is complete when the cluster is in the Running state, and you can use the â€˜kubectl get csâ€™ command to view the cluster health.\n","categories":["QuickStart"],"description":"Deploying the AIO environment\n","excerpt":"Deploying the AIO environment\n","ref":"/en/docs/getting-started/aio-env/","tags":["aio","sample","docs"],"title":"Deploying AIO"},{"body":"What is KubeClipper? KubeClipper aims to provide easy-to-use, easy-to-operate, lightweight, product-grade kubernetes multi-cluster full lifecycle management service, freeing operation and maintenance engineers from complicated configuration and obscure command lines to achieve one-stop management of multi-K8 s clusters across regions and infrastructure.\nWhy do I want KubeClipper? In the cloud-native era, Kubernetes has undoubtedly become the de facto standard for container orchestration. Although there are many tools to assist in the installation and management of kubernetes clusters, it is still very complicated to build and operate a production-level kubernetes cluster. In the process of a large number of services and practices, 99cloud has precipitated an extremely lightweight and easy-to-use graphical interface Kubernetes multi-cluster management tool - KubeClipper.\nUnder the premise of being fully compatible with native Kubernetes, KubeClipper is repackaged based on the kubeadm tool widely used by the community, providing rapid deployment of kubernetes clusters and continuous full life cycle management (installation, uninstallation, upgrade, scaling) in the enterpriseâ€™s own infrastructure. It supports multiple deployment methods such as online, proxy, and offline, and also provides rich and scalable management services for CRI, CNI, CSI, and various CRD components.\nCompared with the existing kubernetes lifecycle management tools such as Sealos, KubeKey, Kubeasz, KubeOperator, and K0S, KubeClipper is more open and native, lightweight, convenient, stable and easy to use.\nGetting Started: Get started with $project Examples: Check out some example code! ","categories":"","description":"Manage kubernetes in the most light and convenient way â˜¸ï¸\n","excerpt":"Manage kubernetes in the most light and convenient way â˜¸ï¸\n","ref":"/en/docs/overview/","tags":"","title":"Overview"},{"body":"KubeClipper æ˜¯ä»€ä¹ˆï¼Ÿ KubeClipper æ—¨åœ¨æä¾›æ˜“ä½¿ç”¨ã€æ˜“è¿ç»´ã€æè½»é‡ã€ç”Ÿäº§çº§çš„ Kubernetes å¤šé›†ç¾¤å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†æœåŠ¡ï¼Œè®©è¿ç»´å·¥ç¨‹å¸ˆä»ç¹å¤çš„é…ç½®å’Œæ™¦æ¶©çš„å‘½ä»¤è¡Œä¸­è§£æ”¾å‡ºæ¥ï¼Œå®ç°ä¸€ç«™å¼ç®¡ç†è·¨åŒºåŸŸã€è·¨åŸºç¡€è®¾æ–½çš„å¤š kubernetes é›†ç¾¤ã€‚\nä¸ºä»€ä¹ˆéœ€è¦ KubeClipperï¼Ÿ äº‘åŸç”Ÿæ—¶ä»£ï¼ŒKubernetes å·²æ¯‹åº¸ç½®ç–‘åœ°æˆä¸ºå®¹å™¨ç¼–æ’çš„äº‹å®æ ‡å‡†ã€‚è™½ç„¶æœ‰è¯¸å¤šè¾…åŠ© kubernetes é›†ç¾¤å®‰è£…å’Œç®¡ç†çš„å·¥å…·ï¼Œä½†æ­å»ºå’Œè¿ç»´ä¸€å¥—ç”Ÿäº§çº§åˆ«çš„ kubernetes é›†ç¾¤ä»ç„¶ååˆ†å¤æ‚ã€‚ä¹å·äº‘åœ¨å¤§é‡çš„æœåŠ¡å’Œå®è·µè¿‡ç¨‹ä¸­ï¼Œæ²‰æ·€å‡ºä¸€ä¸ªæè½»é‡ã€æ˜“ä½¿ç”¨çš„å›¾å½¢åŒ–ç•Œé¢ Kubernetes å¤šé›†ç¾¤ç®¡ç†å·¥å…·â€”â€” KubeClipperã€‚\nKubeClipper åœ¨å®Œå…¨å…¼å®¹åŸç”Ÿ Kubernetes çš„å‰æä¸‹ï¼ŒåŸºäºç¤¾åŒºå¹¿æ³›ä½¿ç”¨çš„ kubeadm å·¥å…·è¿›è¡ŒäºŒæ¬¡å°è£…ï¼Œæä¾›åœ¨ä¼ä¸šè‡ªæœ‰åŸºç¡€è®¾æ–½ä¸­å¿«é€Ÿéƒ¨ç½² kubernetes é›†ç¾¤å’ŒæŒç»­åŒ–å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆå®‰è£…ã€å¸è½½ã€å‡çº§ã€æ‰©ç¼©å®¹ã€è¿œç¨‹è®¿é—®ç­‰ï¼‰èƒ½åŠ›ï¼Œæ”¯æŒåœ¨çº¿ã€ä»£ç†ã€ç¦»çº¿ç­‰å¤šç§éƒ¨ç½²æ–¹å¼ï¼Œè¿˜æä¾›äº†ä¸°å¯Œå¯æ‰©å±•çš„ CRIã€CNIã€CSIã€ä»¥åŠå„ç±» CRD ç»„ä»¶çš„ç®¡ç†æœåŠ¡ã€‚\nä¸ç°æœ‰çš„ Sealosã€KubeKeyã€Kubeaszã€KubeOperatorã€K0S ç­‰ kubernetes ç”Ÿå‘½å‘¨æœŸç®¡ç†å·¥å…·ç›¸æ¯”ï¼ŒKubeClipper æ›´è´´è¿‘å¼€æ”¾åŸç”Ÿã€è½»é‡ä¾¿æ·ã€ç¨³å®šæ˜“ç”¨ã€‚\nå¿«é€Ÿå¼€å§‹: Learn how to get started with Kubeclipper ç”¨æˆ·æ‰‹å†Œ: Check out some example code! ","categories":"","description":"Manage kubernetes in the most light and convenient way â˜¸ï¸\n","excerpt":"Manage kubernetes in the most light and convenient way â˜¸ï¸\n","ref":"/docs/overview/","tags":"","title":"æ¦‚è¿°"},{"body":"Prepare to create a cluster You need to have enough available nodes. To add nodes, refer to \"Add Nodes\".\nPrepare the image or binary files of kubernetes, CRI, calico, CSI and other plug-ins that need to be installed. You can choose online/offline according to the network environment of the platform, and choose the recommended kubernetes version on page. You can also upload the image required for deployment to your own image repository in advance, and specify the image repository during deployment. For more installation configuration, refer to \"Cluster Configuration Guide\".\nCreate an AIO experimental cluster Click \"Cluster Management\" \u003e \"Cluster\" to enter the cluster list page, and click the \"Create Cluster\" button in the upper left corner.\nEnter the \"Node Config\" page of the Create Cluster Wizard page. Fill in the \"Cluster Name\", such as \"test\", without selecting \"Cluster Template\". Select an available node, add it as a master node, and remove the taint from the master node in the taints list. Click the \"Next\" button.\nEnter the \"Cluster Config\" page. Select \"Offline\" for â€œImage Typeâ€, retain the default values for other configurations, click the \"Create Quickly\" button, jump to the â€œConfirm Configâ€ page, and click the \"Confirm\" button.\nThe experimental cluster of a single node is created. You can view the cluster details on the cluster details page, or click the \"ViewLog\" button to view the real-time log during the cluster creation process.\nCreate a cluster using a private registry If you create a cluster that contains large images, it is recommended that you upload the requred images to a private registry to speed up the installing process.\nAdd a private registry. Click \"Cluster Management\" \u003e \"Registry\" to enter the registry list page, and click the \"Add\" button in the upper left corner. In the pop-up window, enter the name and address of the registry where the images are stored, and click the \"OK\" button.\nCreate a cluster. Click \"Cluster Management\" \u003e \"Cluster\" to enter the cluster list page, and click the \"Create Cluster\" button in the upper left corner. Configure the cluster nodes as needed. In the \"Private Registry\" of the \"Cluster Config\" page, select the registry added in the first step, and create the cluster after completing other configurations of the cluster as needed.\nCreate a cluster using the cluster template You can use cluster templates to simplify the cluster creation process.\nAdd a template. There are two ways to save a template. You can add a cluster template on the \"Cluster Management\" \u003e \"Template Management\" page, and select the template when creating a new cluster. You can also save the existing cluster configuration as a template by clicking \"More\" \u003e\"Cluster setings\"\u003e \"Save as Template\" in the cluster operation, so as to create a kubernetes cluster with the same configuration as the former cluster.\nCreate a cluster. Click \"Cluster Management\" \u003e \"Cluster\" to enter the cluster list page, click the \"Create Cluster\" button in the upper left corner, enter the cluster creation page, fill in the \"cluster name\", such as \"demo\", select the cluster template saved in the first step. Add the required nodes, click the \"Create Quickly\" button in the lower right corner, jump to the \"Confirm Config\" page, after checking the template information, click the \"Confirm\" button to create a cluster.\nCluster Configuration Guide Node configuration On the node config page, you can configure the node as follows:\nRegion: The region to which the cluster belongs. When adding a node, a physical or logical region can be specified for the node. The kubernetes cluster created by the node under this region also belongs to this region. Creating a cluster with nodes from multiple regionals is not supported.\nMaster Nodes: Specify an odd number of master nodes for the cluster. The production environments generally use 3 master nodes to achieve high availability.\nWorker nodes: Add worker nodes to the new cluster according to the business size.\nTaint management: You can configure taint for added nodes, kubeclipper will automatically add noschedule taint to the master nodes, and you can also make changes as needed.\nNode Labels: You can configure labels for added cluster nodes as needed.\nYou can configure the required nodes according to your business needs. If you need to create a non-highly available experimental cluster, you can also add only one master node, and remove the taint automatically added for the master node. For details, refer to \"Creating an AIO Experimental Cluster\".\nCluster configuration On the cluster configuration page, you can configure the cluster as follows:\nInstallation method and registry: Online: public network environment Offline: intranet environment no private registry Specified private registry Online Configuration package: Download from kubeclipper.io. Images: The image is pulled from the official registry by default, for example, kubernetes image pulled from k8s.gcr.io, calico pulled from docker.io. Configuration package source: Download from kubeclipper.io.\nImages: Pulled from the filled private registry. The components will inherit the registry by default. Please ensure that the required images are stored in the registry. You can also set an independent registry for a specific component, and the component image will be pulled from this registry. Offline Configuration package: Download from the local kubeclipper server nodes, you can use the â€œkcctl resource listâ€ command to check the available configuration packages, or use the â€œkcctl resource pushâ€ command to upload the required configuration packages.\nImages: Download from the local kubeclipper server nodes, and CRI will import the images after downloading. You can use the â€œkcctl resource listâ€ command to check the available image packages, or use the â€œkcctl resource pushâ€ command to upload the required image packages. Configuration package: Download from the local kubeclipper server nodes, you can use the â€œkcctl resource listâ€ command to check the available configuration packages, or use the â€œkcctl resource pushâ€ command to upload the required configuration packages.\nImages: Pulled from the filled private registry. The components will inherit the registry by default. Please ensure that the required images are stored in the registry. You can also set an independent registry for a specific component, and the component image will be pulled from this address. kubeclipper provides the Docker Registry and uses the â€œkcctl registryâ€ command for management. You can also use your own private registry. kubernetes version: Specify the cluster kubernetes version. When you choose to install offline, you can choose from the kubernetes version of the configuration packages in the current environment; when you choose to install online, you can choose from the officially recommended versions by kubeclipper.\nETCD Data Dir: You can specify the ETCD data directory, which defaults to /var/lib/etcd.\nkubelet Data Dir: You can specify the ETCD data directory, which defaults to /var/lib/kubelet.\nCertSANs: The IP address or domain name of the kubernetes cluster ca certificate signature, more than one can be filled in.\nContainer Runtime: According to the specified kubernetes version, the default container runtime is Docker for kubernetes version before v1.20.0, the default container runtime is Contianerd after v1.20.0; Docker is not supported after v1.24.0.\nContainer Runtime version: Specify the containerd/docker version. As with kubernetes, when you choose to install offline, you can choose from the version of the configuration package in the current environment; when you choose to install online, you can choose from the officially recommended version by kubeclipper.\nContainerd data Path: The \"root dir\" in the config.toml configuration can be filled in. which defaults to /var/lib/containerd.\nDocker data Path: The \"root dir\" in the daemon.json configuration can be filled in . which defaults to /var/lib/docker.\nContainerd registry: The registry address where the images are stored, the \"registry.mirrors\" in the config.toml configuration, more than one can be filled in.\nDocker registry: The registry address where the images are stored, the insecure registry in the daemon.json configuration, more than one can be filled in.\nDNS domain name: The domain name of the kubernetes cluster, which defaults to cluster.local.\nWorker load IP: Used for load balancing from worker nodes to multiple masters, no need to be set for a single master node cluster.\nExternal access IP: You can fill in a floating IP for user access, which can be empty.\nBackup space: Storage location of cluster backup files.\nCNI configuration The current version kubeclipper supports Calico as cluster CNI.\nCalico divides the pod CIDR set by users into several blocks (network segments), dynamically allocates them to the required nodes according to business requirements, and maintains the routing table of the cluster nodes through the bgp peer in the nodes.\nFor example: container address pool: 172.25.0.0/16, dynamically allocated network segment pool: 172.25.0.0 - 172.25.255.192 (172.25.0.0/26 i.e. 10 bits), the number of dynamically allocated network segments: 1023, the number of pods per network segment: 61 (193-254), the total number of pods is 1023 * 61 = 62403, the relative maximum number of nodes (according to the 200 service pod as the reference value): 312.\nClusters larger than 50 nodes are currently not recommended. Clusters larger than 50 nodes are recommended to manually configure route reflection to optimize the stability of routing table maintenance for nodes in the cluster.\nTo use Calico as the cluster CNI, you need the following configuration:\nCalico mode: 5 network modes are supported: Overlay-IPIP-All: Use IP-in-IP technology to open up the network of pods of different nodes. Usually, this method is used in the environment where the underlying platform is IaaS. Of course, if your underlying network environment is directly a physical device, it is also completely can be used, but the efficiency and flexibility will be greatly reduced. It should be noted that you need to confirm that the underlying network environment (underlay) supports the IPIP protocol. (The network method using overlay will have a certain impact on network performance). Overlay-Vxlan-All: Use IP-in-IP technology to open up the network of pods of different nodes. Usually, this method is used in the environment where the underlying platform is IaaS. Of course, if your underlying network environment is directly a physical device, it is also completely can be used, but the efficiency and flexibility will be greatly reduced. In theory, it can run on any network environment. Usually, we will use it when the underlying environment does not support the IPIP protocol. (The network method using overlay has a certain impact on network performance). BGP : Use IP-in-IP technology to open up the network of pods of different nodes. Usually this method is used in a bare metal environment. Of course, if the Iaas platform supports BGP, it can also be used. In this mode, the IP communication of pods is accomplished by exchanging routing tables among nodes in the cluster. If you need to manually open up the pod network between multiple clusters, you need to pay attention that the addresses you assign should not conflict. Overly-IPIP-Cross-Subnet: Use IP-in-IP technology to open up the network of pods of different nodes. Usually this method is used in the environment where the underlying platform is IaaS . It should be noted that you need to confirm the underlying network environment (underlay) supports the IPIP protocol. The difference with Overlay-IPIP-All is that if two upper Pods of different nodes in the same network segment communicate with each other through the routing table, the efficiency of upper Pods of different nodes in the same network segment can be improved. Overly-Vxlan-Cross-Subnet: The logic is similar to that of Overly-IPIP-Cross-Subnet. IP version: The IP version can be specified as IPV4 or IPV4 IPV6 dual stack. Service subnet: Fill in the service subnet CIDR, v4 defaults to: 10.96.0.0/16, v6 defaults to fd03::/112, note that the Service network must not overlap with any host network. Pod CIDR: Fill in the pod subnet CIDR, v4 default: 172.25.0.0/24, v6 default is fd05::/120, note that the Pod network must not overlap with any host network. The bottom layer of the pod network: First-found (default): The program will traverse all valid IP addresses (local, loop back, docker bridge, etc. will be automatically excluded) according to ipfamily (v4 or v6). Usually, if it is a multi-network interface card, it will exclude the default gateway. The network interface card ip other than the gateway will be used as the routing address between nodes. Can-reach: Set the routing address between nodes by checking the reachability of the domain names or IP addresses. Interface: Get all network interface card device names that satisfy the regular expression and return the address of the first network interface card as the routing address between nodes. MTU: Configure the maximum transmission unit (MTU) for the Calico environment. It is recommended to be no larger than 1440. The default is 1440. See https://docs.projectcalico.org/networking/mtu for details. Storage configuration The current version of Kubeclipper supports NFS as external storage types.\nConnect to NFS storage For NFS type external storage, you need to set the following:\nField Function description description/optional ServerAddr ServerAddr, the service address of NFS Required SharedPath SharedPath, the service mount path for NFS Required StorageClassName StorageClassName, the name of the storage class The default is nfs-sc, the name can be customized, and it cannot be repeated with other storage classes in the cluster ReclaimPolicy ReclaimPolicy, VPC recovery strategy Delete/Retain ArchiveOnDelete ArchiveOnDelete, whether to archive PVC after deletion Yes/No MountOptions MountOptions, the options parameter of NFS, such as nfsvers = 4.1 Optional, you can fill in several Replicas Replicas, number of NFS provisioners Default is 1 After setting up the external storage, the card below will show the storages you have enabled. You can choose a storage class as the default storage. For PVCs that do not specify a specific StorageClass, the default storage class will be used.\nConfiguration Confirm You can check the cluster configuration information on the Confirm Config page. After confirming the information, click Confirm. You can also click the â€œEditâ€ button of each card to skip back to the corresponding step to modify the cluster information.\nThe cluster installation may take several minutes. You can check the operation logs on the cluster detail page to track the cluster installation status.\n","categories":"","description":"KubeClipper supports the creation of kubernetes clusters via a wizard-style page.\n","excerpt":"KubeClipper supports the creation of kubernetes clusters via a wizard-style page.\n","ref":"/en/docs/tutorials/create-clusters/","tags":"","title":"Create clusters"},{"body":"åˆ›å»ºé›†ç¾¤å‡†å¤‡å·¥ä½œ æ‚¨éœ€è¦å‡†å¤‡å……è¶³çš„å¯ç”¨èŠ‚ç‚¹ï¼Œå¦‚éœ€æ·»åŠ èŠ‚ç‚¹ï¼Œå‚è§â€œæ·»åŠ èŠ‚ç‚¹â€æ•™ç¨‹ã€‚ å‡†å¤‡å¥½éœ€è¦éƒ¨ç½²çš„ kubernetesã€CRIã€calicoã€CSI å’Œå…¶ä»–æ’ä»¶çš„é•œåƒæˆ–äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œkubeclipper æä¾›äº†æ¨èçš„ç‰ˆæœ¬ï¼Œæ‚¨å¯ä»¥æ ¹æ®å¹³å°æ‰€å¤„ç½‘ç»œç¯å¢ƒï¼Œé€‰æ‹©åœ¨çº¿ / ç¦»çº¿åï¼Œç›´æ¥åœ¨é¡µé¢ä¸Šé€‰å–ä½¿ç”¨ã€‚æ‚¨ä¹Ÿå¯ä»¥å°†éƒ¨ç½²æ‰€éœ€çš„é•œåƒä¸Šä¼ è‡³è‡ªå·±çš„é•œåƒä»“åº“ï¼Œå¹¶åœ¨éƒ¨ç½²æ—¶æŒ‡å®šã€‚æ›´å¤šå®‰è£…é…ç½®ï¼Œå‚è€ƒâ€œé›†ç¾¤é…ç½®â€ç« èŠ‚ã€‚ åˆ›å»ºå•èŠ‚ç‚¹å®éªŒé›†ç¾¤ ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé›†ç¾¤â€ï¼Œè¿›å…¥é›†ç¾¤åˆ—è¡¨é¡µé¢ï¼Œç‚¹å‡»å·¦ä¸Šè§’â€œåˆ›å»ºé›†ç¾¤â€æŒ‰é’®ã€‚\nè¿›å…¥åˆ›å»ºé›†ç¾¤å‘å¯¼é¡µé¢çš„â€œèŠ‚ç‚¹é…ç½®â€é¡µé¢ã€‚å¡«å†™â€œé›†ç¾¤åç§°â€ï¼Œå¦‚ â€œtestâ€ï¼Œä¸éœ€é€‰æ‹©â€œé›†ç¾¤æ¨¡ç‰ˆâ€ã€‚é€‰æ‹©ä¸€ä¸ªå¯ç”¨èŠ‚ç‚¹ï¼Œæ·»åŠ ä¸ºæ§åˆ¶èŠ‚ç‚¹ï¼Œå¹¶åœ¨æ±¡ç‚¹ç®¡ç†åˆ—è¡¨ä¸­ï¼Œå°† master èŠ‚ç‚¹çš„æ±¡ç‚¹ç§»é™¤ã€‚ç‚¹å‡»â€œä¸‹ä¸€æ­¥â€æŒ‰é’®ã€‚\nè¿›å…¥åˆ›å»ºé›†ç¾¤å‘å¯¼é¡µé¢çš„â€œé›†ç¾¤é…ç½®â€é¡µé¢ã€‚é€‰æ‹©â€œç¦»çº¿å®‰è£…â€ï¼Œâ€œé•œåƒä»“åº“â€ä¸éœ€å¡«å†™ï¼Œå…¶ä»–é…ç½®éƒ½å¯ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œç‚¹å‡»â€œå¿«é€Ÿåˆ›å»ºâ€æŒ‰é’®ï¼Œè·³è½¬é…ç½®ç¡®è®¤é¡µé¢ï¼Œç‚¹å‡»â€œç¡®è®¤â€æŒ‰é’®ã€‚\nå•èŠ‚ç‚¹çš„å®éªŒé›†ç¾¤åˆ›å»ºå®Œæˆï¼Œæ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µæŸ¥çœ‹é›†ç¾¤è¯¦æƒ…ï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»â€œæŸ¥çœ‹æ—¥å¿—â€æŒ‰é’®ï¼ŒæŸ¥çœ‹é›†ç¾¤åˆ›å»ºè¿‡ç¨‹ä¸­çš„å®æ—¶æ—¥å¿—ã€‚\nä½¿ç”¨é•œåƒä»“åº“åˆ›å»ºé›†ç¾¤ å¦‚æœåˆ›å»ºçš„é›†ç¾¤ä¸­åŒ…å«è¾ƒå¤§çš„é•œåƒï¼Œæ¨èæ‚¨å°†æ‰€æœ‰é•œåƒä¸Šä¼ åˆ°ç‰¹å®šçš„é•œåƒä»“åº“ï¼Œåˆ›å»ºé›†ç¾¤ä¼šæ›´å¿«é€Ÿæ›´é¡ºç•…ã€‚\næ·»åŠ é•œåƒä»“åº“ã€‚ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé•œåƒä»“åº“â€ï¼Œè¿›å…¥é•œåƒä»“åº“åˆ—è¡¨é¡µé¢ï¼Œç‚¹å‡»å·¦ä¸Šè§’â€œæ·»åŠ â€æŒ‰é’®ã€‚åœ¨æ·»åŠ é•œåƒä»“åº“çš„å¼¹çª—ä¸­è¾“å…¥é•œåƒä»“åº“åç§°å’Œå­˜æ”¾æœ‰é•œåƒçš„ä»“åº“åœ°å€ï¼Œç‚¹å‡»â€œç¡®å®šâ€æŒ‰é’®ã€‚ åˆ›å»ºé›†ç¾¤ã€‚ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé›†ç¾¤â€ï¼Œè¿›å…¥é›†ç¾¤åˆ—è¡¨é¡µé¢ï¼Œç‚¹å‡»å·¦ä¸Šè§’â€œåˆ›å»ºé›†ç¾¤â€æŒ‰é’®ã€‚æŒ‰éœ€é…ç½®é›†ç¾¤èŠ‚ç‚¹ï¼Œåœ¨â€œé›†ç¾¤é…ç½®â€é¡µé¢çš„â€œé•œåƒä»“åº“â€ä¸­ï¼Œé€‰æ‹©ç¬¬ä¸€æ­¥æ·»åŠ çš„é•œåƒä»“åº“ï¼Œæ ¹æ®éœ€è¦å®Œæˆé›†ç¾¤å…¶ä»–é…ç½®ååˆ›å»ºé›†ç¾¤ã€‚ ä½¿ç”¨é›†ç¾¤æ¨¡ç‰ˆåˆ›å»ºé›†ç¾¤ æ‚¨å¯ä»¥ä½¿ç”¨é›†ç¾¤æ¨¡ç‰ˆï¼Œç®€åŒ–é›†ç¾¤åˆ›å»ºæµç¨‹ã€‚\næ·»åŠ æ¨¡ç‰ˆã€‚ä¿å­˜æ¨¡ç‰ˆæœ‰ä¸¤ç§æ–¹å¼ï¼Œæ‚¨å¯ä»¥åœ¨â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œæ¨¡ç‰ˆç®¡ç†â€é¡µé¢ï¼Œæ·»åŠ é›†ç¾¤æ¨¡ç‰ˆï¼Œä»¥å¤‡åˆ›å»ºé›†ç¾¤æ—¶ä½¿ç”¨ã€‚ä¹Ÿå¯ä»¥ç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œä¿å­˜ä¸ºæ¨¡ç‰ˆâ€ï¼Œå°†å·²å­˜åœ¨çš„é›†ç¾¤é…ç½®ä¿å­˜ä¸ºæ¨¡ç‰ˆï¼Œä»¥ä¾¿åˆ›å»ºå‡ºå’Œè¯¥é›†ç¾¤åŒç­‰é…ç½®çš„ kubernetes é›†ç¾¤ã€‚ åˆ›å»ºé›†ç¾¤ã€‚ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé›†ç¾¤â€ï¼Œè¿›å…¥é›†ç¾¤åˆ—è¡¨é¡µé¢ï¼Œç‚¹å‡»å·¦ä¸Šè§’â€œåˆ›å»ºé›†ç¾¤â€æŒ‰é’®ï¼Œè¿›å…¥åˆ›å»ºé›†ç¾¤é¡µé¢ï¼Œå¡«å†™â€œé›†ç¾¤åç§°â€ï¼Œå¦‚ â€œdemoâ€ï¼Œé€‰æ‹©ç¬¬ä¸€æ­¥ä¸­ä¿å­˜çš„é›†ç¾¤æ¨¡ç‰ˆï¼Œæ·»åŠ æ‰€éœ€èŠ‚ç‚¹ï¼Œç‚¹å‡»å³ä¸‹è§’â€œå¿«é€Ÿåˆ›å»ºâ€æŒ‰é’®ï¼Œè·³è½¬è‡³â€œé…ç½®ç¡®è®¤â€é¡µé¢ï¼Œæ ¸å¯¹æ¨¡ç‰ˆä¿¡æ¯æ— è¯¯åï¼Œç‚¹å‡»â€œç¡®è®¤â€æŒ‰é’®ï¼Œåˆ›å»ºé›†ç¾¤ã€‚ é›†ç¾¤é…ç½®æŒ‡å— èŠ‚ç‚¹é…ç½® åœ¨èŠ‚ç‚¹é…ç½®é¡µé¢ï¼Œæ‚¨å¯ä»¥å¯¹èŠ‚ç‚¹è¿›è¡Œä»¥ä¸‹é…ç½®ï¼š\nåŒºåŸŸï¼šé›†ç¾¤æ‰€å±åŒºåŸŸï¼Œæ·»åŠ èŠ‚ç‚¹æ—¶å¯ä¸ºèŠ‚ç‚¹æŒ‡å®šç‰©ç†çš„æˆ–é€»è¾‘çš„åŒºåŸŸï¼Œä½¿ç”¨è¯¥åŒºåŸŸä¸‹èŠ‚ç‚¹åˆ›å»ºçš„ kubernetes é›†ç¾¤ä¹Ÿå±äºè¯¥åŒºåŸŸï¼Œä¸æ”¯æŒä½¿ç”¨è·¨åŒºåŸŸçš„å¤šä¸ªèŠ‚ç‚¹åˆ›å»ºé›†ç¾¤ã€‚ æ§åˆ¶èŠ‚ç‚¹ï¼šä¸ºé›†ç¾¤æŒ‡å®šå¥‡æ•°ä¸ªçš„æ§åˆ¶èŠ‚ç‚¹ï¼Œç”Ÿäº§ç¯å¢ƒä¸€èˆ¬ä½¿ç”¨3ä¸ªæ§åˆ¶èŠ‚ç‚¹ä»¥å®ç°é«˜å¯ç”¨ã€‚ å·¥ä½œèŠ‚ç‚¹ï¼šæ ¹æ®ä¸šåŠ¡è§„æ¨¡ï¼Œä¸ºæ–°é›†ç¾¤æ·»åŠ å·¥ä½œèŠ‚ç‚¹ã€‚ æ±¡ç‚¹ç®¡ç†ï¼šæ‚¨å¯ä»¥ä¸ºå·²æ·»åŠ çš„èŠ‚ç‚¹é…ç½®æ±¡ç‚¹ï¼Œkubeclipper ä¼šè‡ªåŠ¨ä¸ºæ§åˆ¶èŠ‚ç‚¹æ·»åŠ ä¸å…è®¸è°ƒåº¦ï¼ˆnoscheduleï¼‰çš„æ±¡ç‚¹ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œæ›´æ”¹ã€‚ èŠ‚ç‚¹æ ‡ç­¾ï¼šæ‚¨å¯ä»¥æ ¹æ®éœ€è¦ä¸ºå·²æ·»åŠ çš„é›†ç¾¤èŠ‚ç‚¹é…ç½®æ ‡ç­¾ã€‚ æ‚¨å¯ä»¥æŒ‰ä¸šåŠ¡éœ€è¦é…ç½®æ‰€éœ€èŠ‚ç‚¹ã€‚å¦‚æœéœ€è¦åˆ›å»ºéé«˜å¯ç”¨çš„å®éªŒé›†ç¾¤ï¼Œä¹Ÿå¯ä»¥ä»…æ·»åŠ ä¸€ä¸ªæ§åˆ¶èŠ‚ç‚¹ï¼Œå¹¶å°†æ§åˆ¶èŠ‚ç‚¹è‡ªåŠ¨æ·»åŠ çš„æ±¡ç‚¹ç§»é™¤ï¼Œè¯¦ç»†æ“ä½œå‚è§â€œåˆ›å»ºå•èŠ‚ç‚¹å®éªŒé›†ç¾¤â€ã€‚\né›†ç¾¤é…ç½® åœ¨é›†ç¾¤é…ç½®é¡µé¢ï¼Œæ‚¨å¯ä»¥å¯¹é›†ç¾¤è¿›è¡Œä»¥ä¸‹é…ç½®ï¼š\nå®‰è£…æ–¹å¼å’Œé•œåƒä»“åº“ï¼š é•œåƒä»“åº“ä¸ºç©º æŒ‡å®šé•œåƒä»“åº“ åœ¨çº¿ï¼ˆå…¬ç½‘ç¯å¢ƒï¼‰ é…ç½®åŒ…æ¥æºï¼šä» kubeclipper.io ä¸‹è½½ã€‚\né•œåƒæ‹‰å–æ–¹å¼ï¼šé•œåƒé»˜è®¤ä»å®˜æ–¹é•œåƒä»“åº“æ‹‰å–ï¼Œå¦‚ kubernetes é•œåƒä» k8s.gcr.io æ‹‰å–ã€calico ä» docker.io æ‹‰å–ã€‚å¦‚æœæ‚¨è®¾ç½®äº†å›½å†…é•œåƒä»£ç†ï¼Œé•œåƒä¼šä»æ‚¨æŒ‡å®šçš„ â€œKC_IMAGE_REPO_MIRRORâ€ ä»£ç†ä»“åº“æ‹‰å–ã€‚ é…ç½®åŒ…æ¥æºï¼šä» kubeclipper.io ä¸‹è½½ã€‚\né•œåƒæ‹‰å–æ–¹å¼ï¼šä»å¡«å†™çš„é•œåƒä»“åº“æ‹‰å–ï¼Œç»„ä»¶å°†é»˜è®¤ç»§æ‰¿è¯¥ä»“åº“åœ°å€ï¼Œè¯·ç¡®ä¿è¯¥ä»“åº“å­˜åœ¨ç›¸å…³ç»„ä»¶é•œåƒï¼›ç»„ä»¶ä¹Ÿä¼šæä¾›ç‹¬ç«‹çš„é•œåƒä»“åº“å‚æ•°ï¼Œè®¾ç½®åç»„ä»¶é•œåƒä»è¯¥åœ°å€æ‹‰å–ã€‚ ç¦»çº¿ï¼ˆå†…ç½‘ç¯å¢ƒï¼‰ é…ç½®åŒ…æ¥æºï¼šä»æœ¬åœ° kubeclipper é›†ç¾¤ server èŠ‚ç‚¹ä¸‹è½½ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ kcctl resource list å‘½ä»¤æŸ¥çœ‹æœ¬åœ°å¯ç”¨é…ç½®åŒ…ï¼Œæˆ–ä½¿ç”¨ kcctl resource push å‘½ä»¤ä¸Šä¼ æ‰€éœ€é…ç½®åŒ…ã€‚\né•œåƒæ‹‰å–æ–¹å¼ï¼šä»æœ¬åœ° kubeclipper é›†ç¾¤ server èŠ‚ç‚¹ä¸‹è½½ï¼Œä¸‹è½½åç”± CRI è¿›è¡Œé•œåƒå¯¼å…¥ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ kcctl resource list å‘½ä»¤æŸ¥çœ‹æœ¬åœ°å¯ç”¨é•œåƒåŒ…ï¼Œæˆ–ä½¿ç”¨ kcctl resource push å‘½ä»¤ä¸Šä¼ æ‰€éœ€é•œåƒåŒ…ã€‚ é…ç½®åŒ…æ¥æºï¼šä»æœ¬åœ°ä¸‹è½½ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ kcctl resource list å‘½ä»¤æŸ¥çœ‹æœ¬åœ°å¯ç”¨é…ç½®åŒ…ï¼Œæˆ–ä½¿ç”¨ kcctl resource push å‘½ä»¤ä¸Šä¼ æ‰€éœ€é…ç½®åŒ…ã€‚\né•œåƒæ‹‰å–æ–¹å¼ï¼šä»å¡«å†™çš„é•œåƒä»“åº“æ‹‰å–ï¼Œç»„ä»¶å°†é»˜è®¤ç»§æ‰¿è¯¥ä»“åº“åœ°å€ï¼Œè¯·ç¡®ä¿è¯¥ä»“åº“å­˜åœ¨ç›¸å…³ç»„ä»¶é•œåƒï¼›ç»„ä»¶ä¹Ÿä¼šæä¾›ç‹¬ç«‹çš„é•œåƒä»“åº“å‚æ•°ï¼Œè®¾ç½®åç»„ä»¶é•œåƒä»è¯¥åœ°å€æ‹‰å–ã€‚kubeclipper æä¾› Docker Registry æ–¹æ¡ˆï¼Œå¹¶ä½¿ç”¨ kcctl registry å‘½ä»¤è¡Œè¿›è¡Œç®¡ç†ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–è‡ªæœ‰é•œåƒä»“åº“ã€‚ kubernetes ç‰ˆæœ¬ï¼šæŒ‡å®šé›†ç¾¤ kubernetes ç‰ˆæœ¬ã€‚å½“æ‚¨é€‰æ‹©ç¦»çº¿å®‰è£…çš„æ—¶å€™ï¼Œå¯ä»¥ä»å½“å‰ç¯å¢ƒä¸­é…ç½®åŒ…çš„ kubernetes ç‰ˆæœ¬ä¸­é€‰æ‹©ï¼›å½“æ‚¨é€‰æ‹©åœ¨çº¿å®‰è£…çš„æ—¶å€™ï¼Œå¯ä»¥ä» kubeclipper å®˜æ–¹æ¨èçš„ç‰ˆæœ¬ä¸­é€‰æ‹©ã€‚\nETCD æ•°æ®ç›®å½•ï¼šå¯æŒ‡å®š ETCD æ•°æ®ç›®å½•ï¼Œé»˜è®¤ä¸º/var/lib/etcdã€‚\nkubelet æ•°æ®ç›®å½•ï¼šå¯æŒ‡å®š kubelet æ•°æ®ç›®å½•ï¼Œé»˜è®¤ä¸º /var/lib/kubeletã€‚\nCertSANsï¼škubernetes é›†ç¾¤ ca è¯ä¹¦ç­¾åçš„ ip æˆ–è€…åŸŸåï¼Œå¯å¡«å†™å¤šä¸ªã€‚\nå®¹å™¨è¿è¡Œæ—¶ï¼šæ ¹æ®æŒ‡å®š kubernetes ç‰ˆæœ¬ï¼Œkubernetes ç‰ˆæœ¬åœ¨ v1.20.0 ä¹‹å‰ï¼Œå®¹å™¨è¿è¡Œæ—¶é»˜è®¤ dockerï¼Œä¹‹åé»˜è®¤ containerdï¼›v1.24.0 ä¹‹åä¸æ”¯æŒ dockerã€‚\nå®¹å™¨è¿è¡Œæ—¶ç‰ˆæœ¬ï¼šæŒ‡å®š containerd / docker ç‰ˆæœ¬ã€‚ä¸ kubernetes ç›¸åŒï¼Œå½“æ‚¨é€‰æ‹©ç¦»çº¿å®‰è£…çš„æ—¶å€™ï¼Œå¯ä»¥ä»å½“å‰ç¯å¢ƒä¸­é…ç½®åŒ…çš„ç‰ˆæœ¬ä¸­é€‰æ‹©ï¼›å½“æ‚¨é€‰æ‹©åœ¨çº¿å®‰è£…çš„æ—¶å€™ï¼Œå¯ä»¥ä» kubeclipper å®˜æ–¹æ¨èçš„ç‰ˆæœ¬ä¸­é€‰æ‹©ã€‚\nContainerd æ•°æ®ç›®å½•ï¼šå¯å¡«å†™ config.toml é…ç½®ä¸­çš„ root dirï¼Œé»˜è®¤ä¸º/var/lib/containerdã€‚\nDocker æ•°æ®ç›®å½•ï¼šå¯å¡«å†™ daemon.json é…ç½®ä¸­çš„ root dirï¼Œé»˜è®¤ä¸º/var/lib/dockerã€‚\nContainerd é•œåƒä»“åº“ï¼šå­˜æ”¾ containerd é•œåƒçš„ä»“åº“åœ°å€ï¼Œconfig.toml é…ç½®ä¸­çš„ registry.mirrorsï¼Œå¯å¡«å†™å¤šä¸ªã€‚\nDocker é•œåƒä»“åº“ï¼šå­˜æ”¾ docker é•œåƒçš„ä»“åº“åœ°å€ï¼Œdaemon.json é…ç½®ä¸­çš„ insecure registry,å¯å¡«å†™å¤šä¸ªã€‚\nDNS åŸŸåï¼škubernetes é›†ç¾¤çš„åŸŸåï¼Œé»˜è®¤ä¸º cluster.localã€‚\nWorker è´Ÿè½½ IPï¼šç”¨äº worker èŠ‚ç‚¹åˆ°å¤š master çš„è´Ÿè½½å‡è¡¡ï¼Œå•ä¸€ master ä¸éœ€è¦è®¾ç½®ã€‚\nå¤–éƒ¨è®¿é—® IPï¼šå¯ä»¥å¡«å†™ä¸€ä¸ªæµ®åŠ¨ IP ç»™ç”¨æˆ·è®¿é—®ï¼Œå¯ä¸ºç©ºã€‚\nå¤‡ä»½ç©ºé—´ï¼šé›†ç¾¤å¤‡ä»½æ–‡ä»¶å­˜å‚¨ä½ç½®ã€‚\nCNI é…ç½® å½“å‰ç‰ˆæœ¬ä»…æ”¯æŒ Calico ä½œä¸ºé›†ç¾¤ CNIã€‚\nCalico å°†ç”¨æˆ·è®¾ç½®çš„ pod cidr åˆ†ä¸ºè‹¥å¹²ä¸ª block (ç½‘æ®µ)ï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚åŠ¨æ€çš„åˆ†é…ç»™éœ€è¦çš„èŠ‚ç‚¹ï¼Œå¹¶åœ¨èŠ‚ç‚¹ä¸­é€šè¿‡ bgp peer ç»´æŠ¤é›†ç¾¤èŠ‚ç‚¹çš„è·¯ç”±è¡¨ã€‚\nä¾‹å¦‚ï¼šå®¹å™¨çš„åœ°å€æ± ï¼š172.25.0.0/16ï¼ŒåŠ¨æ€åˆ†é…çš„ç½‘æ®µæ± : 172.25.0.0 - 172.25.255.192 (172.25.0.0/26 å³ 10 ä¸ªæ¯”ç‰¹ä½)ï¼ŒåŠ¨æ€åˆ†é…çš„ç½‘æ®µæ•°: 1023ï¼Œæ¯ä¸ªç½‘æ®µçš„ pod æ•°é‡ä¸º: 61 (193-254)ï¼Œæ€» pod æ•°é‡ä¸º1023 * 61 = 62403ï¼Œç›¸å¯¹æœ€å¤§èŠ‚ç‚¹æ•°(æŒ‰ç…§200ä¸šåŠ¡ pod ä¸ºåŸºå‡†å€¼)ï¼š312ã€‚\nç›®å‰ä¸å»ºè®®å¤§äº50ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤ï¼Œå¤§äº50ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤å»ºè®®æ‰‹åŠ¨é…ç½® route reflectionï¼Œç”¨æ¥ä¼˜åŒ–é›†ç¾¤ä¸­çš„èŠ‚ç‚¹çš„è·¯ç”±è¡¨ç»´æŠ¤çš„ç¨³å®šæ€§ã€‚\nä½¿ç”¨ Calico ä½œä¸ºé›†ç¾¤ CNIï¼Œæ‚¨éœ€è¦è¿›è¡Œä»¥ä¸‹é…ç½®ï¼š\nCalico æ¨¡å¼ï¼šæ”¯æŒ5ç§ç½‘ç»œæ¨¡å¼ï¼š\nOverlay-IPIP-All: ä½¿ç”¨ IP-in-IP æŠ€æœ¯æ‰“é€šä¸åŒèŠ‚ç‚¹çš„ pod çš„ç½‘ç»œ,é€šå¸¸è¿™æ ·çš„æ–¹å¼ä½¿ç”¨åœ¨åº•å±‚å¹³å°æ˜¯ iaas çš„ç¯å¢ƒä¹‹ä¸­,å½“ç„¶å¦‚æœä½ åº•å±‚ç½‘è·¯ç¯å¢ƒç›´æ¥æ˜¯ç‰©ç†è®¾å¤‡çš„ä¹Ÿå®Œå…¨å¯ä»¥ä½¿ç”¨åªä¸è¿‡æ•ˆç‡å’Œçµæ´»åº¦éƒ½ä¼šå¤§æ‰“æŠ˜æ‰£,éœ€è¦æ³¨æ„çš„æ˜¯ä½ éœ€è¦ç¡®è®¤åº•å±‚ç½‘ç»œç¯å¢ƒ(underlay)æ˜¯æ”¯æŒ IPIP åè®®çš„.(ä½¿ç”¨ overlay çš„ç½‘ç»œæ–¹å¼å¯¹ç½‘ç»œæ€§èƒ½é€ æˆä¸€å®šçš„å½±å“)ã€‚ Overlay-Vxlan-All: ä½¿ç”¨ IP-in-IP æŠ€æœ¯æ‰“é€šä¸åŒèŠ‚ç‚¹çš„ pod çš„ç½‘ç»œ,é€šå¸¸è¿™æ ·çš„æ–¹å¼ä½¿ç”¨åœ¨åº•å±‚å¹³å°æ˜¯ iaas çš„ç¯å¢ƒä¹‹ä¸­,å½“ç„¶å¦‚æœä½ åº•å±‚ç½‘è·¯ç¯å¢ƒç›´æ¥æ˜¯ç‰©ç†è®¾å¤‡çš„ä¹Ÿå®Œå…¨å¯ä»¥ä½¿ç”¨åªä¸è¿‡æ•ˆç‡å’Œçµæ´»åº¦éƒ½ä¼šå¤§æ‰“æŠ˜æ‰£,ä»–ç†è®ºä¸Šå¯ä»¥åœ¨ä»»ä½•çš„ç½‘ç»œç¯å¢ƒä¸Šè¿è¡Œ,é€šå¸¸åœ¨åº•å±‚ç¯å¢ƒä¸æ”¯æŒ IPIP åè®®çš„æ—¶å€™æˆ‘ä»¬ä¼šä½¿ç”¨ä»–.(ä½¿ç”¨ overlay çš„ç½‘ç»œæ–¹å¼å¯¹ç½‘ç»œæ€§èƒ½é€ æˆä¸€å®šçš„å½±å“)ã€‚ BGP: ä½¿ç”¨ IP-in-IP æŠ€æœ¯æ‰“é€šä¸åŒèŠ‚ç‚¹çš„ pod çš„ç½‘ç»œ,é€šå¸¸è¿™æ ·çš„æ–¹å¼ä½¿ç”¨åœ¨è£¸æœºçš„ç¯å¢ƒä¸Š,å½“ç„¶åº• Iaas å¹³å°æ”¯æŒ BGP çš„è¯ä¹Ÿæ˜¯å¯ä»¥ä½¿ç”¨çš„,è¿™ç§æ¨¡å¼ä¸‹ pod çš„ ip é€šä¿¡æ˜¯é€šè¿‡ é›†ç¾¤ä¸­çš„å„ä¸ªèŠ‚ç‚¹ä¸­äº’ç›¸äº¤æ¢è·¯ç”±è¡¨æ¥å®Œæˆ pod ä¹‹é—´çš„é€šä¿¡çš„,å¦‚æœä½ éœ€è¦æ‰‹åŠ¨æ‰“é€šå¤šä¸ªé›†ç¾¤ä¹‹é—´çš„ pod ç½‘ç»œéœ€è¦æ³¨æ„ä½ åˆ†é…çš„åœ°å€æ–­ä¸åº”è¯¥æœ‰å†²çªã€‚ Overaly-IPIP-Cross-Subnet: ä½¿ç”¨ IP-in-IP æŠ€æœ¯æ‰“é€šä¸åŒèŠ‚ç‚¹çš„ pod çš„ç½‘ç»œ,é€šå¸¸è¿™æ ·çš„æ–¹å¼ä½¿ç”¨åœ¨åº•å±‚å¹³å°æ˜¯ iaas çš„ç¯å¢ƒä¹‹ä¸­,éœ€è¦æ³¨æ„çš„æ˜¯ä½ éœ€è¦ç¡®è®¤åº•å±‚ç½‘ç»œç¯å¢ƒ(underlay)æ˜¯æ”¯æŒ IPIP åè®®çš„.å’Œ Overlay-IPIP-All çš„ä¸åŒä¹‹å¤„åœ¨äº,å¦‚æœ 2 ä¸ªä¸åŒèŠ‚ç‚¹ä½†åœ¨åŒä¸€ä¸ªç½‘æ®µä¸­çš„ä¸Š pod äº’ç›¸é€šä¿¡æ—¶æ˜¯é€šè¿‡è·¯ç”±è¡¨,è¿™æ ·å¯ä»¥æé«˜åœ¨ä¸åŒèŠ‚ç‚¹ä½†åœ¨åŒä¸€ä¸ªç½‘æ®µä¸­çš„ä¸Š pod äº’ç›¸é€šä¿¡æ—¶çš„æ•ˆç‡ã€‚ Overaly-Vxlan-Cross-Subnet: å’Œ Overaly-IPIP-Cross-Subnet é€»è¾‘ç›¸ä¼¼ä¸å†åšé‡å¤çš„è§£é‡Šã€‚ Calico ç‰ˆæœ¬ï¼šæŒ‡å®š calico ç‰ˆæœ¬ã€‚ä¸ kubernetes ç›¸åŒï¼Œå½“æ‚¨é€‰æ‹©ç¦»çº¿å®‰è£…çš„æ—¶å€™ï¼Œå¯ä»¥ä»å½“å‰ç¯å¢ƒä¸­é…ç½®åŒ…çš„ç‰ˆæœ¬ä¸­é€‰æ‹©ï¼›å½“æ‚¨é€‰æ‹©åœ¨çº¿å®‰è£…çš„æ—¶å€™ï¼Œå¯ä»¥ä» kubeclipper å®˜æ–¹æ¨èçš„ç‰ˆæœ¬ä¸­é€‰æ‹©ã€‚\nIPç‰ˆæœ¬ï¼šå¯æŒ‡å®š IP ç‰ˆæœ¬ä¸º IPV4 æˆ– IPV4 IPV6 åŒæ ˆã€‚\næœåŠ¡å­ç½‘ï¼šå¡«å†™ service å­ç½‘ CIDRï¼Œv4 é»˜è®¤ä¸ºï¼š10.96.0.0/16ï¼Œv6 é»˜è®¤ä¸º fd03::/112ï¼Œæ³¨æ„ Service ç½‘ç»œä¸å¾—ä¸ä»»ä½•ä¸»æœºç½‘ç»œé‡å ã€‚\nPod CIDRï¼šå¡«å†™ Pod å­ç½‘ CIDRï¼Œv4 é»˜è®¤ï¼š172.25.0.0/24ï¼Œv6 é»˜è®¤ä¸º fd05::/120ï¼Œæ³¨æ„ Pod ç½‘ç»œä¸å¾—ä¸ä»»ä½•ä¸»æœºç½‘ç»œé‡å ã€‚\npodç½‘è·¯çš„åº•å±‚ï¼š\nfirst-foundï¼ˆé»˜è®¤ï¼‰ï¼šç¨‹åºä¼šæ ¹æ® ipfamily (v4 æˆ– v6)éå†æ‰€æœ‰çš„æœ‰æ•ˆçš„ ip åœ°å€ï¼ˆlocal,loop backï¼Œdocker bridgeç­‰ä¼šè¢«è‡ªåŠ¨æ’é™¤ï¼‰é€šå¸¸å¦‚æœæ˜¯å¤šç½‘å¡æ—¶ä¼šæ’é™¤é»˜è®¤ç½‘å…³ä»¥å¤–çš„ç½‘å¡çš„ ip ä½œä¸ºèŠ‚ç‚¹ä¹‹é—´çš„è·¯ç”±åœ°å€ã€‚ can-reachï¼šé€šè¿‡æ£€æŸ¥åŸŸåæˆ–è€… ip çš„å¯è¾¾æ€§æ¥è®¾ç½®èŠ‚ç‚¹ä¹‹é—´çš„è·¯ç”±åœ°å€ã€‚ interfaceï¼šæ ¹æ®æ­£åˆ™è¡¨è¾¾å¼è·å–æ‰€æœ‰æ»¡è¶³çš„ç½‘å¡è®¾å¤‡åç§°å¹¶è¿”å›ç¬¬ä¸€ä¸ªæ»¡è¶³è¡¨è¾¾å¼ç½‘å¡çš„åœ°å€ä½œä¸ºèŠ‚ç‚¹ä¹‹é—´çš„è·¯ç”±åœ°å€ã€‚ MTUï¼šä¸º Calico ç¯å¢ƒé…ç½®æœ€å¤§ä¼ è¾“å•å…ƒ(MTU)ï¼Œå»ºè®®ä¸å¤§äº1440ï¼Œé»˜è®¤ä¸º1440ï¼Œè¯¦æƒ…è§ https://docs.projectcalico.org/networking/mtuã€‚\nå­˜å‚¨é…ç½® Kubeclipperå½“å‰ç‰ˆæœ¬å†…ç½®äº† NFS ä½œä¸ºé›†ç¾¤å¤–æ¥å­˜å‚¨ã€‚\nå¯¹æ¥ NFS ç±»å‹çš„å¤–æ¥å­˜å‚¨ï¼Œæ‚¨éœ€è¦è®¾ç½®ä»¥ä¸‹å†…å®¹ï¼š\nå­—æ®µ ä½œç”¨è¯´æ˜ å¡«å†™è¯´æ˜/å¯é€‰é¡¹ æœåŠ¡åœ°å€ ServerAddrï¼ŒNFSçš„æœåŠ¡åœ°å€ å¿…å¡« å…±äº«è·¯å¾„ SharedPathï¼ŒNFSçš„æœåŠ¡æŒ‚è½½è·¯å¾„ å¿…å¡« å­˜å‚¨ç±» StorageClassNameï¼Œå­˜å‚¨ç±»çš„åç§° é»˜è®¤ä¸º nfs-scï¼Œå¯è‡ªå®šä¹‰åç§°ï¼Œä¸å¯ä¸é›†ç¾¤å…¶ä»–å­˜å‚¨ç±»é‡å¤ å›æ”¶ç­–ç•¥ ReclaimPolicyï¼ŒVPCå›æ”¶ç­–ç•¥ åˆ é™¤ Delete / ä¿ç•™ Retain æŒ‚è½½é€‰é¡¹ MountOptionsï¼ŒNFS çš„ options å‚æ•°ï¼Œå¦‚nfsvers=3 é€‰å¡«ï¼Œå¯å¡«å†™å¤šä¸ª å‰¯æœ¬æ•° Replicasï¼ŒNFS provisionerå‰¯æœ¬æ•° é»˜è®¤ä¸º1 è®¾ç½®å®Œå¤–æ¥å­˜å‚¨åï¼Œä¸‹æ–¹å¡ç‰‡ä¼šæ˜¾ç¤ºæ‚¨å·²ç»å¼€å¯çš„å­˜å‚¨ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä¸€ä¸ªå­˜å‚¨ç±»ä½œä¸ºé»˜è®¤å­˜å‚¨ï¼Œå¯¹äºæœªæŒ‡å®šç‰¹å®šStorageClass çš„ PVC ï¼Œä¼šç›´æ¥ä½¿ç”¨é»˜è®¤çš„å­˜å‚¨ç±»ã€‚\né…ç½®ç¡®è®¤ æ‚¨å¯ä»¥åœ¨é…ç½®ç¡®è®¤é¡µé¢æµè§ˆé›†ç¾¤çš„é…ç½®ä¿¡æ¯ï¼Œç¡®è®¤æ— è¯¯åï¼Œç‚¹å‡»â€œç¡®è®¤â€œæŒ‰é’®ã€‚ä¹Ÿå¯ä»¥ç‚¹å‡»å¡ç‰‡å³ä¾§çš„â€œç¼–è¾‘â€æŒ‰é’®ï¼Œè·³å›åˆ°ç›¸åº”æ­¥éª¤ä¿®æ”¹é›†ç¾¤ä¿¡æ¯ã€‚\nå®‰è£…é›†ç¾¤å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œæ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µé¢æŸ¥çœ‹æ“ä½œæ—¥å¿—ï¼Œè·Ÿè¸ªé›†ç¾¤å®‰è£…çŠ¶æ€ã€‚\nè®¾ç½®å›½å†…é•œåƒä»£ç†ï¼ˆå¯é€‰ï¼‰ Q: è®¾ç½®å›½å†…é•œåƒä»£ç†æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ\nA: è®¾ç½®äº†å›½å†…é•œåƒä»£ç†ï¼Œä½¿ç”¨åœ¨çº¿å®‰è£…åŠŸèƒ½æ—¶ï¼Œä¼šä»æŒ‡å®šä»£ç†æ‹‰å– kubernetes ç›¸å…³é•œåƒï¼Œé¿å…åœ¨å›½å†…æ— æ³•è®¿é—® gcr è€Œå¯¼è‡´é›†ç¾¤å®‰è£…å¤±è´¥é—®é¢˜ã€‚\nä»¥ä¸‹è®¾ç½®æ–¹æ³•éœ€åœ¨æ‰§è¡Œ kcctl deploy éƒ¨ç½²å‘½ä»¤çš„æœºå™¨ä¸Šå®Œæˆï¼Œä»»é€‰å…¶ä¸€å³å¯ã€‚\n**æ–¹å¼ä¸€ï¼š**è®¾ç½® KC_IMAGE_REPO_MIRROR ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰\n# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæ¨èä½¿ç”¨é˜¿é‡Œäº‘é•œåƒä»£ç†ï¼Œæ‚¨ä¹Ÿå¯ä»¥è‡ªè¡Œè®¾å®š export KC_IMAGE_REPO_MIRROR=\"registry.aliyuncs.com/google_containers\" **æ–¹å¼äºŒï¼š**è®¾ç½® /etc/kc/kc.env ç¯å¢ƒå˜é‡æ–‡ä»¶\n# åˆ›å»º kc ç›®å½• mkdir -pv /etc/kc # åˆ›å»º kc.env æ–‡ä»¶å¹¶ä¼ å…¥ç¯å¢ƒå˜é‡ä¿¡æ¯ cat \u003c\u003cEOF \u003e /etc/kc/kc.env KC_IMAGE_REPO_MIRROR=\"registry.aliyuncs.com/google_containers\" EOF ","categories":"","description":"KubeClipper æ”¯æŒé€šè¿‡å‘å¯¼å¼é¡µé¢åˆ›å»º kubernetes é›†ç¾¤ï¼Œå¹¶å®‰è£… CNIã€CSI ç­‰æ‰€éœ€æ’ä»¶ã€‚\n","excerpt":"KubeClipper æ”¯æŒé€šè¿‡å‘å¯¼å¼é¡µé¢åˆ›å»º kubernetes é›†ç¾¤ï¼Œå¹¶å®‰è£… CNIã€CSI ç­‰æ‰€éœ€æ’ä»¶ã€‚\n","ref":"/docs/tutorials/create-clusters/","tags":"","title":"åˆ›å»ºé›†ç¾¤"},{"body":" For the first contact with KubeClipper, it is recommended to deploy AIO environment and quickly get started to experience the features provided by KubeClipper. If you want to apply KubeClipper to a build environment, then this document may be helpful.\nOverview According to the KubeClipper architecture design, KubeClipper has the following 4 core components:\nKc-server: mainly includes APISERVER, controller, static resource services and built-in message queue, etc., kc-server communicates with kc-agent through message queue (supports external); kc-server has no master-slave relationship and is independent of each other; usually deployed in independent nodes to provide stable and reliable services to the outside world. Kc-agent: mainly includes the task processor, which is responsible for receiving the tasks delivered by the kc-server and feeding back the task processing results; usually deployed in nodes that need to install kubernetes, it is an ultra-lightweight service process. Kc-etcd: The backend database of kc-server, deployed on the same node as kc-server. Kc-dashboard: graphical management interface, deployed on the same node with kc-server. To sum up, we call the node that deploys kc-server as server, and the node that deploys kc-agent as agent. Then the key point of deploying a highly available KubeClipper cluster is how to plan and deploy server nodes while ensuring the high availability of kc-etcd.\nGenerally speaking, for deploying highly available distributed application clusters, it is basically recommended to have at least 3 nodes; also for KubeClipper, 3 nodes can ensure that kc-server can still provide services after 2 nodes Downtime, and can ensure that kc-etcd will not appear Split-Brain exception.\nThe above brief introduction to the KubeClipper architecture and core components is to better understand how to deploy a highly available KubeClipper cluster, so as to lead to thinking about server node planning and Hardware configuration requirements.\nRecommended configuration KubeClipper as an extremely lightweight Kubernetes multi-cluster full lifecycle management tool, itself will not take up too many resources.\nserver node\nQuantity: 3 and more Hardware requirements: CPU \u003e = 2 cores, RAM \u003e = 2GB, hard disk \u003e = 20GB System: CentOS 7.x/Ubuntu 18.04/Ubuntu 20.04 Agent node\nQuantity: any Hardware requirements: according to actual needs System: CentOS 7.x/Ubuntu 18.04/Ubuntu 20.04 Start by installing kcctl Kcctl is a command line tool provided by KubeClipper that enables rapid deployment of KubeClipper clusters and most Kuberneters cluster management features to simplify operations.\nInstall kcctl:\n# The latest release is installed by default curl -sfL https://oss.kubeclipper.io/kcctl.sh | bash - # Install the specified version curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=v1.3.1 bash - # If you are in China, you can specify the KC_REGION environment variable during installation, at this time we will use registry.aliyuncs.com/google_containers instead of k8s.gcr.io # This is very useful for online installation of k8s cluster curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn bash - After the installation is successful, the installation version and installation Path will be output.\nYou can also download the GitHub Release Page download the specified kcctl version\nVerify installation:\nkcctl version -o json kcctl version: { \"major\": \"1\", \"minor\": \"3\", \"gitVersion\": \"v1.3.1\", \"gitCommit\": \"5f19dcf78d3a9dc2d1035a779152fa993e0553df\", \"gitTreeState\": \"clean\", \"buildDate\": \"2022-12-02T10:12:36Z\", \"goVersion\": \"go1.19.2\", \"compiler\": \"gc\", \"platform\": \"linux/amd64\" } # View help documentation kcctl -h Learn about the kcctl deploy command The kcctl deploy -h command is specially used to deploy KubeClipper cluster, for more examples and parameter explanation, please execute kcctl deploy -h\nIntroduction to common parameters\nâ€“Server: IP server node, such as 192.168.10.10, 192.168.10.11, IP separated by commas. â€“Agent: Agent node IP, such as 192.168.10.10, 192.168.10.11, IP separated by commas. â€“Pk-file: ssh password-free login private key, it is recommended to use password-free login on the command line. â€“User: ssh login username, default is root. â€“Passwd: ssh login password, it is not recommended to use the password to log in at the command line. â€“Pkg: Installation package Path, support local Path and online link; get online installation package link rules: https://oss.kubeclipper.io/release/ {KC_VERSION}/kc- {GOARCH} .tar.gz . KC_VERSION for Release Version default setting current kcctl corresponding version, GOARCH is amd64 or arm64, default setting current kcctl Compilation architecture. â€“Ip-detect: Node IP discovery rules, support a variety of rules, such as specifying the name of the network interface card, etc., very useful for multiple network interface card nodes, the default is â€œfirst-foundâ€. After understanding the basic usage of kcctl deploy, letâ€™s start deploying the KubeClipper cluster.\nDeploy KubeClipper with kcctl We recommend that in the multi-node installation scenario, the server nodes involved are uniformly set up password-free login to avoid password Plain Text leakage.\nDeploy 3 server nodes with private key:\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --pkg https://oss.kubeclipper.io/release/{KC_VERSION}/kc-{GOARCH}.tar.gz Deploy 3 server + 3 agent nodes in private key mode, specify pkg:\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --agent AGENT_IPS \\ --pkg https://oss.kubeclipper.io/release/{KC_VERSION}/kc-{GOARCH}.tar.gz Deploy 3 server + 3 agent nodes with private key, pkg is not specified, and the default is the same as the installed version of kcctl (recommended):\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --agent AGENT_IPS Private key deployment 3 server + 3 agent node, specify etcd port, default port is client-12379 | peer-12380 | metrics-12381 :\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --agent AGENT_IPS \\ --etcd-port 12379 --etcd-peer-port 12380 --etcd-metric-port 12381 Parameter input example:\nSERVER_IPS: 192.168.10.20,192.168.10.21\nAGENT_IPS: 192.168.10.30,192.168.10.31\nKC_VERSION : KubeClipper release version, see GitHub Release Page\nGOARCH System Architecture, AMD64 (aka x84_64), ARM64 (aka AARCH 64)\nKcctl deploy supports a variety of parameters, which can meet your specific needs for deploying KubeClipper clusters, and more functions are waiting for you to explore.\nAfter executing the kcctl deploy command, the command will detect whether your environment meets the installation requirements, and will synchronize warning messages, installation progress, etc. to the Console. Finally, the following KubeClipper banner will be printed after the installation is successful:\n_ __ _ _____ _ _ | | / / | | / __ \\ (_) | |/ / _ _| |__ ___| / \\/ |_ _ __ _ __ ___ _ __ | \\| | | | '_ \\ / _ \\ | | | | '_ \\| '_ \\ / _ \\ '__| | |\\ \\ |_| | |_) | __/ \\__/\\ | | |_) | |_) | __/ | \\_| \\_/\\__,_|_.__/ \\___|\\____/_|_| .__/| .__/ \\___|_| | | | | |_| |_| System default management account: admin/Thinkbig1 Login to Console: Open a browser and visit http://SERVER_IP (accessible through any Server node) to enter the KubeClipper Console\nLogin command line:\nkcctl login -H http://SERVER_IP -u admin -p Thinkbig1 Most kcctl commands rely on login status, so itâ€™s best to log in early when you execute the cli command.\nAdd agent node to KubeClipper using kcctl The current kcctl join command only supports adding agent nodes, and will gradually support adding server nodes in the future.\nNewly added agent nodes should also be uniformly set up password-free login, and the private key is the same.\nJoin agent node:\nkcctl join --agent=AGENT_IPS Remove agent node from KubeClipper using kcctl The current kcctl drain command only supports deleting agent nodes, and will gradually support deleting server nodes in the future.\nDrain agent node:\nkcctl drain --agent=AGENT_IPS # Force drain node, ignore errors kcctl drain --agent=AGENT_IPS --force If you find that KubeClipper cannot be successfully deployed according to this document, please move to the KubeClipper Github Issue to provide your comments or feedback.\n","categories":"","description":"Rapidly deploy highly available, production-ready KubeClipper clusters\n","excerpt":"Rapidly deploy highly available, production-ready KubeClipper clusters\n","ref":"/en/docs/deployment-docs/ha-deploy/","tags":"","title":"Deploy Highly Available KubeClipper"},{"body":"","categories":["Examples","Placeholders"],"description":"Quickly build the experience platform function\n","excerpt":"Quickly build the experience platform function\n","ref":"/en/docs/getting-started/","tags":["test","docs"],"title":"Getting Started"},{"body":"å¯¹äºåˆæ¬¡æ¥è§¦ KubeClipper å¹¶æƒ³å¿«é€Ÿä¸Šæ‰‹çš„ç”¨æˆ·ï¼Œå»ºè®®ä½¿ç”¨ AIOï¼ˆå³ All-in-Oneï¼Œä½¿ç”¨å•ä¸ªèŠ‚ç‚¹å®‰è£… KubeClipperï¼‰æ¨¡å¼ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©æ‚¨é›¶é…ç½®å¿«é€Ÿéƒ¨ç½² KubeClipperã€‚\néƒ¨ç½² KubeClipper ä¸‹è½½å¹¶å®‰è£… kcctl KubeClipper æä¾›äº†å‘½ä»¤è¡Œå·¥å…·ğŸ”§ kcctl ä»¥ç®€åŒ–è¿ç»´å·¥ä½œï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½æœ€æ–°ç‰ˆ kcctlï¼š\n# é»˜è®¤å®‰è£…æœ€æ–°çš„å‘è¡Œç‰ˆ curl -sfL https://oss.kubeclipper.io/kcctl.sh | bash - # å®‰è£…æŒ‡å®šç‰ˆæœ¬ curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=v1.3.1 bash - # å¦‚æœæ‚¨åœ¨ä¸­å›½ï¼Œ æ‚¨å¯ä»¥åœ¨å®‰è£…æ—¶ä½¿ç”¨ cn ç¯å¢ƒå˜é‡, æ­¤æ—¶ KubeClipper ä¼šä½¿ç”¨ registry.aliyuncs.com/google_containers ä»£æ›¿ k8s.gcr.io curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn bash - æ‚¨ä¹Ÿå¯ä»¥åœ¨ GitHub Release Page ä¸‹è½½æŒ‡å®šç‰ˆæœ¬ã€‚\nå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤éªŒè¯ kcctl æ˜¯å¦å®‰è£…æˆåŠŸ:\n# å¦‚æœä¸€åˆ‡é¡ºåˆ©ï¼Œæ‚¨å°†çœ‹åˆ° kcctl ç‰ˆæœ¬ä¿¡æ¯ kcctl version å¼€å§‹å®‰è£… æ‚¨å¯ä»¥ä½¿ç”¨ kcctl deploy å¿«é€Ÿå®‰è£…éƒ¨ç½² KubeClipperã€‚kcctl ä½¿ç”¨ SSH è®¿é—®æœ€ç»ˆéƒ¨ç½² KubeClipper çš„ç›®æ ‡èŠ‚ç‚¹ï¼Œå› æ­¤éœ€è¦æ‚¨æä¾› SSH è®¿é—®å‡­è¯ï¼Œä¼ é€’å‡­è¯çš„æ–¹æ³•å¦‚ä¸‹ï¼š\nKcctl deploy [--user \u003cusername\u003e] [--passwd \u003cpassword\u003e | --pk-file \u003cprivate key path\u003e] ç¤ºä¾‹ï¼š\n# ä½¿ç”¨ç§é’¥ kcctl deploy --user root --pk-file /root/.ssh/id_rsa # ä½¿ç”¨å¯†ç  kcctl deploy --user root --passwd password æ‰§è¡Œ kcctl deploy å‘½ä»¤ kcctl å°†ä¼šæ£€æŸ¥æ‚¨çš„å®‰è£…ç¯å¢ƒï¼Œè‹¥æ»¡è¶³æ¡ä»¶å°†è‡ªåŠ¨è¿›å…¥å®‰è£…æµç¨‹ã€‚è‹¥æ‚¨çœ‹åˆ°å¦‚ä¸‹ KubeClipper banner åå³è¡¨ç¤ºå®‰è£…æˆåŠŸã€‚\n_ __ _ _____ _ _ | | / / | | / __ \\ (_) | |/ / _ _| |__ ___| / \\/ |_ _ __ _ __ ___ _ __ | \\| | | | '_ \\ / _ \\ | | | | '_ \\| '_ \\ / _ \\ '__| | |\\ \\ |_| | |_) | __/ \\__/\\ | | |_) | |_) | __/ | \\_| \\_/\\__,_|_.__/ \\___|\\____/_|_| .__/| .__/ \\___|_| | | | | |_| |_| æ‚¨ä¹Ÿå¯ä»¥éƒ¨ç½² master ç‰ˆæœ¬çš„ KubeClipperï¼Œæ¥ä½“éªŒæœ€æ–°çš„åŠŸèƒ½ç‰¹æ€§ï¼ˆmaster ç‰ˆæœ¬æ²¡æœ‰ç»è¿‡ä¸¥æ ¼éªŒè¯ï¼Œå¯èƒ½åŒ…å«å½±å“ä½“éªŒçš„æœªçŸ¥é”™è¯¯ï¼‰\nå®‰è£… master ç‰ˆæœ¬ kcctl curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=master bash - åœ¨å®‰è£…æœåŠ¡å™¨ä¸Šè®¾ç½®ç¯å¢ƒå˜é‡ export KC_VERSION=master ä»¥ AIO æ–¹å¼éƒ¨ç½² KubeClipper kcctl deploy ç™»å½•æ§åˆ¶å° å®‰è£…å®Œæˆåï¼Œæ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® http://\u003ckc-server ip address\u003e å³å¯è¿›å…¥ KubeClipper æ§åˆ¶å°ã€‚(é€šå¸¸ kc-server ip æ˜¯æ‚¨éƒ¨ç½² kubeClipper èŠ‚ç‚¹çš„ ip)\næ‚¨å¯ä»¥ä½¿ç”¨é»˜è®¤å¸å·å¯†ç  admin / Thinkbig1 è¿›è¡Œç™»å½•ã€‚\næ‚¨å¯èƒ½éœ€è¦é…ç½®ç«¯å£è½¬å‘è§„åˆ™å¹¶åœ¨å®‰å…¨ç»„ä¸­å¼€æ”¾ç«¯å£ï¼Œä»¥ä¾¿å¤–éƒ¨ç”¨æˆ·è®¿é—®æ§åˆ¶å°ã€‚\nåˆ›å»º Kubernetes é›†ç¾¤ éƒ¨ç½²æˆåŠŸåæ‚¨å¯ä»¥ä½¿ç”¨ kcctl å·¥å…·æˆ–è€…é€šè¿‡æ§åˆ¶å°åˆ›å»º Kubernetes é›†ç¾¤ã€‚åœ¨æœ¬å¿«é€Ÿå…¥é—¨æ•™ç¨‹ä¸­ä½¿ç”¨ kcctl å·¥å…·è¿›è¡Œåˆ›å»ºã€‚\né¦–å…ˆä½¿ç”¨é»˜è®¤å¸å·å¯†ç è¿›è¡Œç™»å½•è·å– tokenï¼Œä¾¿äºåç»­ kcctl å’Œ kc-server è¿›è¡Œäº¤äº’ã€‚\nkcctl login -H http://\u003ckc-server ip address\u003e:8080 -u admin -p Thinkbig1 é€šè¿‡ä»¥ä¸‹å‘½ä»¤åˆ›å»º Kubernetes é›†ç¾¤:\nNODE=$(kcctl get node -o yaml|grep ipv4DefaultIP:|sed 's/ipv4DefaultIP: //') kcctl create cluster --master $NODE --name demo --untaint-master å¤§æ¦‚ 3 åˆ†é’Ÿå·¦å³å³å¯å®Œæˆé›†ç¾¤åˆ›å»º,æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹é›†ç¾¤çŠ¶æ€\nkcctl get cluster -o yaml|grep status -A5 æ‚¨ä¹Ÿå¯ä»¥è¿›å…¥æ§åˆ¶å°æŸ¥çœ‹å®æ—¶æ—¥å¿—ã€‚\né›†ç¾¤å¤„äº Running çŠ¶æ€å³è¡¨ç¤ºé›†ç¾¤å®‰è£…å®Œæˆ,æ‚¨å¯ä»¥ä½¿ç”¨ kubectl get cs å‘½ä»¤æ¥æŸ¥çœ‹é›†ç¾¤å¥åº·çŠ¶å†µã€‚\n","categories":["QuickStart"],"description":"éƒ¨ç½² AIO ç¯å¢ƒ\n","excerpt":"éƒ¨ç½² AIO ç¯å¢ƒ\n","ref":"/docs/getting-started/aio-env/","tags":["aio","sample","docs"],"title":"éƒ¨ç½² AIO"},{"body":" å¯¹äºåˆæ¬¡æ¥è§¦ KubeClipperï¼Œå»ºè®®éƒ¨ç½² AIO ç¯å¢ƒï¼Œå¿«é€Ÿä¸Šæ‰‹ä½“éªŒ KubeClipper æä¾›çš„åŠŸèƒ½ç‰¹æ€§ã€‚ å¯¹äºæƒ³å°† KubeClipper åº”ç”¨åˆ°ç”Ÿæˆç¯å¢ƒï¼Œé‚£ä¹ˆæœ¬æ–‡æ¡£æˆ–è®¸å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚\næ¦‚è¿° æ ¹æ® KubeClipper æ¶æ„è®¾è®¡å¯çŸ¥ï¼ŒKubeClipper æœ‰ä»¥ä¸‹ 4 ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š\nkc-serverï¼šä¸»è¦åŒ…æ‹¬ APISERVER ã€æ§åˆ¶å™¨ã€é™æ€èµ„æºæœåŠ¡ä»¥åŠå†…ç½®æ¶ˆæ¯é˜Ÿåˆ—ç­‰ï¼Œkc-server é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆæ”¯æŒå¤–ç½®ï¼‰ä¸ kc-agent é€šä¿¡ï¼›kc-server ä¹‹é—´æ— ä¸»ä»å…³ç³»ï¼Œä¸”ç›¸äº’ç‹¬ç«‹ï¼›é€šå¸¸éƒ¨ç½²åœ¨ç‹¬ç«‹çš„èŠ‚ç‚¹ï¼Œä»è€Œå¯¹å¤–æä¾›ç¨³å®šå¯é çš„æœåŠ¡ã€‚ kc-agentï¼šä¸»è¦åŒ…æ‹¬ä»»åŠ¡å¤„ç†å™¨ï¼Œè´Ÿè´£æ¥æ”¶ kc-server æŠ•é€’çš„ä»»åŠ¡ï¼Œå¹¶åé¦ˆä»»åŠ¡å¤„ç†ç»“æœï¼›é€šå¸¸éƒ¨ç½²åœ¨éœ€è¦å®‰è£… kubernetes çš„èŠ‚ç‚¹ï¼Œæ˜¯ä¸€ä¸ªè¶…è½»é‡çº§çš„æœåŠ¡è¿›ç¨‹ã€‚ kc-etcdï¼škc-server çš„åç«¯æ•°æ®åº“ï¼Œè·Ÿéš kc-server éƒ¨ç½²åœ¨åŒä¸€èŠ‚ç‚¹ä¸Šã€‚ kc-dashboardï¼šå›¾å½¢åŒ–ç®¡ç†ç•Œé¢ï¼Œè·Ÿéš kc-server éƒ¨ç½²åœ¨åŒä¸€èŠ‚ç‚¹ã€‚ ç»¼ä¸Šï¼Œæˆ‘ä»¬å°†éƒ¨ç½² kc-server çš„èŠ‚ç‚¹ç§°ä¸º serverï¼Œéƒ¨ç½² kc-agent çš„èŠ‚ç‚¹ç§°ä¸º agentã€‚ é‚£ä¹ˆéƒ¨ç½²é«˜å¯ç”¨ KubeClipper é›†ç¾¤çš„å…³é”®ç‚¹ï¼Œå°±åœ¨äºå¦‚ä½•è§„åˆ’éƒ¨ç½² server èŠ‚ç‚¹åŒæ—¶ä¿è¯ kc-etcd çš„é«˜å¯ç”¨ã€‚ é€šå¸¸æ¥çœ‹ï¼Œå¯¹äºéƒ¨ç½²é«˜å¯ç”¨çš„åˆ†å¸ƒå¼åº”ç”¨é›†ç¾¤ï¼ŒåŸºæœ¬å»ºè®®èŠ‚ç‚¹è‡³å°‘ 3 ä¸ªï¼›åŒæ ·å¯¹äº KubeClipperï¼Œ3 ä¸ªèŠ‚ç‚¹èƒ½ä¿è¯ kc-server åœ¨å…¶ä¸­ 2 ä¸ªèŠ‚ç‚¹å®•æœºåä¾æ—§å¯ä»¥æä¾›æœåŠ¡ï¼ŒåŒæ—¶èƒ½ä¿è¯ kc-etcd ä¸ä¼šå‡ºç°è„‘è£‚å¼‚å¸¸ã€‚\nä»¥ä¸Šç®€å•ä»‹ç»äº† KubeClipper æ¶æ„ä»¥åŠæ ¸å¿ƒç»„ä»¶ï¼Œæ˜¯ä¸ºäº†æ›´å¥½çš„ç†è§£è¯¥å¦‚ä½•éƒ¨ç½²é«˜å¯ç”¨ KubeClipper é›†ç¾¤ï¼Œä»è€Œå¼•å‡ºå…³äºå¯¹æœåŠ¡å™¨èŠ‚ç‚¹è§„åˆ’ä»¥åŠç¡¬ä»¶é…ç½®è¦æ±‚çš„æ€è€ƒã€‚\næ¨èé…ç½® KubeClipper ä½œä¸ºä¸€ä¸ªæè½»é‡çš„ Kubernetes å¤šé›†ç¾¤å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å·¥å…·ï¼Œæœ¬èº«ä¸ä¼šå ç”¨å¤ªå¤šèµ„æº\nserver èŠ‚ç‚¹\næ•°é‡ï¼š3 ä¸ªåŠä»¥ä¸Š ç¡¬ä»¶è¦æ±‚ï¼šCPU \u003e= 2 æ ¸ï¼Œå†…å­˜ \u003e= 2GBï¼Œç¡¬ç›˜ \u003e= 20GB ç³»ç»Ÿï¼šCentOS 7.x / Ubuntu 18.04 / Ubuntu 20.04 agent èŠ‚ç‚¹\næ•°é‡ï¼šä»»æ„ ç¡¬ä»¶è¦æ±‚ï¼šä¾æ®å®é™…éœ€æ±‚è€Œå®š ç³»ç»Ÿï¼šCentOS 7.x / Ubuntu 18.04 / Ubuntu 20.04 ä»å®‰è£… kcctl å¼€å§‹ kcctl æ˜¯ KubeClipper æä¾›çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œå®ƒæ”¯æŒå¿«é€Ÿéƒ¨ç½² KubeClipper é›†ç¾¤ä»¥åŠå¤§éƒ¨åˆ† Kuberneters é›†ç¾¤ç®¡ç†åŠŸèƒ½ï¼Œç”¨ä»¥ç®€åŒ–è¿ç»´å·¥ä½œã€‚\nå®‰è£… kcctlï¼š\n# é»˜è®¤å®‰è£…æœ€æ–°å‘è¡Œç‰ˆ curl -sfL https://oss.kubeclipper.io/kcctl.sh | bash - # å®‰è£…æŒ‡å®šç‰ˆæœ¬ curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=v1.3.1 bash - # å¦‚æœæ‚¨åœ¨ä¸­å›½ï¼Œæ‚¨å¯ä»¥åœ¨å®‰è£…æ—¶æŒ‡å®š KC_REGION ç¯å¢ƒå˜é‡ï¼Œæ­¤æ—¶æˆ‘ä»¬ä¼šä½¿ç”¨ registry.aliyuncs.com/google_containers ä»£æ›¿ k8s.gcr.io # è¿™å¯¹äºåœ¨çº¿å®‰è£… k8s é›†ç¾¤éå¸¸æœ‰ç”¨ curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn bash - å®‰è£…æˆåŠŸåï¼Œä¼šè¾“å‡ºå®‰è£…ç‰ˆæœ¬ä»¥åŠå®‰è£…è·¯å¾„ç­‰ä¿¡æ¯ã€‚\næ‚¨ä¹Ÿå¯ä»¥åœ¨ GitHub Release Page ä¸‹è½½æŒ‡å®šçš„ kcctl ç‰ˆæœ¬\néªŒè¯å®‰è£…ï¼š\nkcctl version -o json kcctl version: { \"major\": \"1\", \"minor\": \"3\", \"gitVersion\": \"v1.3.1\", \"gitCommit\": \"5f19dcf78d3a9dc2d1035a779152fa993e0553df\", \"gitTreeState\": \"clean\", \"buildDate\": \"2022-12-02T10:12:36Z\", \"goVersion\": \"go1.19.2\", \"compiler\": \"gc\", \"platform\": \"linux/amd64\" } # æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£ kcctl -h äº†è§£ kcctl deploy å‘½ä»¤ kcctl deploy å‘½ä»¤æ˜¯ä¸“é—¨ç”¨äºéƒ¨ç½² KubeClipper é›†ç¾¤ï¼Œæ›´å¤šç¤ºä¾‹ä»¥åŠå‚æ•°è§£é‡Šè¯·æ‰§è¡Œ kcctl deploy -h\nå¸¸ç”¨å‚æ•°ç®€ä»‹\nâ€“server: server èŠ‚ç‚¹ IPï¼Œä¾‹å¦‚ 192.168.10.10,192.168.10.11ï¼Œå¤šä¸ª IP ä»¥é€—å·éš”å¼€ã€‚ â€“agent: agent èŠ‚ç‚¹ IPï¼Œä¾‹å¦‚ 192.168.10.10,192.168.10.11ï¼Œå¤šä¸ª IP ä»¥é€—å·éš”å¼€ã€‚ â€“pk-file: ssh å…å¯†ç™»å½•ç§é’¥ï¼Œæ¨èåœ¨å‘½ä»¤è¡Œä½¿ç”¨å…å¯†ç™»å½•ã€‚ â€“user: ssh ç™»å½•ç”¨æˆ·åï¼Œé»˜è®¤ä¸º rootã€‚ â€“passwd: ssh ç™»å½•å¯†ç ï¼Œä¸æ¨èåœ¨å‘½ä»¤è¡Œä½¿ç”¨å¯†ç ç™»å½•ã€‚ â€“pkg: å®‰è£…åŒ…è·¯å¾„ï¼Œæ”¯æŒæœ¬åœ°è·¯å¾„ä»¥åŠåœ¨çº¿é“¾æ¥ï¼›è·å–åœ¨çº¿å®‰è£…åŒ…é“¾æ¥è§„åˆ™ï¼šhttps://oss.kubeclipper.io/release/{KC_VERSION}/kc-{GOARCH}.tar.gz ã€‚KC_VERSION ä¸º Release Version é»˜è®¤è®¾ç½®å½“å‰ kcctl å¯¹åº”ç‰ˆæœ¬ï¼ŒGOARCH ä¸º amd64 æˆ– arm64ï¼Œé»˜è®¤è®¾ç½®å½“å‰ kcctl çš„ç¼–è¯‘æ¶æ„ã€‚ â€“ip-detect: èŠ‚ç‚¹ ip å‘ç°è§„åˆ™ï¼Œæ”¯æŒå¤šç§è§„åˆ™ï¼Œä¾‹å¦‚æŒ‡å®šç½‘å¡åç§°ç­‰ï¼Œå¯¹äºå¤šç½‘å¡èŠ‚ç‚¹éå¸¸æœ‰ç”¨ï¼Œé»˜è®¤ä¸º â€œfirst-foundâ€ã€‚ äº†è§£å®Œ kcctl deploy çš„åŸºç¡€ä½¿ç”¨ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥å°±å¼€å§‹éƒ¨ç½² KubeClipper é›†ç¾¤å§ã€‚\nä½¿ç”¨ kcctl éƒ¨ç½² KubeClipper æˆ‘ä»¬æ¨èåœ¨å¤šèŠ‚ç‚¹å®‰è£…åœºæ™¯ä¸­ï¼Œå°†æ¶‰åŠåˆ°çš„æœåŠ¡å™¨èŠ‚ç‚¹éƒ½ç»Ÿä¸€è®¾ç½®å…å¯†ç™»å½•ï¼Œé¿å…å¯†ç æ˜æ–‡æ³„éœ²ã€‚\nç§é’¥æ–¹å¼éƒ¨ç½² 3 server èŠ‚ç‚¹ï¼š\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --pkg https://oss.kubeclipper.io/release/{KC_VERSION}/kc-{GOARCH}.tar.gz ç§é’¥æ–¹å¼éƒ¨ç½² 3 server + 3 agent èŠ‚ç‚¹ï¼ŒæŒ‡å®š pkgï¼š\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --agent AGENT_IPS \\ --pkg https://oss.kubeclipper.io/release/{KC_VERSION}/kc-{GOARCH}.tar.gz ç§é’¥æ–¹å¼éƒ¨ç½² 3 server + 3 agent èŠ‚ç‚¹ï¼ŒæœªæŒ‡å®š pkgï¼Œé»˜è®¤ä¸ kcctl å®‰è£…ç‰ˆæœ¬ä¸€è‡´ï¼ˆæ¨èï¼‰ï¼š\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --agent AGENT_IPS ç§é’¥æ–¹å¼éƒ¨ç½² 3 server + 3 agent èŠ‚ç‚¹ï¼ŒæŒ‡å®š etcd ç«¯å£ï¼Œé»˜è®¤ç«¯å£ä¸º client-12379 | peer-12380 | metrics-12381ï¼š\nkcctl deploy --pk-file=~/.ssh/id_rsa \\ --server SERVER_IPS \\ --agent AGENT_IPS \\ --etcd-port 12379 --etcd-peer-port 12380 --etcd-metric-port 12381 å‚æ•°è¾“å…¥ç¤ºä¾‹ï¼š\nSERVER_IPS: 192.168.10.20,192.168.10.21\nAGENT_IPS: 192.168.10.30,192.168.10.31\nKC_VERSION: KubeClipper çš„ release versionï¼ŒæŸ¥çœ‹ GitHub Release Page è·å–\nGOARCHï¼šç³»ç»Ÿæ¶æ„ï¼Œamd64 ï¼ˆåˆå x84_64ï¼‰ï¼Œarm64ï¼ˆåˆå aarch64ï¼‰\nkcctl deploy æ”¯æŒå¤šç§å‚æ•°ï¼Œèƒ½å¤Ÿæ»¡è¶³æ‚¨å¯¹éƒ¨ç½² KubeClipper é›†ç¾¤çš„ç‰¹å®šéœ€æ±‚ï¼Œæ›´å¤šåŠŸèƒ½ç­‰æ‚¨æ¢ç´¢ã€‚\nåœ¨æ‰§è¡Œ kcctl deploy å‘½ä»¤åï¼Œå‘½ä»¤ä¼šæ£€æµ‹æ‚¨çš„ç¯å¢ƒæ˜¯å¦ç¬¦åˆå®‰è£…è¦æ±‚ï¼Œä¼šå°†è­¦å‘Šä¿¡æ¯ã€å®‰è£…è¿›åº¦ç­‰åŒæ­¥è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œæœ€ååœ¨å®‰è£…æˆåŠŸåä¼šæ‰“å°å¦‚ä¸‹ KubeClipper bannerï¼š\n_ __ _ _____ _ _ | | / / | | / __ \\ (_) | |/ / _ _| |__ ___| / \\/ |_ _ __ _ __ ___ _ __ | \\| | | | '_ \\ / _ \\ | | | | '_ \\| '_ \\ / _ \\ '__| | |\\ \\ |_| | |_) | __/ \\__/\\ | | |_) | |_) | __/ | \\_| \\_/\\__,_|_.__/ \\___|\\____/_|_| .__/| .__/ \\___|_| | | | | |_| |_| ç³»ç»Ÿé»˜è®¤ç®¡ç†è´¦å·ï¼šadmin / Thinkbig1\nç™»å½•æ§åˆ¶å°ï¼š æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® http://SERVER_IP ï¼ˆé€šè¿‡ä»»æ„ä¸€ä¸ª Server èŠ‚ç‚¹å‡å¯è®¿é—®ï¼‰å³å¯è¿›å…¥ KubeClipper æ§åˆ¶å°\nç™»å½•å‘½ä»¤è¡Œï¼š\nkcctl login -H http://SERVER_IP -u admin -p Thinkbig1 å¤§å¤šæ•° kcctl å‘½ä»¤éƒ½ä¾èµ–ç™»å½•çŠ¶æ€ï¼Œå› æ­¤æœ€å¥½åœ¨æ‰§è¡Œ cli å‘½ä»¤æ—¶æå‰ç™»å½•ã€‚\nä½¿ç”¨ kcctl æ·»åŠ  agent èŠ‚ç‚¹åˆ° KubeClipper å½“å‰ kcctl join å‘½ä»¤ä»…æ”¯æŒæ·»åŠ  agent èŠ‚ç‚¹ï¼Œåç»­ä¼šé€æ­¥æ”¯æŒæ·»åŠ  server èŠ‚ç‚¹ã€‚ æ–°åŠ å…¥çš„ agent èŠ‚ç‚¹ä¹Ÿåº”è¯¥ç»Ÿä¸€è®¾ç½®å…å¯†ç™»å½•ï¼Œä¸”ç§é’¥ç›¸åŒã€‚\nJoin agent èŠ‚ç‚¹ï¼š\nkcctl join --agent=AGENT_IPS ä½¿ç”¨ kcctl ä» KubeClipper ä¸­åˆ é™¤ agent èŠ‚ç‚¹ å½“å‰ kcctl drain å‘½ä»¤ä»…æ”¯æŒåˆ é™¤ agent èŠ‚ç‚¹ï¼Œåç»­ä¼šé€æ­¥æ”¯æŒåˆ é™¤ server èŠ‚ç‚¹ã€‚\nDrain agent èŠ‚ç‚¹ï¼š\nkcctl drain --agent=AGENT_IPS # å¼ºåˆ¶ drain èŠ‚ç‚¹ï¼Œå¿½ç•¥é”™è¯¯ kcctl drain --agent=AGENT_IPS --force å¦‚æœæ‚¨å‘ç°æ ¹æ®æœ¬æ–‡æ¡£æ— æ³•æˆåŠŸéƒ¨ç½² KubeClipperï¼Œè¯·ç§»æ­¥ KubeClipper Github Issueï¼Œæå‡ºæ‚¨çš„æ„è§æˆ–åé¦ˆã€‚\n","categories":"","description":"å¿«é€Ÿéƒ¨ç½²é«˜å¯ç”¨ã€ç”Ÿäº§å°±ç»ªçš„ KubeClipper é›†ç¾¤\n","excerpt":"å¿«é€Ÿéƒ¨ç½²é«˜å¯ç”¨ã€ç”Ÿäº§å°±ç»ªçš„ KubeClipper é›†ç¾¤\n","ref":"/docs/deployment-docs/ha-deploy/","tags":"","title":"éƒ¨ç½²é«˜å¯ç”¨ KubeClipper"},{"body":"å¯¹äºåˆæ¬¡æ¥è§¦ KubeClipper å¹¶æƒ³å¿«é€Ÿä¸Šæ‰‹çš„ç”¨æˆ·ï¼Œå»ºè®®ä½¿ç”¨ All-in-One å®‰è£…æ¨¡å¼ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©æ‚¨é›¶é…ç½®å¿«é€Ÿéƒ¨ç½² KubeClipperã€‚\nå‡†å¤‡å·¥ä½œ KubeClipper æœ¬èº«å¹¶ä¸ä¼šå ç”¨å¤ªå¤šèµ„æºï¼Œä½†æ˜¯ä¸ºäº†åç»­æ›´å¥½çš„è¿è¡Œ Kubernetes å»ºè®®ç¡¬ä»¶é…ç½®ä¸ä½äºæœ€ä½è¦æ±‚ã€‚\næ‚¨ä»…éœ€å‚è€ƒä»¥ä¸‹å¯¹æœºå™¨ç¡¬ä»¶å’Œæ“ä½œç³»ç»Ÿçš„è¦æ±‚å‡†å¤‡ä¸€å°ä¸»æœºã€‚\nç¡¬ä»¶æ¨èé…ç½® ç¡®ä¿æ‚¨çš„æœºå™¨æ»¡è¶³æœ€ä½ç¡¬ä»¶è¦æ±‚ï¼šCPU \u003e= 2 æ ¸ï¼Œå†…å­˜ \u003e= 2GBã€‚ æ“ä½œç³»ç»Ÿï¼šCentOS 7.x / Ubuntu 18.04 / Ubuntu 20.04ã€‚ èŠ‚ç‚¹è¦æ±‚ èŠ‚ç‚¹å¿…é¡»èƒ½å¤Ÿé€šè¿‡ SSH è¿æ¥ã€‚ èŠ‚ç‚¹ä¸Šå¯ä»¥ä½¿ç”¨ sudo / curl / wget / tar å‘½ä»¤ã€‚ å»ºè®®æ‚¨çš„æ“ä½œç³»ç»Ÿå¤„äºå¹²å‡€çŠ¶æ€ï¼ˆä¸å®‰è£…ä»»ä½•å…¶ä»–è½¯ä»¶ï¼‰ï¼Œå¦åˆ™å¯èƒ½ä¼šå‘ç”Ÿå†²çªã€‚\néƒ¨ç½² KubeClipper ä¸‹è½½ kcctl KubeClipper æä¾›äº†å‘½ä»¤è¡Œå·¥å…·ğŸ”§ kcctl ä»¥ç®€åŒ–è¿ç»´å·¥ä½œï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½æœ€æ–°ç‰ˆ kcctlï¼š\n# curl -sfL https://oss.kubeclipper.io/kcctl.sh | bash - # å¦‚æœä½ åœ¨ä¸­å›½ï¼Œ ä½ å¯ä»¥åœ¨å®‰è£…æ—¶ä½¿ç”¨ cn ç¯å¢ƒå˜é‡, æ­¤æ—¶æˆ‘ä»¬ä¼šä½¿ç”¨ registry.aliyuncs.com/google_containers ä»£æ›¿ k8s.gcr.io curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn bash - æ‚¨ä¹Ÿå¯ä»¥åœ¨ GitHub Release Page ä¸‹è½½æŒ‡å®šç‰ˆæœ¬ã€‚\né€šè¿‡ä»¥ä¸‹å‘½ä»¤æ£€æµ‹æ˜¯å¦å®‰è£…æˆåŠŸ:\nkcctl version å¼€å§‹å®‰è£… åœ¨æœ¬å¿«é€Ÿå…¥é—¨æ•™ç¨‹ä¸­ï¼Œæ‚¨åªéœ€æ‰§è¡Œä¸€ä¸ªå‘½ä»¤å³å¯å®‰è£… KubeClipperï¼Œå…¶æ¨¡æ¿å¦‚ä¸‹æ‰€ç¤ºï¼š\nkcctl deploy è‹¥ä½¿ç”¨ ssh passwd æ–¹å¼åˆ™å‘½ä»¤å¦‚ä¸‹æ‰€ç¤º:\nkcctl deploy --user root --passwd $SSH_PASSWD ç§é’¥æ–¹å¼å¦‚ä¸‹ï¼š\nkcctl deploy --user root --pk-file $SSH_PRIVATE_KEY æ‚¨åªéœ€è¦æä¾› ssh user ä»¥åŠ ssh passwd æˆ–è€… ssh ç§é’¥å³å¯åœ¨æœ¬æœºéƒ¨ç½² KubeClipperã€‚\næ‰§è¡Œè¯¥å‘½ä»¤åï¼ŒKcctl å°†æ£€æŸ¥æ‚¨çš„å®‰è£…ç¯å¢ƒï¼Œè‹¥æ»¡è¶³æ¡ä»¶å°†ä¼šè¿›å…¥å®‰è£…æµç¨‹ã€‚åœ¨æ‰“å°å‡ºå¦‚ä¸‹çš„ KubeClipper banner åå³è¡¨ç¤ºå®‰è£…å®Œæˆã€‚\n_ __ _ _____ _ _ | | / / | | / __ \\ (_) | |/ / _ _| |__ ___| / \\/ |_ _ __ _ __ ___ _ __ | \\| | | | '_ \\ / _ \\ | | | | '_ \\| '_ \\ / _ \\ '__| | |\\ \\ |_| | |_) | __/ \\__/\\ | | |_) | |_) | __/ | \\_| \\_/\\__,_|_.__/ \\___|\\____/_|_| .__/| .__/ \\___|_| | | | | |_| |_| ç™»å½•æ§åˆ¶å° å®‰è£…å®Œæˆåï¼Œæ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® http://$IP å³å¯è¿›å…¥ KubeClipper æ§åˆ¶å°ã€‚\næ‚¨å¯ä»¥ä½¿ç”¨é»˜è®¤å¸å·å¯†ç  admin / Thinkbig1 è¿›è¡Œç™»å½•ã€‚\næ‚¨å¯èƒ½éœ€è¦é…ç½®ç«¯å£è½¬å‘è§„åˆ™å¹¶åœ¨å®‰å…¨ç»„ä¸­å¼€æ”¾ç«¯å£ï¼Œä»¥ä¾¿å¤–éƒ¨ç”¨æˆ·è®¿é—®æ§åˆ¶å°ã€‚\nåˆ›å»º kubernetes é›†ç¾¤ éƒ¨ç½²æˆåŠŸåæ‚¨å¯ä»¥ä½¿ç”¨ kcctl å·¥å…·æˆ–è€…é€šè¿‡æ§åˆ¶å°åˆ›å»º kubernetes é›†ç¾¤ã€‚åœ¨æœ¬å¿«é€Ÿå…¥é—¨æ•™ç¨‹ä¸­ä½¿ç”¨ kcctl å·¥å…·è¿›è¡Œåˆ›å»ºã€‚\né¦–å…ˆä½¿ç”¨é»˜è®¤å¸å·å¯†ç è¿›è¡Œç™»å½•è·å– tokenï¼Œä¾¿äºåç»­ kcctl å’Œ kc-server è¿›è¡Œäº¤äº’ã€‚\nkcctl login -H http://localhost -u admin -p Thinkbig1 ç„¶åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åˆ›å»º kubernetes é›†ç¾¤:\nNODE=$(kcctl get node -o yaml|grep ipv4DefaultIP:|sed 's/ipv4DefaultIP: //') kcctl create cluster --master $NODE --name demo --untaint-master å¤§æ¦‚ 3 åˆ†é’Ÿå·¦å³å³å¯å®Œæˆé›†ç¾¤åˆ›å»º,ä¹Ÿå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹é›†ç¾¤çŠ¶æ€\nkcctl get cluster -o yaml|grep status -A5 æ‚¨ä¹Ÿå¯ä»¥è¿›å…¥æ§åˆ¶å°æŸ¥çœ‹å®æ—¶æ—¥å¿—ã€‚\nè¿›å…¥ Running çŠ¶æ€å³è¡¨ç¤ºé›†ç¾¤å®‰è£…å®Œæˆ,æ‚¨å¯ä»¥ä½¿ç”¨ kubectl get cs å‘½ä»¤æ¥æŸ¥çœ‹é›†ç¾¤å¥åº·çŠ¶å†µã€‚\n","categories":["QuickStart"],"description":"å¿«é€Ÿæ­å»ºä½“éªŒå¹³å°åŠŸèƒ½\n","excerpt":"å¿«é€Ÿæ­å»ºä½“éªŒå¹³å°åŠŸèƒ½\n","ref":"/docs/getting-started/","tags":["docs"],"title":"å¿«é€Ÿå¼€å§‹"},{"body":"1. Go to the creation screen Log in to the Kubeclipper platform and click the button as shown in the figure to enter the cluster creation interface\n2. Configure cluster nodes Follow the text prompts to complete the steps of entering the cluster name and selecting nodes\nNote: The number of master nodes cannot be an even number.\n3. Configure cluster This step is used to configure the cluster network and components such as the database and container runtime\nSelect offline installation and fill in the address of the image repository you have built first\n4. Configure cluster storage Select nfs storage and follow the text prompts to fill in the appropriate fields\n5. Installation completed Complete all configurations to confirm installation\nInstallation is successful and the cluster is up and running\n","categories":"","description":"How to create a kubernetes cluster offline using the KC platform\n","excerpt":"How to create a kubernetes cluster offline using the KC platform\n","ref":"/en/docs/getting-started/carete-k8s-cluster-offline/","tags":"","title":"Create kubernetes clusters offline using the kubeclipper platform"},{"body":"Kubeadm cluster hosting For a host cluster created and managed by kubeadm, kubeclipper gets the cluster and node information from the kubeconfig file and imports it into the kubeclipper platform.\nClick â€œCluster Managementâ€ \u003e â€œCluster Hostingâ€ button to enter the cluster hosting page. Click â€œAddâ€ button at the upper left corner. In the pop-up window of Add Provider, fill in the provider name (such as kubeadm-demo) and description, and then fill in the following information:\nRegion: The region of the cluster and node in the kubeclipper platform.\nProvider type: Select kubeadm.\nSSH: Specifies the connection method of cluster nodes. Private Key or Password can be selected. Ensure that all cluster nodes can be connected through the selected method.\nPrivate Key: enter the node user name and private key information. Password: enter the node user name and password. Cluster name: Specifies the display name on the platform and cannot be the same as any other clusters.\nKubeConfig: The KubeConfig file of the host cluster.\nClick the â€œOKâ€ button to import the cluster and node into the platform. Click the provider name (kubeadm-demo) to enter the Provider detail page, where you can view the cluster under the provider and perform the following operations on the provider:\nSynchronization: Kubeclipper synchronizes cluster information every four hours. You can also click â€œSynchronizeâ€ to manually perform the operation. Edit: Edit the providerâ€™s name, description, access information, and node connection method. Remove: Remove the cluster information from kubeclipper, but the cluster will not be uninstalled. Managed cluster management You can choose â€œCluster Managementâ€ \u003e â€œClusterâ€ to go to the cluster list page and view the list of all clusters, including hosted clusters and local clusters. The following table lists the operations supported by different clusters:\nNote that â€œdocker.ioâ€ will be used as image resource by default when you install external storage and other plug-ins for host clusters. If you are in an offline environment, you need to fill in the address of the accessible private registry during plug-in installation. The private registry must be added to the CRI registry of the cluster. For details, refer to CRI Registry.\nFunction Clusters created by Kubeclipper Hosted kubeadm cluster View log âœ” âœ” Retry after failed task âœ” âœ” Access Kubectl âœ” âœ” Edit âœ” âœ” Save as template âœ” âœ˜ CRI Registry âœ” âœ” Add/remove cluster nodes âœ” âœ” Cluster Backup and Recovery âœ” âœ” Version Upgrade âœ” âœ˜ Delete cluster âœ” âœ˜ Remove cluster (provider) / âœ” Reset status âœ” âœ” Cluster plugin management âœ” âœ” Update cluster certificate âœ” âœ” View kubeconfig file âœ” âœ” ","categories":"","description":"For kubernetes clusters running outside the kubeclipper platform, you can host them within the kubeclipper platform for management. The current version supports host kubeadmin clusters.\n","excerpt":"For kubernetes clusters running outside the kubeclipper platform, you can host them within the kubeclipper platform for management. The current version supports host kubeadmin clusters.\n","ref":"/en/docs/tutorials/cluster-hosting/","tags":"","title":"Cluster hosting"},{"body":"Kubeadm é›†ç¾¤æ‰˜ç®¡ æ‰˜ç®¡ç”± kubeadm åˆ›å»ºå’Œç®¡ç†çš„ kubernetes é›†ç¾¤ï¼Œkubeclipper ä¼šé€šè¿‡ kubeconfig æ–‡ä»¶ï¼Œè·å–é›†ç¾¤å’ŒèŠ‚ç‚¹ä¿¡æ¯ï¼Œå¹¶å¯¼å…¥åˆ° kubeclipper å¹³å°ä¸­ã€‚\nç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé›†ç¾¤æ‰˜ç®¡â€æŒ‰é’®è¿›å…¥é›†ç¾¤æ‰˜ç®¡é¡µé¢ï¼Œç‚¹å‡»å·¦ä¸Šè§’â€œæ·»åŠ â€æŒ‰é’®ï¼Œåœ¨æ·»åŠ æä¾›å•†å¼¹çª—ä¸­ï¼Œå¡«å†™æä¾›å•†åç§°ï¼ˆå¦‚ kubeadm-demoï¼‰å’Œæè¿°åï¼Œå¡«å†™ä»¥ä¸‹ä¿¡æ¯ï¼š\nåŒºåŸŸï¼šæä¾›å•†ä¸‹çš„é›†ç¾¤å’ŒèŠ‚ç‚¹åœ¨ kubeclipper å¹³å°ä¸­çš„æ‰€å±åŒºåŸŸã€‚ æä¾›å•†ç±»å‹ï¼šé€‰æ‹© kubeadmã€‚ èŠ‚ç‚¹è¿æ¥æ–¹å¼ï¼šé›†ç¾¤èŠ‚ç‚¹çš„è¿æ¥æ–¹å¼ï¼Œå¯ä»¥é€‰æ‹©â€œç§é’¥â€æˆ–è€…â€œå¯†ç â€ï¼Œæ‚¨éœ€è¦ç¡®ä¿å¯ä»¥é€šè¿‡æ‰€é€‰æ–¹å¼ ssh åˆ°é›†ç¾¤èŠ‚ç‚¹ã€‚ é€‰æ‹©â€œç§é’¥â€ï¼Œéœ€è¦è¾“å…¥èŠ‚ç‚¹ç”¨æˆ·åå’Œç§é’¥ä¿¡æ¯ã€‚ é€‰æ‹©â€œå¯†ç â€ï¼Œéœ€è¦è¾“å…¥èŠ‚ç‚¹ç”¨æˆ·åå’Œå¯†ç ä¿¡æ¯ã€‚ é›†ç¾¤åç§°ï¼šä½œä¸ºåœ¨æœ¬å¹³å°çš„å±•ç¤ºåç§°ï¼Œä¸èƒ½ä¸å…¶ä»–é›†ç¾¤é‡å¤ã€‚ KubeConfigï¼šæ‰˜ç®¡é›†ç¾¤çš„ KubeConfig æ–‡ä»¶ã€‚ å¡«å†™å®Œæˆåç‚¹å‡»â€œç¡®å®šâ€æŒ‰é’®ï¼Œå°†é›†ç¾¤å’ŒèŠ‚ç‚¹å¯¼å…¥åˆ°å¹³å°ä¸­ã€‚ç‚¹å‡»æä¾›å•†åç§°ï¼ˆkubeadm-demoï¼‰ï¼Œè¿›å…¥æä¾›å•†è¯¦æƒ…é¡µï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æä¾›å•†ä¸‹çš„é›†ç¾¤ï¼Œå¹¶å¯¹æä¾›å•†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nåŒæ­¥ï¼šç³»ç»Ÿå°†æ¯éš”4å°æ—¶å®šæœŸåŒæ­¥é›†ç¾¤ä¿¡æ¯ï¼Œæ‚¨ä¹Ÿå¯ä»¥ç‚¹å‡»â€œåŒæ­¥â€æŒ‰é’®æ‰‹åŠ¨æ‰§è¡Œã€‚ ç¼–è¾‘ï¼šç¼–è¾‘æä¾›å•†çš„åç§°ã€æè¿°ã€è®¿é—®ä¿¡æ¯ã€èŠ‚ç‚¹è¿æ¥æ–¹å¼ã€‚ ç§»é™¤ï¼šç§»é™¤é›†ç¾¤ä¿¡æ¯ï¼Œä½†é›†ç¾¤ä¸ä¼šè¢«å¸è½½ã€‚ æ‰˜ç®¡é›†ç¾¤ç®¡ç† æ‚¨å¯ä»¥ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé›†ç¾¤â€è¿›å…¥é›†ç¾¤åˆ—è¡¨é¡µé¢ï¼ŒæŸ¥çœ‹åŒ…æ‹¬æ‰˜ç®¡é›†ç¾¤å’Œæœ¬åœ°é›†ç¾¤åœ¨å†…çš„æ‰€æœ‰é›†ç¾¤åˆ—è¡¨ï¼Œå¯¹äºä¸åŒé›†ç¾¤ï¼Œæ”¯æŒçš„ç®¡ç†æ“ä½œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š\næ³¨æ„ï¼šæ‰˜ç®¡çš„ kubeadm é›†ç¾¤å®‰è£…æ’ä»¶æˆ–å¤–æ¥å­˜å‚¨çš„é•œåƒæ¥æºä¼šé»˜è®¤ä½¿ç”¨ docker.ioï¼Œå¦‚æœæ‚¨å¤„äºç¦»çº¿ç¯å¢ƒï¼Œéœ€è¦åœ¨å®‰è£…æ’ä»¶æ—¶å¡«å†™å¯è®¿é—®çš„ç¦»çº¿é•œåƒä»“åº“åœ°å€ï¼Œè¯¥ç¦»çº¿é•œåƒä»“åº“çš„åœ°å€éœ€è¦é¢„å…ˆæ·»åŠ åˆ° cri çš„ç§æœ‰é•œåƒä»“åº“é…ç½®ï¼Œå‚è§ CRI é•œåƒä»“åº“é…ç½® ã€‚\nåŠŸèƒ½ Kubeclipper åˆ›å»ºçš„é›†ç¾¤ æ‰˜ç®¡çš„ kubeadm é›†ç¾¤ æŸ¥çœ‹æ—¥å¿— âœ”ï¸ âœ”ï¸ ä»»åŠ¡å¤±è´¥åé‡è¯• âœ”ï¸ âœ”ï¸ è®¿é—® kubectl âœ”ï¸ âœ”ï¸ ç¼–è¾‘ âœ”ï¸ âœ”ï¸ ä¿å­˜ä¸ºæ¨¡ç‰ˆ âœ”ï¸ âœ˜ CRI é•œåƒä»“åº“é…ç½® âœ”ï¸ âœ”ï¸ æ·»åŠ /ç§»é™¤é›†ç¾¤èŠ‚ç‚¹ âœ”ï¸ âœ”ï¸ å¤‡ä»½å’Œæ¢å¤ç®¡ç† âœ”ï¸ âœ”ï¸ ç‰ˆæœ¬å‡çº§ âœ”ï¸ âœ˜ åˆ é™¤é›†ç¾¤ âœ”ï¸ âœ˜ ç§»é™¤é›†ç¾¤ï¼ˆæä¾›å•†ï¼‰ / âœ”ï¸ é‡ç½®çŠ¶æ€ âœ”ï¸ âœ”ï¸ é›†ç¾¤æ’ä»¶ç®¡ç† âœ”ï¸ âœ”ï¸ æ›´æ–°é›†ç¾¤è¯ä¹¦ âœ”ï¸ âœ”ï¸ æŸ¥çœ‹ kubeconfig âœ”ï¸ âœ”ï¸ ","categories":"","description":"å¯¹äºåœ¨ kubeclipper å¹³å°å¤–è¿è¡Œçš„ kubernetes é›†ç¾¤ï¼Œæ‚¨å¯ä»¥æ‰˜ç®¡è‡³ kubeclipper å¹³å°å†…è¿›è¡Œç®¡ç†ï¼Œå½“å‰ç‰ˆæœ¬æ”¯æŒæ‰˜ç®¡ kubeadmin é›†ç¾¤ã€‚\n","excerpt":"å¯¹äºåœ¨ kubeclipper å¹³å°å¤–è¿è¡Œçš„ kubernetes é›†ç¾¤ï¼Œæ‚¨å¯ä»¥æ‰˜ç®¡è‡³ kubeclipper å¹³å°å†…è¿›è¡Œç®¡ç†ï¼Œå½“å‰ç‰ˆæœ¬æ”¯æŒæ‰˜ç®¡ kubeadmin é›†ç¾¤ã€‚\n","ref":"/docs/tutorials/cluster-hosting/","tags":"","title":"é›†ç¾¤æ‰˜ç®¡"},{"body":"","categories":"","description":"Deploying the sample\n","excerpt":"Deploying the sample\n","ref":"/en/docs/deployment-docs/","tags":"","title":"Deployment docs"},{"body":"","categories":"","description":"éƒ¨ç½²ç¤ºä¾‹\n","excerpt":"éƒ¨ç½²ç¤ºä¾‹\n","ref":"/docs/deployment-docs/","tags":"","title":"éƒ¨ç½²æ–‡æ¡£"},{"body":"1. è¿›å…¥åˆ›å»ºç•Œé¢ ç™»å½• Kubeclipper å¹³å°åç‚¹å‡»å¦‚å›¾æ‰€ç¤ºæŒ‰é’®ï¼Œè¿›å…¥é›†ç¾¤åˆ›å»ºç•Œé¢\n2. é…ç½®é›†ç¾¤èŠ‚ç‚¹ æŒ‰ç…§æ–‡å­—æç¤ºå®Œæˆè¾“å…¥é›†ç¾¤åç§°ã€é€‰æ‹©èŠ‚ç‚¹ç­‰æ­¥éª¤\næ³¨æ„: master èŠ‚ç‚¹æ•°é‡ä¸èƒ½ä¸ºå¶æ•°\n3. é…ç½®é›†ç¾¤ æ­¤æ­¥éª¤ç”¨äºé…ç½®é›†ç¾¤ç½‘ç»œä»¥åŠæ•°æ®åº“ã€å®¹å™¨è¿è¡Œæ—¶ç­‰ç»„ä»¶\né€‰æ‹©ç¦»çº¿å®‰è£…å¹¶å¡«å†™é¦–å…ˆæ­å»ºå¥½çš„é•œåƒä»“åº“åœ°å€\n4. é…ç½®å­˜å‚¨ é€‰æ‹© nfs å­˜å‚¨ï¼ŒæŒ‰ç…§æ–‡å­—æç¤ºå¡«å†™ç›¸åº”å†…å®¹\n5. å®‰è£…å®Œæˆ å®Œæˆæ‰€æœ‰é…ç½®ç¡®è®¤å®‰è£…\nå®‰è£…æˆåŠŸï¼Œé›†ç¾¤æ­£å¸¸è¿è¡Œ\n","categories":"","description":"å¦‚ä½•ä½¿ç”¨ KC å¹³å°ç¦»çº¿åˆ›å»º kubernetes é›†ç¾¤\n","excerpt":"å¦‚ä½•ä½¿ç”¨ KC å¹³å°ç¦»çº¿åˆ›å»º kubernetes é›†ç¾¤\n","ref":"/docs/getting-started/carete-k8s-cluster-offline/","tags":"","title":"ä½¿ç”¨ Kubeclipper ç¦»çº¿åˆ›å»º kubernetes é›†ç¾¤"},{"body":"View Cluster operations On the cluster details page, click the \"Operation Log\" tab to see the cluster operation records. Click the \"ViewLog\" button on the right side to inspect the detailed logs of all steps and nodes in the pop-up window. Click the step name on the left to inspect the detailed log of the execution steps.\nDuring the execution of cluster operations, you can inspect real-time log updates to trace the operation execution. For operations that failed to execute, you can also locate error by red dot under the step name, and troubleshoot the cause of the operation failure.\nTry again after failed task If the task failed but you do not need to modify the task parameters after troubleshooting, you can click â€œRetryâ€ on the right of the operation record to retry the task at the breakpoint.\nNote: The retry operation is not universal. You need to determine the cause of the task failure by yourself.\nAfter cluster operation (such as creation, restoration, and upgrade) failure, the cluster status may be displayed as â€œxx failedâ€ and other operations cannot be performed. If the operation can not be retrayed successflly. You need to refer to the O\u0026M document to manually rectify the cluster error, and click More \u003e Cluster Status \u003e Reset Status to reset the cluster to normal status.\nAccess Kubectl The Kubernetes command-line tool, kubectl, allows you to run commands on Kubernetes clusters. You can use kubectl to deploy applications, inspect and manage cluster resources, view logs, and more.\nClick \"More\" \u003e \"Connect Terminal\" in the cluster operation, and you can execute the kubectl commands in the cluster kuebectl pop-up window.\nCluster Settings Edit You can click More \u003e Cluster Settings \u003e Edit on the right of the cluster list to edit the cluster description, backup space, external access IP address, and cluster label information.\nSave as template You can click More \u003e Cluster Settings \u003e Save as Template on the right of the cluster list to save the cluster settings as a template and use it to creat new clusters with similar configurations.\nCRI Registry Docker and Containerd use dockerhub as the default registry. If you need to use other private registry (especially self-signed https registries or http registries), you need to configure CRI registry.\nClick â€œMoreâ€ \u003e â€œCluster Settingsâ€ \u003e â€œCRI Registryâ€ on the right of the cluster page. In the pop-up window configure the required private registry. You can select an existing registry on the platform or temporarily enter the address of a registry. For a self-signed https or http registry, it is recommended to add the registry information on the Cluster Management \u003e Registry in advance.\nCluster node management On the \"Nodes list\" page of the cluster detail page, you can view the list of nodes in the cluster, specification, status and role information of the nodes.\nAdd cluster node When the cluster load is high, you can add nodes to the cluster to expand capacity. Adding nodes operation does not affect the running services.\nOn the cluster detail page, under the Node List tab, click the \"AddNode\" button on the left, select the available nodes in the pop-up window, set the node labels, and click the \"OK\" button. The current version only supports adding worker nodes.\nRemove cluster node On the cluster detail page, under the Node List tab, you can remove a node by clicking the \"Remove\" button on the right of the node. The current version only supports removing worker nodes.\nNote: To remove cluster nodes, you need to pay attention to security issues in production to avoid application interruptions.\nCluster Backup and Recovery The backup of kubernetes cluster by KubeClipper backs up the data of ETCD database, and kubernetes resource object, such as namespaces, deployments, configMaps. The files and data generated by the resource itself are not backed up. For example, the data and files generated by the mysql pod will not be backed up. Similarly, the files under the PV object are not backed up, only the pv object is backed up. The backup function provided by KubeClipper is hot backup, which does not affect cluster usage. While KubeClipper strongly disapproves of backing up during the \"busy period\" of the cluster.\nCreate a backup space Before performing a backup operation, you need to set a backup space for the cluster, that is, set the storage location of the backup files. The storage type of the backup space can be FS storage or S3 storage . Tack the node local storage , NFS storage and MINIO storage as examples:\nNode local storage (only for AIO experimental clusters): Create a storage directory. Connect to the cluster master node terminal ( refer to Connect Nodes Terminal ) and use the mkdir command to create the \"/root/backup\" directory in the master node.\nCreate a backup space. Click \"Cluster Management\" \u003e \"backup space\" to enter the backup space list page, click the \"Create\" button in the upper left corner, in the Create pop-up window, enter \"Backup Space Name\", such as \"local\", select \"StorageType\" as \"FS\", fill in \"backupRootDir\" as \"/root/backup\".\nSet up the cluster backup space. When creating a cluster, select \"backup space\" as \"local\" on the \"Cluster Config\" page, or edit an existing cluster and select \"local\" as the \"backup space\".\nNote: Using a local node to store backup files does not require the introduction of external storage. The disadvantage is that if the local node is damaged, the backup files will also be lost, so it is strongly disapproved in a production environment .\nNFSï¼š Prepare NFS storage. Prepare an NFS service and create a directory on the NFS server to store backup files, such as \"/data/kubeclipper/cluster-backups\".\nMount the storage directory. Connect the cluster master node terminal ( refer to Connect node Terminal ), use the mkdir command to create the \"/data/kubeclipper/cluster-backups\" directory in each master node, and mount it to the /data/kubeclipper/cluster-backups directory of the NFS server.\nCommand example:\nmount -t nfs {NFS\\_IP}:/data/kubeclipper/cluster-backups /opt/kubeclipper/cluster-backups -o proto = tcp -o nolock Create a backup space. Click \"Cluster Management\" \u003e \"Backup Space\" to enter the backup space list page, click the \"Create\" button in the upper left corner, in the Create pop-up window, enter \"Backup Space Name\", such as \"nfs\", select \"StorageType\" as \"FS\", fill in \"backupRootDir\" as \"/opt/kubeclipper/cluster-backups\".\nSet up the cluster backup space. When creating a cluster, select \"backup space\" as \"nfs\" on the \"Cluster Config\" page, or edit an existing cluster and select \"nfs\" as the \"backup space\".\nMINIOï¼š Prepare MINIO storage. Build MINIO services, refer to the official website https://docs.min.io/docs/minio-quickstart-guide.html for the deployment process, or use existing MINIO services.\nCreate a backup space. Click \"Cluster Management\" \u003e \"Backup Space\" to enter the backup space list page, click the \"Create\" button in the upper left corner, in the Create window, enter \"Backup Space Name\", such as \"minio\", select \"Storage Type\" as \"S3\", fill in \"bucket name\", such as \"kubeclipper-backups\", the bucket will be automatically created by kubeclipper, fill in the IP and port number of the MINIO storage service in the first step in \"Endpoint\", fill in the service username and password, click the \"OK\" button.\nSet up the cluster backup space. When creating a cluster, select \"backup space\" as \"minio\" on the \"Cluster Config\" page, or edit an existing cluster and select \"minio\" as the \"backup space\".\nYou can view the list and details of all backup spaces on the \"Cluster Management\"\u003e\"backup spaces\" page and perform the following operations:\nEdit: Edit the backup space description, and the username/password of the S3 type backup space.\nDelete: Delete the backup space. If there are backup files under the backup space, deletion is not allowed.\nCluster backup You can back up your cluster ETCD data by clicking the \"More\" \u003e â€œBackup and recoveryâ€ \u003e \"Backup Cluster\" button in the cluster operation.\nYou can view all backup files of the cluster under the Backup tab on the cluster detail page, and you can perform the following operations for backups:\nEdit: Edit the backup description.\nRestore: Performs a cluster restore operation to restore the cluster to the specified backup state.\nDelete: Deletes the backup file.\nScheduled backup You can also create a scheduled backup task for the cluster, click the \"More\" \u003e â€œBackup and recoveryâ€ \u003e \"Scheduled Backup\" button in the cluster operation, in the Scheduled Backup pop-up window, enter the scheduled backup name, execution type ( repeat / onlyonce) and execution time, and set the number of valid backups for a repeat scheduled backups, and click the \"OK\" button.\nkubeClipper will perform backup tasks for the cluster at the execution time you set, and the backup file will be automatically named \"Cluster Name - Scheduled Backup Name - Random Code\". For repeat scheduled backups, when the number of backup files exceeds the number of valid backup files, kubeClipper will automatically delete the earlier backup files.\nAfter the scheduled backup task is added, you can view the scheduled backup task information on the \"Scheduled Backup\" tab of the cluster detail page, and you can also view the backup files generated by the scheduled backup on the \"Backup\" tab.\nFor scheduled backup tasks, you can also perform the following operations:\nEdit: Edit the execution time of the scheduled backup task and the number of valid backups for repeat scheduled backups.\nEnable/Disable: Disabled scheduled backup tasks are temporarily stopped.\nDelete: Delete a scheduled backup task.\nRestore Cluster If you perform restore operation while the cluster is running, KubeClipper will perform overlay recovery on the cluster, that is, the ETCD data in the backup file, overwriting the existing data .\nYou can click the \"Restore\" button on the right side of the backup under the Backup tab of the cluster detail page; or click the \"More\" \u003e â€œBackup and recoveryâ€ \u003e \"Restore Cluster\" button in the cluster operation, and select the backup to be restored in the Restore Cluster pop-up window. The current cluster can be restored to the specified backup state.\nNote: After the kubernetes version of the cluster is upgraded, it will no longer be possible to restore the cluster to the pre-upgrade backup version.\nCluster Status Cluster version upgrade If the cluster version does not meet the requirements, you can upgrade the kubernetes version of the cluster. Similar to creating a cluster, you need to prepare the configuration package required and the kubernetes image of the target version, upload them to the specified location. For details, refer to Prepare to Create a Cluster.\nClick the \"More\" \u003e â€œCluster statusâ€ \u003e \"Cluster Upgrade\" button of the cluster operation. In the cluster upgrade pop-up window, select the installation method and registry, and select the target upgrade version. The installation method and the configuration of the kubernetes version are the same as those of creating a cluster. For details, please refer to Cluster Configuration Guide.\nCluster upgrades can be performed across minor versions, but upgrades skipped over later versions are not supported. For example, you can upgrade from v1.20.2 to v1.20.13, or from v1.20.x to v1.21.x, but not from v1.20.x to v1.22.x. For version 1.23.x, upgrading to version 1.24.x is not currently supported.\nThe cluster upgrade operation may take a long time. You can view the operation log on the cluster detail page to track the cluster upgrade status.\nDelete cluster You can click â€œMoreâ€ \u003e â€œCluster Statusâ€ \u003e â€œDelete Clusterâ€ on the right of the cluster list to delete the cluster.\nNote that after the cluster is deleted, it cannot be restored. You must perform this operation with great caution. If the cluster is connected to an external storage device, the volumes in the storage class whose reclaim policy is â€œRetainâ€ will be retained. You can access them in other ways or manually delete them. Volumes in the storage class whose reclaim policy is â€œDeleteâ€ will be automatically deleted when the cluster is deleted.\nReset the status After cluster operation (such as creation, restoration, and upgrade) failure, the cluster status may be displayed as â€œxx failedâ€ and other operations cannot be performed. If the operation can not be retrayed successflly. You need to refer to the O\u0026M document to manually rectify the cluster error, and click More \u003e Cluster Status \u003e Reset Status to reset the cluster to normal status.\nCluster plugin management In addition to installing plugins when creating a cluster, you can also install plugins for a running cluster. Taking the installation of storage plugins as an example, click the \"More\" \u003e â€œplugin managementâ€\u003e\"Add Storage\" button in the cluster operation to enter the Add Storage page. You can install NFS plugins for the cluster. The installation configuration is the same as the configuration in cluster creation.\nFor installed plugins, you can view the plugin information on the cluster detail page, and perform the following operations:\nSave as Template: Save the plugin information as a template for use by other clusters Remove plug-in: Uninstalls the cluster plug-in. Cluster certificate management Update cluster certificate The default validity period of the kubernetes cluster certificate is one year. You can view the certificate expiration time in the basic information on the cluster detail page. You can also view the certificate expiration notification in the cluster list the day before the certificate expires. To update the cluster certificate, click â€œMoreâ€ \u003e â€œCluster Certificateâ€ \u003e â€œUpdate Cluster Certificateâ€ in the cluster operation to update all cluster certificates.\nView kubeconfig file You can click â€œMoreâ€ \u003e â€œCluster Certificateâ€ \u003e â€œView KubeConfig Fileâ€ button in the cluster operation to view the cluster kubeconfig file, or click â€œDownloadâ€ button in the pop-up window to download the kubeconfig file.\n","categories":"","description":"kubeclipper supports full lifecycle management for Kubernetes clusters.\n","excerpt":"kubeclipper supports full lifecycle management for Kubernetes clusters.\n","ref":"/en/docs/tutorials/cluster-management/","tags":"","title":"Cluster management"},{"body":"é›†ç¾¤æ“ä½œæ—¥å¿—æŸ¥çœ‹ åœ¨é›†ç¾¤è¯¦æƒ…é¡µé¢ï¼Œç‚¹å‡»â€œæ“ä½œæ—¥å¿—â€æ ‡ç­¾é¡µï¼Œå¯ä»¥æŸ¥çœ‹é›†ç¾¤æ“ä½œæ—¥å¿—åˆ—è¡¨ã€‚ç‚¹å‡»æ“ä½œæ—¥å¿—å³ä¾§â€œæŸ¥çœ‹æ—¥å¿—â€æŒ‰é’®ï¼Œå¯ä»¥åœ¨å¼¹çª—ä¸­æŸ¥çœ‹å…¨éƒ¨æ­¥éª¤å’ŒèŠ‚ç‚¹çš„è¯¦ç»†æ—¥å¿—ã€‚ç‚¹å‡»å·¦ä¾§æ­¥éª¤åç§°ï¼Œå¯æŸ¥çœ‹æ‰§è¡Œæ­¥éª¤è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºã€‚\nåœ¨é›†ç¾¤æ“ä½œæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œç‚¹å‡»æŸ¥çœ‹æ—¥å¿—ï¼Œæ‚¨å¯ä»¥å®æ—¶æŸ¥çœ‹åˆ°æ—¥å¿—æ›´æ–°æ¥è·Ÿè¸ªæ“ä½œæ‰§è¡Œæƒ…å†µã€‚å¯¹äºæ‰§è¡Œå¤±è´¥çš„ä»»åŠ¡ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡æŸ¥çœ‹æ—¥å¿—ï¼Œæ‰¾åˆ°çº¢è‰²åœ†ç‚¹æ ‡æ³¨çš„æ‰§è¡Œæ­¥éª¤å’ŒèŠ‚ç‚¹ï¼Œå¿«é€Ÿå®šä½é”™è¯¯ï¼Œæ’æŸ¥æ“ä½œå¤±è´¥åŸå› ã€‚\nä»»åŠ¡å¤±è´¥åé‡è¯• å¯¹äºä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œä½†æ’æŸ¥é”™è¯¯åŸå› åä¸éœ€è¦ä¿®æ”¹ä»»åŠ¡å‚æ•°çš„æƒ…å†µï¼Œæ‚¨å¯ä»¥ç‚¹å‡»æ“ä½œæ—¥å¿—å³ä¾§çš„â€œä»æ–­ç‚¹å¤„é‡è¯•â€æŒ‰é’®ï¼Œä»æ–­ç‚¹å¤„é‡æ–°æ‰§è¡Œä»»åŠ¡ã€‚\næ³¨æ„ï¼šé‡è¯•æ“ä½œå¹¶ä¸æ˜¯ä¸‡èƒ½çš„ï¼Œæ‚¨éœ€è¦è‡ªè¡Œåˆ¤æ–­ä»»åŠ¡æ‰§è¡Œå¤±è´¥çš„åŸå› ï¼Œå¤„ç†åå¦‚æœä¸éœ€è¦æ›´æ”¹æ‰§è¡Œä»»åŠ¡æ—¶å¡«å†™çš„å‚æ•°ï¼Œå°±å¯ä»¥ç‚¹å‡»é‡è¯•æŒ‰é’®ï¼Œä»é”™è¯¯å¤„é‡æ–°å¼€å§‹æ‰§è¡Œã€‚\né›†ç¾¤æ“ä½œï¼ˆå¦‚åˆ›å»ºã€æ¢å¤ã€å‡çº§ç­‰ï¼‰æ‰§è¡Œå¤±è´¥ï¼Œå¯èƒ½ä¼šå¯¼è‡´é›†ç¾¤çŠ¶æ€æ˜¾ç¤ºä¸ºâ€œxxå¤±è´¥â€å¹¶æ— æ³•æ­£å¸¸æ‰§è¡Œå…¶ä»–æ“ä½œï¼Œå¦‚æœä»æ–­ç‚¹å¤„é‡è¯•ä¹Ÿæ— æ³•æ‰§è¡ŒæˆåŠŸï¼Œæ‚¨å¯ä»¥å‚è€ƒè¿ç»´æ–‡æ¡£ï¼Œæ‰‹åŠ¨ä¿®å¤é›†ç¾¤é—®é¢˜ã€‚é—®é¢˜ä¿®å¤åï¼Œæ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤å³ä¾§â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤çŠ¶æ€â€\u003eâ€œé‡ç½®çŠ¶æ€â€æŒ‰é’®ï¼Œé‡ç½®é›†ç¾¤è‡³æ­£å¸¸çŠ¶æ€ã€‚\nè®¿é—®é›†ç¾¤ kubectl Kubectl æ˜¯ Kubernetes å‘½ä»¤è¡Œå·¥å…·ï¼Œæ‚¨å¯ä»¥ç”¨å®ƒåœ¨ Kubernetes é›†ç¾¤ä¸Šè¿è¡Œå‘½ä»¤ã€‚Kubectl å¯ç”¨äºéƒ¨ç½²åº”ç”¨ã€æŸ¥çœ‹å’Œç®¡ç†é›†ç¾¤èµ„æºã€æŸ¥çœ‹æ—¥å¿—ç­‰ã€‚\næ‚¨å¯ä»¥è®¿é—®è¿è¡Œä¸­é›†ç¾¤çš„ kubectlï¼Œç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€œ\u003eâ€è®¿é—® kubectlâ€ï¼Œå°±å¯ä»¥åœ¨é›†ç¾¤ kuebectl å¼¹çª—ä¸­æ‰§è¡Œ kubectl å‘½ä»¤è¡Œæ“ä½œã€‚\né›†ç¾¤è®¾ç½® ç¼–è¾‘ æ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤åˆ—è¡¨å³ä¾§â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤è®¾ç½®â€\u003eâ€œç¼–è¾‘â€æŒ‰é’®ï¼Œç¼–è¾‘é›†ç¾¤æè¿°ã€å¤‡ä»½ç©ºé—´ã€å¤–éƒ¨è®¿é—® IPã€é›†ç¾¤æ ‡ç­¾ä¿¡æ¯ã€‚\nä¿å­˜ä¸ºæ¨¡ç‰ˆ æ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤åˆ—è¡¨å³ä¾§â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤è®¾ç½®â€\u003eâ€œä¿å­˜ä¸ºæ¨¡ç‰ˆâ€æŒ‰é’®ï¼Œå°†é›†ç¾¤ä¿¡æ¯ä¿å­˜ä¸ºæ¨¡ç‰ˆï¼Œä»¥ä¾¿å†æ¬¡åˆ›å»ºç›¸ä¼¼é…ç½®çš„é›†ç¾¤æ—¶ä½¿ç”¨ã€‚\nCRI é•œåƒä»“åº“é…ç½® Docker å’Œ Containerd ä½¿ç”¨ dockerhub ä½œä¸ºé»˜è®¤é•œåƒä»“åº“ï¼Œå¦‚æœæ‚¨éœ€è¦ä½¿ç”¨å…¶ä»–é•œåƒä»“åº“ï¼ˆç‰¹åˆ«æ˜¯ä½¿ç”¨è‡ªç­¾å https ä»“åº“æˆ–è€… http ä»“åº“ï¼‰ï¼Œæ‚¨éœ€è¦é…ç½® CRI é•œåƒä»“åº“ã€‚\nç‚¹å‡»é›†ç¾¤å³ä¾§â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤è®¾ç½®â€\u003eâ€œCRI é•œåƒä»“åº“â€æŒ‰é’®ï¼Œåœ¨ CRI é•œåƒä»“åº“å¼¹çª—ä¸­ï¼Œé…ç½®æ‚¨éœ€è¦çš„é•œåƒä»“åº“ï¼Œæ‚¨å¯ä»¥é€‰æ‹©å¹³å°ä¸­å·²å­˜åœ¨çš„é•œåƒä»“åº“ï¼Œä¹Ÿå¯ä»¥ä¸´æ—¶å¡«å†™é•œåƒä»“åº“åœ°å€ã€‚å¯¹äºè‡ªç­¾å https ä»“åº“æˆ–è€… http ä»“åº“ï¼Œå»ºè®®æ‚¨å…ˆåœ¨â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œé•œåƒä»“åº“â€é¡µé¢æ·»åŠ ä»“åº“ä¿¡æ¯ï¼Œå†åœ¨æ­¤æ“ä½œä¸­é…ç½®ã€‚\né›†ç¾¤èŠ‚ç‚¹ç®¡ç† åœ¨é›†ç¾¤è¯¦æƒ…é¡µçš„â€œèŠ‚ç‚¹â€åˆ—è¡¨é¡µé¢ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹å½“å‰é›†ç¾¤ä¸­çš„èŠ‚ç‚¹åˆ—è¡¨ï¼ŒèŠ‚ç‚¹çš„è§„æ ¼ã€çŠ¶æ€å’Œè§’è‰²ä¿¡æ¯ã€‚\næ·»åŠ é›†ç¾¤èŠ‚ç‚¹ å½“é›†ç¾¤è´Ÿè½½è¾ƒé«˜æ—¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¸ºé›†ç¾¤æ·»åŠ èŠ‚ç‚¹æ¥è¾¾åˆ°ä¸»åŠ¨æ‰©å®¹çš„ç›®çš„ï¼Œæ·»åŠ æ–°çš„â€œèŠ‚ç‚¹â€ä¸ä¼šå½±å“ç°æœ‰çš„ä¸šåŠ¡çš„è¿è¡Œã€‚\nåœ¨é›†ç¾¤è¯¦æƒ…é¡µçš„èŠ‚ç‚¹åˆ—è¡¨æ ‡ç­¾é¡µä¸‹ï¼Œç‚¹å‡»å·¦ä¾§çš„â€œæ·»åŠ èŠ‚ç‚¹â€æŒ‰é’®ï¼Œåœ¨å¼¹çª—ä¸­é€‰æ‹©å¯ç”¨èŠ‚ç‚¹ï¼Œè®¾ç½®èŠ‚ç‚¹æ ‡ç­¾ï¼Œç‚¹å‡»â€œç¡®è®¤â€æŒ‰é’®ã€‚å½“å‰ç‰ˆæœ¬ä»…æ”¯æŒæ·»åŠ å·¥ä½œèŠ‚ç‚¹ã€‚\nç§»é™¤é›†ç¾¤èŠ‚ç‚¹ åœ¨é›†ç¾¤è¯¦æƒ…é¡µçš„èŠ‚ç‚¹åˆ—è¡¨æ ‡ç­¾é¡µä¸‹ï¼Œæ‚¨å¯ä»¥ç‚¹å‡»èŠ‚ç‚¹å³ä¾§çš„ â€œç§»é™¤â€æŒ‰é’®ç§»é™¤èŠ‚ç‚¹ã€‚å½“å‰ç‰ˆæœ¬ä»…æ”¯æŒç§»é™¤å·¥ä½œèŠ‚ç‚¹ã€‚\næ³¨æ„ï¼šç§»é™¤é›†ç¾¤èŠ‚ç‚¹ï¼Œæ‚¨éœ€è¦æ³¨æ„ç”Ÿäº§ä¸­çš„å®‰å…¨é—®é¢˜ï¼Œé¿å…åº”ç”¨å‘ç”Ÿä¸­æ–­ã€‚\né›†ç¾¤å¤‡ä»½å’Œæ¢å¤ KubeClipper å¯¹ kubernetes é›†ç¾¤çš„å¤‡ä»½ä¸»è¦ä¸ºå¤‡ä»½ ETCD æ•°æ®åº“æ•°æ®ï¼Œä»¥åŠ kubernetes çš„èµ„æºå¯¹è±¡å¤‡ä»½ï¼Œå¦‚ namespaceï¼Œdeploymentã€configMapã€‚å¯¹èµ„æºè‡ªèº«äº§ç”Ÿçš„æ–‡ä»¶å’Œæ•°æ®ä¸åšå¤‡ä»½ï¼Œä¾‹å¦‚å¯¹é›†ç¾¤ä¸­è¿è¡Œçš„ mysql podï¼Œè¯¥ mysql pod äº§ç”Ÿçš„æ•°æ®å’Œæ–‡ä»¶ï¼Œä¸ä¼šä¸ºä¹‹å¤‡ä»½ï¼ŒåŒç†ï¼Œæ–‡ä»¶ç±»çš„ pv å¯¹è±¡ä¸‹çš„æ–‡ä»¶ï¼Œä¹Ÿä¸åšå¤‡ä»½ï¼Œä»…ä»…å¤‡ä»½ pv è¿™ä¸ªå¯¹è±¡ã€‚KubeClipper æä¾›çš„å¤‡ä»½åŠŸèƒ½æ˜¯çƒ­å¤‡ä»½ï¼Œå¤‡ä»½æœŸé—´ä¸å½±å“é›†ç¾¤çš„ä½¿ç”¨ã€‚KubeClipper è™½ç„¶ä¸åå¯¹åœ¨é›†ç¾¤ â€œç¹å¿™æœŸâ€ å¤‡ä»½ï¼Œä½†ä¹Ÿå¼ºçƒˆä¸èµæˆåœ¨é›†ç¾¤ â€œç¹å¿™æœŸâ€ å¤‡ä»½ã€‚\nåˆ›å»ºå¤‡ä»½ç©ºé—´ æ‰§è¡Œå¤‡ä»½ä¹‹å‰ï¼Œæ‚¨éœ€è¦å…ˆä¸ºé›†ç¾¤è®¾ç½®å¤‡ä»½ç©ºé—´ï¼Œå³è®¾ç½®å¤‡ä»½æ–‡ä»¶çš„å­˜å‚¨ä½ç½®ã€‚å¤‡ä»½ç©ºé—´çš„å­˜å‚¨ç±»å‹å¯ä»¥æ˜¯ FS å­˜å‚¨æˆ– S3 å­˜å‚¨ï¼Œä¸‹é¢ä»¥èŠ‚ç‚¹æœ¬åœ°å­˜å‚¨ã€NFS å­˜å‚¨å’Œ MINIO å­˜å‚¨ä¸ºä¾‹ï¼š\nèŠ‚ç‚¹æœ¬åœ°å­˜å‚¨ï¼ˆä»…é€‚ç”¨å•èŠ‚ç‚¹å®éªŒé›†ç¾¤ï¼‰ï¼š åˆ›å»ºå­˜å‚¨ç›®å½•ã€‚è¿æ¥é›†ç¾¤ master èŠ‚ç‚¹ç»ˆç«¯ï¼ˆå¯å‚è§è¿æ¥èŠ‚ç‚¹ç»ˆç«¯ï¼‰ï¼Œä½¿ç”¨ mkdir å‘½ä»¤ï¼Œåœ¨ master èŠ‚ç‚¹ä¸­åˆ›å»ºâ€œ/root/backupâ€ç›®å½•ã€‚ åˆ›å»ºå¤‡ä»½ç©ºé—´ã€‚ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œå¤‡ä»½ç©ºé—´â€ï¼Œè¿›å…¥å¤‡ä»½ç©ºé—´åˆ—è¡¨é¡µï¼Œç‚¹å‡»å³ä¸Šè§’â€œåˆ›å»ºâ€æŒ‰é’®ï¼Œåœ¨åˆ›å»ºå¤‡ä»½ç©ºé—´å¼¹çª—ä¸­ï¼Œè¾“å…¥â€œå¤‡ä»½ç©ºé—´åç§°â€ï¼Œå¦‚ â€œlocalâ€ï¼Œé€‰æ‹©â€œå­˜å‚¨ç±»å‹â€ä¸º â€œFSâ€ï¼Œå¡«å†™â€œå¤‡ä»½è·¯å¾„â€ï¼Œå¦‚ â€œ/root/backupâ€ã€‚ è®¾ç½®é›†ç¾¤å¤‡ä»½ç©ºé—´ã€‚åˆ›å»ºé›†ç¾¤æ—¶ï¼Œåœ¨â€œé›†ç¾¤é…ç½®â€é¡µé¢é€‰æ‹©â€œå¤‡ä»½ç©ºé—´â€ä¸º â€œlocalâ€ï¼Œæˆ–è€…ç¼–è¾‘å·²æœ‰é›†ç¾¤ï¼Œåœ¨ç¼–è¾‘é›†ç¾¤å¼¹çª—ä¸­çš„â€œå¤‡ä»½ç©ºé—´â€ä¸­é€‰æ‹© â€œlocalâ€ã€‚ æ³¨æ„ï¼šä½¿ç”¨æœ¬åœ°èŠ‚ç‚¹å­˜å‚¨å¤‡ä»½æ–‡ä»¶ï¼Œä¸éœ€è¦å¼•å…¥å¤–éƒ¨å­˜å‚¨ï¼Œç¼ºç‚¹æ˜¯å¦‚æœæœ¬åœ°èŠ‚ç‚¹é­åˆ°ç ´åï¼Œå¤‡ä»½æ–‡ä»¶ä¹Ÿä¼šä¸¢å¤±ï¼Œæ‰€ä»¥å¼ºçƒˆä¸èµæˆåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ã€‚\nNFSï¼š å‡†å¤‡ NFS å­˜å‚¨ã€‚å‡†å¤‡ä¸€å° NFS æœåŠ¡ï¼Œå¹¶åœ¨ NFS æœåŠ¡å™¨ä¸Šåˆ›å»ºä¸€ä¸ªç”¨äºå­˜æ”¾å¤‡ä»½æ–‡ä»¶çš„ç›®å½•ï¼Œå¦‚ â€œ/data/kubeclipper/cluster-backupsâ€ã€‚\næŒ‚è½½å­˜å‚¨ç›®å½•ã€‚è¿æ¥é›†ç¾¤ master èŠ‚ç‚¹ç»ˆç«¯ï¼ˆå¯å‚è§è¿æ¥èŠ‚ç‚¹ç»ˆç«¯ï¼‰ï¼Œä½¿ç”¨ mkdir å‘½ä»¤ï¼Œåœ¨æ¯ä¸ª master èŠ‚ç‚¹ä¸­åˆ›å»º â€œ/data/kubeclipper/cluster-backupsâ€ ç›®å½•ï¼Œå¹¶ mount åˆ° NFS æœåŠ¡å™¨çš„ /data/kubeclipper/cluster-backups ç›®å½•å³å¯ã€‚\nå‘½ä»¤ç¤ºä¾‹ï¼š\nmount -t nfs { NFS_IP }:/data/kubeclipper/cluster-backups /opt/kubeclipper/cluster-backups -o proto=tcp -o nolock åˆ›å»ºå¤‡ä»½ç©ºé—´ã€‚ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œå¤‡ä»½ç©ºé—´â€ï¼Œè¿›å…¥å¤‡ä»½ç©ºé—´åˆ—è¡¨é¡µï¼Œç‚¹å‡»å³ä¸Šè§’â€œåˆ›å»ºâ€æŒ‰é’®ï¼Œåœ¨åˆ›å»ºå¤‡ä»½ç©ºé—´å¼¹çª—ä¸­ï¼Œè¾“å…¥â€œå¤‡ä»½ç©ºé—´åç§°â€ï¼Œå¦‚ â€œnfsâ€ï¼Œé€‰æ‹©â€œå­˜å‚¨ç±»å‹â€ä¸º â€œFSâ€ï¼Œå¡«å†™â€œå¤‡ä»½è·¯å¾„â€ä¸º â€œ/opt/kubeclipper/cluster-backupsâ€ã€‚\nè®¾ç½®é›†ç¾¤å¤‡ä»½ç©ºé—´ã€‚åˆ›å»ºé›†ç¾¤æ—¶ï¼Œåœ¨â€œé›†ç¾¤é…ç½®â€é¡µé¢é€‰æ‹©â€œå¤‡ä»½ç©ºé—´â€ä¸º â€œnfsâ€ï¼Œæˆ–è€…ç¼–è¾‘å·²æœ‰é›†ç¾¤ï¼Œåœ¨ç¼–è¾‘é›†ç¾¤å¼¹çª—ä¸­çš„â€œå¤‡ä»½ç©ºé—´â€ä¸­é€‰æ‹© â€œnfsâ€ã€‚\nMINIOï¼š å‡†å¤‡ MINIO å­˜å‚¨ã€‚æ­å»º MINIO æœåŠ¡ï¼Œéƒ¨ç½²è¿‡ç¨‹å‚è€ƒå®˜ç½‘ https://docs.min.io/docs/minio-quickstart-guide.htmlï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å·²æœ‰ MINIO æœåŠ¡ã€‚ åˆ›å»ºå¤‡ä»½ç©ºé—´ã€‚ç‚¹å‡»â€œé›†ç¾¤ç®¡ç†â€\u003eâ€œå¤‡ä»½ç©ºé—´â€ï¼Œè¿›å…¥å¤‡ä»½ç©ºé—´åˆ—è¡¨é¡µï¼Œç‚¹å‡»å³ä¸Šè§’â€œåˆ›å»ºâ€æŒ‰é’®ï¼Œåœ¨åˆ›å»ºå¤‡ä»½ç©ºé—´å¼¹çª—ä¸­ï¼Œè¾“å…¥â€œå¤‡ä»½ç©ºé—´åç§°â€ï¼Œå¦‚ â€œminioâ€ï¼Œé€‰æ‹©â€œå­˜å‚¨ç±»å‹â€ä¸º â€œS3â€ï¼Œå¡«å†™ â€œbucket åç§°â€ï¼Œå¦‚ â€œkubeclipper-backupsâ€ï¼Œè¯¥ bucket å°†ç”± kubeclipper è‡ªåŠ¨åˆ›å»ºï¼Œâ€œEndpointâ€ ä¸­å¡«å†™ç¬¬ä¸€æ­¥ MINIO å­˜å‚¨æœåŠ¡çš„ ip å’Œç«¯å£å·ï¼Œå¡«å†™æœåŠ¡ç”¨æˆ·åå’Œå¯†ç ï¼Œç‚¹å‡»â€œç¡®å®šâ€æŒ‰é’®ã€‚ è®¾ç½®é›†ç¾¤å¤‡ä»½ç©ºé—´ã€‚åˆ›å»ºé›†ç¾¤æ—¶ï¼Œåœ¨â€œé›†ç¾¤é…ç½®â€é¡µé¢é€‰æ‹©â€œå¤‡ä»½ç©ºé—´â€ä¸º â€œminioâ€ï¼Œæˆ–è€…ç¼–è¾‘å·²æœ‰é›†ç¾¤ï¼Œåœ¨ç¼–è¾‘é›†ç¾¤å¼¹çª—ä¸­çš„â€œå¤‡ä»½ç©ºé—´â€ä¸­é€‰æ‹©â€œminioâ€ã€‚ æ‚¨å¯ä»¥åœ¨â€œé›†ç¾¤ç®¡ç†â€çš„â€œå¤‡ä»½ç©ºé—´â€é¡µé¢æŸ¥çœ‹æ‰€æœ‰å¤‡ä»½ç©ºé—´åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯ï¼Œå¹¶æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nç¼–è¾‘ï¼šç¼–è¾‘å¤‡ä»½ç©ºé—´æè¿°ï¼Œå’Œ S3 ç±»å‹å¤‡ä»½ç©ºé—´çš„ç”¨æˆ·å/å¯†ç ã€‚\nåˆ é™¤ï¼šåˆ é™¤å¤‡ä»½ç©ºé—´ï¼Œå¤‡ä»½ç©ºé—´ä¸‹å­˜åœ¨å¤‡ä»½æ–‡ä»¶çš„ï¼Œä¸å…è®¸åˆ é™¤ã€‚\né›†ç¾¤å¤‡ä»½ æ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œå¤‡ä»½å’Œæ¢å¤â€\u003e â€œé›†ç¾¤å¤‡ä»½â€æŒ‰é’®ï¼Œå¤‡ä»½é›†ç¾¤ ETCD æ•°æ®ã€‚\næ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µé¢çš„å¤‡ä»½æ ‡ç­¾é¡µä¸‹ï¼ŒæŸ¥çœ‹å½“å‰é›†ç¾¤çš„æ‰€æœ‰å¤‡ä»½æ–‡ä»¶ï¼Œè¿˜å¯ä»¥å¯¹å¤‡ä»½æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nç¼–è¾‘ï¼šç¼–è¾‘å¤‡ä»½æè¿°ã€‚\næ¢å¤ï¼šæ‰§è¡Œé›†ç¾¤æ¢å¤æ“ä½œï¼Œå°†é›†ç¾¤æ¢å¤è‡³æŒ‡å®šå¤‡ä»½çŠ¶æ€ã€‚\nåˆ é™¤ï¼šåˆ é™¤æŒ‡å®šå¤‡ä»½æ–‡ä»¶ã€‚\nå®šæ—¶å¤‡ä»½ æ‚¨ä¹Ÿå¯ä»¥ä¸ºé›†ç¾¤åˆ›å»ºå®šæ—¶å¤‡ä»½ï¼Œç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œå¤‡ä»½å’Œæ¢å¤â€\u003e â€œå®šæ—¶å¤‡ä»½â€æŒ‰é’®ï¼Œåœ¨å®šæ—¶å¤‡ä»½å¼¹çª—ä¸­ï¼Œè¾“å…¥å®šæ—¶å¤‡ä»½åç§°ã€æ‰§è¡Œç±»å‹ï¼ˆé‡å¤æ‰§è¡Œ/ä»…æ‰§è¡Œä¸€æ¬¡ï¼‰å’Œæ‰§è¡Œæ—¶é—´ï¼Œå¹¶ä¸ºé‡å¤æ‰§è¡Œçš„å®šæ—¶å¤‡ä»½è®¾ç½®æœ‰æ•ˆå¤‡ä»½ä¸ªæ•°ï¼Œç‚¹å‡»â€œç¡®è®¤â€æŒ‰é’®ã€‚\nkubeClipper ä¼šåœ¨æ‚¨è®¾ç½®çš„æ‰§è¡Œæ—¶é—´ä¸ºé›†ç¾¤æ‰§è¡Œå¤‡ä»½ä»»åŠ¡ï¼Œå¤‡ä»½æ–‡ä»¶ä¼šè‡ªåŠ¨å‘½åä¸ºâ€œé›†ç¾¤åç§°-å®šæ—¶å¤‡ä»½åç§°-éšæœºç â€ï¼Œå¯¹äºé‡å¤æ‰§è¡Œçš„å®šæ—¶å¤‡ä»½ï¼ŒkubeClipper ä¼šåœ¨è¯¥å®šæ—¶ä»»åŠ¡ä¸‹çš„å¤‡ä»½æ–‡ä»¶è¶…è¿‡æœ‰æ•ˆå¤‡ä»½ä¸ªæ•°æ—¶ï¼Œè‡ªåŠ¨åˆ é™¤è¶…å‡ºä¸ªæ•°çš„è¾ƒæ—©çš„å¤‡ä»½æ–‡ä»¶ã€‚\nå®šæ—¶å¤‡ä»½æ·»åŠ å®Œæˆåï¼Œå¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µçš„â€œå®šæ—¶å¤‡ä»½â€æ ‡ç­¾é¡µæŸ¥çœ‹å®šæ—¶å¤‡ä»½ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥åœ¨â€œå¤‡ä»½â€æ ‡ç­¾é¡µæŸ¥çœ‹å®šæ—¶å¤‡ä»½äº§ç”Ÿçš„å¤‡ä»½æ–‡ä»¶ã€‚\nå¯¹äºå®šæ—¶å¤‡ä»½ä»»åŠ¡ï¼Œæ‚¨è¿˜å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nç¼–è¾‘ï¼šç¼–è¾‘å®šæ—¶å¤‡ä»½ä»»åŠ¡æ‰§è¡Œæ—¶é—´ï¼Œå’Œé‡å¤æ‰§è¡Œçš„å®šæ—¶å¤‡ä»½çš„æœ‰æ•ˆå¤‡ä»½ä¸ªæ•°ã€‚\nå¯ç”¨/ç¦ç”¨ï¼šç¦ç”¨çš„å®šæ—¶å¤‡ä»½ä»»åŠ¡å°†æš‚æ—¶åœæ­¢æ‰§è¡Œã€‚\nåˆ é™¤ï¼šåˆ é™¤å®šæ—¶å¤‡ä»½ä»»åŠ¡ã€‚\né›†ç¾¤å¤‡ä»½æ¢å¤ å¦‚æœæ‚¨åœ¨é›†ç¾¤æ­£å¸¸è¿è¡ŒæœŸé—´æ‰§è¡Œæ¢å¤æ“ä½œï¼Œåˆ™ KubeClipper å°†å¯¹è¯¥é›†ç¾¤è¿›è¡Œè¦†ç›–å¼æ¢å¤ï¼Œå°±æ˜¯å¤‡ä»½æ–‡ä»¶é‡Œé¢çš„ etcd æ•°æ®ï¼Œè¦†ç›–ç°æœ‰çš„æ•°æ®ã€‚\næ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µçš„å¤‡ä»½æ ‡ç­¾é¡µä¸‹ï¼Œç‚¹å‡»å¤‡ä»½å³ä¾§çš„ â€œæ¢å¤â€æŒ‰é’®ï¼›æˆ–ç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œå¤‡ä»½å’Œæ¢å¤â€\u003eâ€œæ¢å¤é›†ç¾¤â€æŒ‰é’®ï¼Œåœ¨æ¢å¤é›†ç¾¤å¼¹çª—ä¸­é€‰æ‹©éœ€è¦æ¢å¤çš„å¤‡ä»½ï¼Œå¯ä»¥å°†å½“å‰é›†ç¾¤æ¢å¤è‡³æŒ‡å®šå¤‡ä»½çŠ¶æ€ã€‚\næ³¨æ„ï¼šé›†ç¾¤å‡çº§åï¼Œå°†æ— æ³•å†æ¢å¤åˆ°å‡çº§å‰ç‰ˆæœ¬çš„å¤‡ä»½ã€‚\né›†ç¾¤çŠ¶æ€ é›†ç¾¤ç‰ˆæœ¬å‡çº§ å¦‚å½“é›†ç¾¤ç‰ˆæœ¬ä¸æ»¡è¶³éœ€è¦ï¼Œæ‚¨å¯ä»¥ä¸ºé›†ç¾¤å‡çº§ kubernetes ç‰ˆæœ¬ã€‚ä¸åˆ›å»ºé›†ç¾¤ä¸€æ ·ï¼Œæ‚¨éœ€è¦å‡†å¤‡å¥½é›†ç¾¤ç‰ˆæœ¬æ‰€éœ€é…ç½®åŒ…å’Œç›®æ ‡ç‰ˆæœ¬çš„ kubernetes é•œåƒå¹¶ä¸Šä¼ è‡³æŒ‡å®šä½ç½®ï¼Œè¯¦æƒ…å‚è§åˆ›å»ºé›†ç¾¤å‡†å¤‡å·¥ä½œã€‚\nç‚¹å‡»é›†ç¾¤æ“ä½œçš„â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤çŠ¶æ€â€\u003e â€œé›†ç¾¤å‡çº§â€æŒ‰é’®ï¼Œåœ¨é›†ç¾¤å‡çº§å¼¹çª—ä¸­é€‰æ‹©å®‰è£…æ–¹å¼å’Œé•œåƒä»“åº“ï¼Œé€‰æ‹©å‡çº§çš„ç›®æ ‡ç‰ˆæœ¬ï¼Œå‡çº§çš„å®‰è£…æ–¹å¼å’Œ kubernetes ç‰ˆæœ¬çš„é…ç½®ä¸åˆ›å»ºé›†ç¾¤ç›¸åŒï¼Œè¯¦æƒ…å‚è§é›†ç¾¤é…ç½®æŒ‡å—ã€‚\né›†ç¾¤å‡çº§å¯ä»¥è·¨å°ç‰ˆæœ¬ï¼Œä½†ä¸æ”¯æŒç•¥è¿‡æ¬¡ç‰ˆæœ¬çš„å‡çº§ï¼Œå¦‚æ‚¨å¯ä»¥ä» v1.20.2 å‡çº§åˆ° v1.20.13ï¼Œæˆ–ç”± v1.20.x å‡çº§åˆ° v1.21.xï¼Œä½†ä¸æ”¯æŒä» v1.20.x å‡çº§åˆ° v1.22.xã€‚å¯¹äº 1.23.x ç‰ˆæœ¬ï¼Œæš‚ä¸æ”¯æŒå‡çº§åˆ° 1.24.x ç‰ˆæœ¬ã€‚\nå‡çº§é›†ç¾¤æ“ä½œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œæ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µé¢æŸ¥çœ‹æ“ä½œæ—¥å¿—ï¼Œè·Ÿè¸ªé›†ç¾¤å‡çº§çŠ¶æ€ã€‚\nåˆ é™¤é›†ç¾¤ æ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤åˆ—è¡¨å³ä¾§â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤çŠ¶æ€â€\u003e â€œåˆ é™¤â€æŒ‰é’®ï¼Œåˆ é™¤é›†ç¾¤ã€‚\næ³¨æ„åˆ é™¤åé›†ç¾¤ä¸å¯æ¢å¤ã€‚è¯·è°¨æ…æ“ä½œã€‚å¦‚æœé›†ç¾¤å¯¹æ¥äº†å¤–éƒ¨å­˜å‚¨ï¼Œå›æ”¶ç­–ç•¥ä¸ºâ€œä¿ç•™â€çš„å­˜å‚¨ç±»ä¸­çš„æ•°æ®å·ä¼šè¢«ä¿ç•™ï¼Œæ‚¨å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼è®¿é—®ï¼Œæˆ–æ‰‹åŠ¨åˆ é™¤ï¼›å›æ”¶ç­–ç•¥ä¸ºâ€œåˆ é™¤â€çš„å­˜å‚¨ç±»ä¸­çš„æ•°æ®å·ï¼Œä¼šåœ¨åˆ é™¤é›†ç¾¤æ—¶è‡ªåŠ¨åˆ é™¤ã€‚\né‡ç½®çŠ¶æ€ é›†ç¾¤æ“ä½œï¼ˆå¦‚åˆ›å»ºã€æ¢å¤ã€å‡çº§ç­‰ï¼‰æ‰§è¡Œå¤±è´¥ï¼Œå¯èƒ½ä¼šå¯¼è‡´é›†ç¾¤çŠ¶æ€æ˜¾ç¤ºä¸ºâ€œxxå¤±è´¥â€å¹¶æ— æ³•æ­£å¸¸æ‰§è¡Œå…¶ä»–æ“ä½œï¼Œå¦‚æœä»æ–­ç‚¹å¤„é‡è¯•ä¹Ÿæ— æ³•æ‰§è¡ŒæˆåŠŸï¼Œæ‚¨å¯ä»¥å‚è€ƒè¿ç»´æ–‡æ¡£ï¼Œæ‰‹åŠ¨ä¿®å¤é›†ç¾¤é—®é¢˜ã€‚é—®é¢˜ä¿®å¤åï¼Œæ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤å³ä¾§â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤çŠ¶æ€â€\u003eâ€œé‡ç½®çŠ¶æ€â€æŒ‰é’®ï¼Œé‡ç½®é›†ç¾¤è‡³æ­£å¸¸çŠ¶æ€ã€‚\né›†ç¾¤æ’ä»¶ç®¡ç† é™¤äº†åœ¨åˆ›å»ºé›†ç¾¤æ—¶å®‰è£…æ’ä»¶ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä¸ºè¿è¡Œä¸­çš„é›†ç¾¤å®‰è£…å­˜å‚¨å’Œå…¶ä»–è‡ªå®šä¹‰æ’ä»¶ã€‚ä»¥å®‰è£…å­˜å‚¨æ’ä»¶ä¸ºä¾‹ï¼Œç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œæ’ä»¶ç®¡ç†â€\u003eâ€œæ·»åŠ å­˜å‚¨é¡¹â€æŒ‰é’®ï¼Œè¿›å…¥æ·»åŠ å­˜å‚¨é¡¹é¡µé¢ï¼Œå¯ä»¥ä¸ºé›†ç¾¤å®‰è£…å­˜å‚¨æ’ä»¶ï¼Œå®‰è£…é…ç½®ä¸åˆ›å»ºé›†ç¾¤ä¸­çš„é…ç½®ç›¸åŒã€‚\nå¯¹äºå·²å®‰è£…çš„æ’ä»¶ï¼Œæ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µæŸ¥çœ‹æ’ä»¶ä¿¡æ¯ï¼Œå¹¶æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nä¿å­˜ä¸ºæ¨¡ç‰ˆï¼šå°†æ’ä»¶ä¿¡æ¯ä¿å­˜ä¸ºæ¨¡ç‰ˆï¼Œä»¥ä¾¿ä¸ºå…¶ä»–é›†ç¾¤ä½¿ç”¨ã€‚\nç§»é™¤æ’ä»¶ï¼šå¸è½½é›†ç¾¤æ’ä»¶ã€‚\né›†ç¾¤è¯ä¹¦ç®¡ç† æ›´æ–°é›†ç¾¤è¯ä¹¦ kubernetes é›†ç¾¤è¯ä¹¦é»˜è®¤æœ‰æ•ˆæœŸä¸ºä¸€å¹´ï¼Œæ‚¨å¯ä»¥åœ¨é›†ç¾¤è¯¦æƒ…é¡µçš„åŸºæœ¬ä¿¡æ¯ä¸­æŸ¥çœ‹è¯ä¹¦è¿‡æœŸæ—¶é—´ï¼Œè¯ä¹¦è¿‡æœŸå‰ä¸€å¤©ï¼Œæ‚¨ä¹Ÿå¯ä»¥åœ¨é›†ç¾¤åˆ—è¡¨çœ‹åˆ°è¯ä¹¦è¿‡æœŸçš„æé†’ã€‚æ›´æ–°é›†ç¾¤è¯ä¹¦ï¼Œæ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤è¯ä¹¦â€\u003eâ€œæ›´æ–°é›†ç¾¤è¯ä¹¦â€æŒ‰é’®ï¼Œæ›´æ–°é›†ç¾¤å…¨éƒ¨è¯ä¹¦ã€‚\nè·å– kubeconfig æ–‡ä»¶ æ‚¨å¯ä»¥ç‚¹å‡»é›†ç¾¤æ“ä½œä¸­çš„â€œæ›´å¤šâ€\u003eâ€œé›†ç¾¤è¯ä¹¦â€\u003eâ€œæŸ¥çœ‹ kubeconfig æ–‡ä»¶â€æŒ‰é’®ï¼ŒæŸ¥çœ‹é›†ç¾¤ kubeconfig æ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»å¼¹çª—ä¸­çš„â€œä¸‹è½½â€æŒ‰é’®ï¼Œä¸‹è½½ kubeconfig æ–‡ä»¶ã€‚\n","categories":"","description":"kubeclipper æ”¯æŒå¯¹ kubernetes é›†ç¾¤çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚\n","excerpt":"kubeclipper æ”¯æŒå¯¹ kubernetes é›†ç¾¤çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚\n","ref":"/docs/tutorials/cluster-management/","tags":"","title":"é›†ç¾¤ç®¡ç†"},{"body":"é—®é¢˜å¤ç° å®‰è£… v1.2.1 ç‰ˆæœ¬çš„ kcctl\ncurl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_VERSION=v1.2.1 bash - é€šè¿‡ kcctl deploy å‘½ä»¤éƒ¨ç½² KubeClipper é›†ç¾¤\n# å®‰è£… AIO ç¯å¢ƒ kcctl deploy é€šè¿‡ kcctl create cluster å‘½ä»¤åˆ›å»º kubernetes é›†ç¾¤\n# éœ€è¦å…ˆç™»å½• kcctl login --host http://127.0.0.1 --username admin --password Thinkbig1 # åˆ›å»ºé›†ç¾¤ kcctl create cluster --name test --master 192.168.10.98 --untaint-master ç™»å½• KubeClipper ç®¡ç†ç•Œé¢ï¼ŒæŸ¥çœ‹åˆ›å»ºé›†ç¾¤æ“ä½œæ—¥å¿—ï¼Œæ—¥å¿—æ˜¾ç¤ºåœ¨å®‰è£… cni è¿‡ç¨‹ä¸­å‘ç°ä¸‹è½½ calico v3.21.2 404 æ— æ³•æ‰¾åˆ°\né—®é¢˜ä¿®å¤ PR æäº¤å·²ç»åˆå¹¶åˆ°äº† masterï¼ŒPRï¼šhttps://github.com/kubeclipper/kubeclipper/commit/7e6eb0ed199ff1cb00fde0c2624c62cdc5ca0b9c\nä½† v1.2.1 å·²ç»å‘å¸ƒäº†ï¼ŒæŒ‰ç…§å‘ç‰ˆè§„èŒƒæ— æ³•åœ¨è¯¥ç‰ˆæœ¬æ‰“è¡¥ä¸ï¼Œéœ€è¦ç­‰åˆ°åç»­ v1.2.2 å‘å¸ƒè§£å†³ï¼Œå› æ­¤æˆ‘ä»¬æä¾›ä¸€ç§ä¸´æ—¶æ–¹æ¡ˆæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\nè§£å†³æ–¹æ³• åˆ¶ä½œç¦»çº¿èµ„æºåŒ… ä¸‹è½½ calico v3.21.2 çš„å®‰è£…åŒ…ï¼Œæ‰“åŒ…ä¸ºæŒ‡å®šæ ¼å¼çš„ç¦»çº¿èµ„æºåŒ…\n# åˆ›å»ºèµ„æºç›®å½• mkdir -pv calico/v3.21.2/amd64 # ä¸‹è½½ v3.21.2 ç‰ˆæœ¬çš„ calico wget -P calico/v3.21.2/amd64 https://oss.kubeclipper.io/packages/calico/v3.21.2/amd64/images.tar.gz wget -P calico/v3.21.2/amd64 https://oss.kubeclipper.io/packages/calico/v3.21.2/amd64/manifest.json # å‹ç¼©æ–‡ä»¶ä¸ºæŒ‡å®šå‘½ä»¤ tar -zcvf calico-v3.21.2-amd64.tar.gz calico æ¨é€ç¦»çº¿èµ„æºåŒ…\n# æ¨é€ kcctl resource push --pkg calico-v3.21.2-amd64.tar.gz --type cni # éªŒè¯ kcctl resource list|grep v3.21.2 å¦‚æœåœ¨æ‰§è¡Œ kcctl resource push æŠ¥äº†å¦‚ä¸‹é”™è¯¯ï¼š è§£å†³æ–¹æ³•å¦‚ä¸‹ï¼š\nç¼–è¾‘ /root/.kc/deploy-config.yaml æ–‡ä»¶ã€‚ æ‰¾åˆ° ssh é…ç½®é¡¹ï¼Œæ·»åŠ  pkFile å­—æ®µé…ç½®ï¼Œå€¼ä¸ºå½“å‰æœåŠ¡å™¨çš„ ssh å…¬é’¥æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚\né€šè¿‡å‘½ä»¤è¡Œå®‰è£… kubernetes é›†ç¾¤ï¼Œåœ¨ KubeClipper ç®¡ç†åå°æŸ¥çœ‹æ“ä½œæ—¥å¿—\nkcctl create cluster --name test --master 192.168.10.98 --untaint-master æŸ¥çœ‹ kubernetes é›†ç¾¤ pods è¿è¡ŒçŠ¶æ€\nkubectl get pods -A ","categories":["FAQ"],"description":"åœ¨ v1.2.1 ç‰ˆæœ¬ï¼ˆåŒ…æ‹¬ v1.2.1ï¼‰ä¹‹å‰ï¼Œä½¿ç”¨ `kcctl create cluster` å‘½ä»¤åˆ›å»ºé›†ç¾¤åŠŸèƒ½ï¼Œä¼šå‘ç”Ÿåˆ›å»ºå¤±è´¥é”™è¯¯ï¼Œä»¥ä¸‹æä¾›ä¸€ç§ä¸´æ—¶çš„è§£å†³æ–¹æ³•ã€‚ åœ¨ v1.2.1 ç‰ˆæœ¬ä¹‹åï¼Œæˆ‘ä»¬ä¿®å¤äº†è¯¥é—®é¢˜ã€‚\n","excerpt":"åœ¨ v1.2.1 ç‰ˆæœ¬ï¼ˆåŒ…æ‹¬ v1.2.1ï¼‰ä¹‹å‰ï¼Œä½¿ç”¨ `kcctl create cluster` å‘½ä»¤åˆ›å»ºé›†ç¾¤åŠŸèƒ½ï¼Œä¼šå‘ç”Ÿåˆ›å»ºå¤±è´¥é”™è¯¯ï¼Œä»¥ä¸‹æä¾›ä¸€ç§ä¸´æ—¶çš„è§£å†³æ–¹æ³•ã€‚ åœ¨ v1.2.1 ç‰ˆæœ¬ä¹‹åï¼Œæˆ‘ä»¬ä¿®å¤äº†è¯¥é—®é¢˜ã€‚\n","ref":"/docs/faq/kcctl-create-cluster-error/","tags":["kcctl","create","cluster"],"title":"é€šè¿‡ kcctl å‘½ä»¤åˆ›å»ºé›†ç¾¤é”™è¯¯"},{"body":"","categories":"","description":"ç”¨æˆ·ä½¿ç”¨æ‰‹å†Œ\n","excerpt":"ç”¨æˆ·ä½¿ç”¨æ‰‹å†Œ\n","ref":"/docs/tutorials/","tags":"","title":"ä½¿ç”¨æ‰‹å†Œ"},{"body":"","categories":"","description":"User manual\n","excerpt":"User manual\n","ref":"/en/docs/tutorials/","tags":"","title":"Tutorials"},{"body":"","categories":"","description":"Q\u0026A\n","excerpt":"Q\u0026A\n","ref":"/en/docs/faq/","tags":"","title":"FAQ"},{"body":"Region management KubeClipper supports multi-region management. That is, all nodes and clusters managed by the platform are divided into physical or logical regions. On the Region Management page, you can view all regions in the platform. Click a region name to enter the region detail page, and you can view the clusters and nodes in the region.\nNode management The platform supports multi-region management, that is, the owning region of all nodes managed by the platform. On the Region Management page, you can view all regions managed by the platform. Click a region name to go to the region details page, where you can view the list of all clusters and nodes in the region.\nOn the \"Node Info\" page, you can view the list of all nodes managed in the platform, node specifications, status and other information. Click the node name to enter the node detail page, you can view detailed node basic information and system information.\nThe node status in KubeClipper represents the management status of the node by kc-gent. Under normal circumstances, the node status is displayed as \"Ready\". When the node is out of contact for 4 minutes (within 10s of the error time), the status will be updated to \"Unknown\". Nodes with unknown status cannot perform any operations, nor can they create clusters or add/remove nodes to clusters.\nAdd node When deploying KubeClipper, you can add the initial server nodes which are used to deploy KubeClipper's own services, and agent nodes which are used to deploy kubernetes clusters. In a KubeClipper environment for experimentation or development, you can add a server node as an agent node at the same time. However, if it is used for a production environment, it is recommended not to reuse the server node as an agent node.\nYou can also use the kcctl join command to add agent nodes to KubeClipper, and mark a region for each agent node. The region can be a physical or logical location. You can use nodes in the same region to create a kubernetes cluster, but cannot use nodes across regions to create a cluster. Nodes in unmarked regions belong to the default region.\nCommand line example:\nkcctl join --agent beijing:1.2.3.4 --agent shanghai:2.3.4.5 Remove node When you no longer need some nodes, you can use the kcctl drain command to remove nodes from the platform.\nCommand line example:\nkcctl drain --agent 192.168.10.19 Connect Terminal On the node list page, you can click the \"Connect Terminal\" button on the right side of the target node, enter the node port and username password information in the pop-up window, access the node SSH console and execute command tasks.\nEnable/disable a node You can click the Disable button on the right side of the node to temporarily disable the node. The node in the disabled state cannot be created or added to the cluster.\n","categories":"","description":"KubeClipper supports node and cluster management across multiple regions.\n","excerpt":"KubeClipper supports node and cluster management across multiple regions.\n","ref":"/en/docs/tutorials/node-management/","tags":"","title":"Node management"},{"body":"åŒºåŸŸç®¡ç† å¹³å°æ”¯æŒå¤šåŒºåŸŸç®¡ç†ï¼Œå³ä¸ºå¹³å°ç®¡ç†çš„æ‰€æœ‰èŠ‚ç‚¹å’Œé›†ç¾¤è¿›è¡Œç‰©ç†æˆ–é€»è¾‘çš„åŒºåŸŸåˆ’åˆ†ã€‚æ‚¨å¯ä»¥åœ¨â€œåŒºåŸŸç®¡ç†â€é¡µé¢æŸ¥çœ‹å¹³å°å†…ç®¡ç†çš„æ‰€æœ‰åŒºåŸŸï¼Œç‚¹å‡»åŒºåŸŸåç§°ï¼Œè¿›å…¥åŒºåŸŸè¯¦æƒ…é¡µé¢ï¼Œå¯ä»¥æŸ¥çœ‹åŒºåŸŸä¸‹çš„æ‰€æœ‰é›†ç¾¤åˆ—è¡¨å’ŒèŠ‚ç‚¹åˆ—è¡¨ã€‚\nèŠ‚ç‚¹ç®¡ç† æ‚¨å¯ä»¥åœ¨â€œèŠ‚ç‚¹ä¿¡æ¯â€é¡µé¢æŸ¥çœ‹å¹³å°ä¸­ç®¡ç†çš„å…¨éƒ¨èŠ‚ç‚¹åˆ—è¡¨ï¼Œå’ŒèŠ‚ç‚¹è§„æ ¼ã€çŠ¶æ€ç­‰ä¿¡æ¯ã€‚ç‚¹å‡»èŠ‚ç‚¹åç§°è¿›å…¥èŠ‚ç‚¹è¯¦æƒ…é¡µé¢ï¼Œå¯ä»¥æŸ¥çœ‹è¯¦ç»†çš„èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯å’Œç³»ç»Ÿä¿¡æ¯ã€‚\nKubeClipper ä¸­çš„èŠ‚ç‚¹çŠ¶æ€è¡¨ç¤º kc-agent å¯¹èŠ‚ç‚¹çš„ç®¡ç†çŠ¶æ€ã€‚æ­£å¸¸æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹çŠ¶æ€æ˜¾ç¤ºä¸ºâ€œå°±ç»ªâ€ï¼Œå½“èŠ‚ç‚¹å¤±è”4åˆ†é’Ÿï¼ˆè¯¯å·®æ—¶é—´ 10s å†…ï¼‰åï¼ŒçŠ¶æ€ä¼šæ›´æ–°ä¸ºâ€œæœªçŸ¥â€ï¼ŒæœªçŸ¥çŠ¶æ€çš„èŠ‚ç‚¹æ— æ³•è¿›è¡Œä»»ä½•æ“ä½œï¼Œä¹Ÿæ— æ³•åˆ›å»ºé›†ç¾¤æˆ–ä¸ºé›†ç¾¤æ·»åŠ /ç§»é™¤èŠ‚ç‚¹ã€‚\næ·»åŠ èŠ‚ç‚¹ åœ¨éƒ¨ç½² KubeClipper æ—¶ï¼Œæ‚¨å°±å¯ä»¥æ·»åŠ åˆå§‹çš„ server èŠ‚ç‚¹å’Œ agent èŠ‚ç‚¹ï¼Œå…¶ä¸­ï¼Œserver èŠ‚ç‚¹ç”¨äºéƒ¨ç½² KubeClipper è‡ªèº«æœåŠ¡ï¼Œagent èŠ‚ç‚¹å¯ç”¨äºéƒ¨ç½² kubernetes é›†ç¾¤ã€‚åœ¨ç”¨äºå®éªŒæˆ–å¼€å‘çš„ KubeClipper ç¯å¢ƒï¼Œæ‚¨å¯ä»¥å°† server èŠ‚ç‚¹åŒæ—¶æ·»åŠ ä¸º agent èŠ‚ç‚¹ã€‚ä½†å¦‚æœç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œå»ºè®®ä¸è¦å°† server èŠ‚ç‚¹å¤ç”¨ä¸º agent èŠ‚ç‚¹ã€‚\næ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ kcctl join å‘½ä»¤ä¸º KubeClipper æ·»åŠ  agent èŠ‚ç‚¹ã€‚åŒæ—¶ï¼Œæ‚¨å¯ä»¥ä¸ºæ¯ä¸ª agent èŠ‚ç‚¹æ ‡è®°ä¸€ä¸ªåŒºåŸŸï¼ŒåŒºåŸŸå¯ä»¥æ˜¯ç‰©ç†çš„æˆ–é€»è¾‘çš„ä½ç½®ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨åŒä¸€åŒºåŸŸçš„èŠ‚ç‚¹åˆ›å»º kubernetes é›†ç¾¤ï¼Œä½†ä¸å¯ä»¥ä½¿ç”¨è·¨åŒºåŸŸçš„èŠ‚ç‚¹åˆ›å»ºé›†ç¾¤ã€‚æœªæ ‡è®°åŒºåŸŸçš„èŠ‚ç‚¹é»˜è®¤å±äº default åŒºåŸŸã€‚\nå‘½ä»¤è¡Œç¤ºä¾‹ï¼š\nkcctl join --agent beijing:1.2.3.4 --agent shanghai:2.3.4.5 ç§»é™¤èŠ‚ç‚¹ å½“æ‚¨ä¸å†éœ€è¦æŸäº›èŠ‚ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨ kcctl drain å‘½ä»¤å°†èŠ‚ç‚¹ä»å¹³å°ä¸­ç§»é™¤ã€‚\nå‘½ä»¤è¡Œç¤ºä¾‹ï¼š\nkcctl drain --agent 192.168.10.19 è¿æ¥ç»ˆç«¯ åœ¨èŠ‚ç‚¹åˆ—è¡¨é¡µé¢ï¼Œæ‚¨å¯ä»¥ç‚¹å‡»ç›®æ ‡èŠ‚ç‚¹å³ä¾§çš„â€œè¿æ¥ç»ˆç«¯â€æŒ‰é’®ï¼Œåœ¨è¿æ¥ç»ˆç«¯çš„å¼¹çª—ä¸­è¾“å…¥èŠ‚ç‚¹ç«¯å£å’Œç”¨æˆ·åå¯†ç ä¿¡æ¯åï¼Œè®¿é—®èŠ‚ç‚¹ SSH æ§åˆ¶å°å¹¶æ‰§è¡Œå‘½ä»¤ã€‚\nå¯ç”¨/ç¦ç”¨èŠ‚ç‚¹ æ‚¨å¯ä»¥ç‚¹å‡»èŠ‚ç‚¹å³ä¾§â€œç¦ç”¨â€æŒ‰é’®æš‚æ—¶ç¦ç”¨èŠ‚ç‚¹ï¼Œç¦ç”¨çŠ¶æ€ä¸‹çš„èŠ‚ç‚¹ä¸å…è®¸åˆ›å»ºæˆ–æ·»åŠ åˆ°é›†ç¾¤ã€‚\n","categories":"","description":"KubeClipper æ”¯æŒè·¨åŒºåŸŸçš„èŠ‚ç‚¹å’Œé›†ç¾¤ç®¡ç†ã€‚\n","excerpt":"KubeClipper æ”¯æŒè·¨åŒºåŸŸçš„èŠ‚ç‚¹å’Œé›†ç¾¤ç®¡ç†ã€‚\n","ref":"/docs/tutorials/node-management/","tags":"","title":"èŠ‚ç‚¹ç®¡ç†"},{"body":"","categories":"","description":"å¸¸è§é—®é¢˜è®°å½•\n","excerpt":"å¸¸è§é—®é¢˜è®°å½•\n","ref":"/docs/faq/","tags":"","title":"å¸¸è§é—®é¢˜"},{"body":"Create user After installing KubeClipper, you need to create a user of a desired role. Initially, there is only one user, admin, by default, with the platform administrator role.\nClick \"Access Control\" \u003e \"Users\" to enter the user management page, click the \"Create User\" button in the upper left corner, fill in the user name, password, alias name and other information in the pop-up window, specify the user role, and click the \"OK\" button. The four initial roles in the system are as follows:\nplatform-admin: Platform administrator, with the authority to set platform, cluster management, user management, audit, etc.\ncluster-manager: Cluster administrator, with all cluster management permissions.\niam-manager: User administrator, with all user management permissions.\nPlatform-view: Platform read-only user, with all platform viewing permissions.\nAfter the user is created, you can view the user details and login logs on the user detail page and perform the following operations:\nEdit: Edit user alias, role, mobile phone number, email information.\nEdit Password: Edit the user login password.\nDelete: Delete the user.\nCreate a custom role In addition to system initial roles, you can also create customized roles to meet business needs.\nClick \"Access Control\" \u003e \"Roles\" to enter the role management page. You can click the \"Create Role\" button in the upper left corner to create a custom role.\nOn the Create Role page, you need to fill in the role name and description, and check the permissions required. Some permissions depend on other permissions. When these permissions are selected, the dependent permissions will be automatically selected.\nAfter creating a customized role, you can view the basic role information, role permission list, authorized user list on the role detail page, and perform the following operations:\nEdit: Edit the custom role description.\nEdit permissions: Edit permissions of the customized role.\nDelete: To delete a customized role, make sure that no user is using the role to be deleted.\nAccess to external users External users can log in to KubeClipper via the OIDC protocol .\nFirst, the platform administrator needs to log in to the platform server node and insert the following information under â€œauthenticationâ€ in the kubeclipepr-server.yaml file:\noauthOptions: identityProviders: - name: keycloak type: OIDC mappingMethod: auto provider: clientID: kc clientSecret: EErn729BB1bKawdRtnZgrqj9Bx0]mzUs issuer: http://172.20.163.233:7777/auth/realms/kubeclipper scopes: - openid - email redirectURL: http://{kc-console-address}/oatuh2/redirect/{IDP-Name} Under \"provider\", you need to fill in the clientID , clientSecret , and issuer information of your OAuth2 service, taking keycloack as an example, as shown in the figure below.\nRedirectURL example: http://172.0.0.90/oauth2/redirect/keycloack\nOAuth2 users can log in to the KubeClipper platform by following these steps:\nClick the \"OAuth2 Login\" button on the login page, enter the OAuth2 login page, fill in the username and password to enter the KubeClipper platform. When logging in for the first time, you will not be able to access the platform because you have not been granted any permission.\nThe platform administrator or other user with user management rights log in to KubeClipper, find the target OAuth2 user on the user management page, and set the user role by editing the user information.\nThe OAuth2 user repeats the first step, logs in to KubeClipper, and accesses the platform normally.\n","categories":"","description":"KubeClipper access control usage guide.\n","excerpt":"KubeClipper access control usage guide.\n","ref":"/en/docs/tutorials/access-control/","tags":"","title":"Access control"},{"body":"ç”¨æˆ·ç®¡ç† å®‰è£… KubeClipper ä¹‹åï¼Œæ‚¨éœ€è¦åˆ›å»ºæ‰€éœ€è§’è‰²çš„ç”¨æˆ·ã€‚ä¸€å¼€å§‹ï¼Œç³»ç»Ÿé»˜è®¤åªæœ‰ä¸€ä¸ªç”¨æˆ· adminï¼Œå…·æœ‰å¹³å°ç®¡ç†å‘˜è§’è‰²ã€‚\nç‚¹å‡»â€œè®¿é—®æ§åˆ¶â€\u003eâ€œç”¨æˆ·â€ï¼Œè¿›å…¥ç”¨æˆ·ç®¡ç†é¡µé¢ï¼Œç‚¹å‡»å·¦ä¸Šè§’â€œåˆ›å»ºç”¨æˆ·â€æŒ‰é’®ï¼Œåœ¨å¼¹çª—ä¸­å¡«å†™ç”¨æˆ·åã€å¯†ç ã€æ‰‹æœºå·ç ã€é‚®ç®±ç­‰ä¿¡æ¯ï¼Œå¹¶æŒ‡å®šç”¨æˆ·è§’è‰²ï¼Œç‚¹å‡»â€œç¡®è®¤â€æŒ‰é’®ã€‚ç³»ç»Ÿå†…ç½®å››ä¸ªè§’è‰²å¦‚ä¸‹ï¼š\nå¹³å°ç®¡ç†å‘˜ï¼šæ‹¥æœ‰é›†ç¾¤ç®¡ç†ã€ç”¨æˆ·ç®¡ç†ã€å®¡è®¡ç®¡ç†ç­‰å…¨éƒ¨å¹³å°æŸ¥çœ‹å’Œæ“ä½œæƒé™ã€‚\né›†ç¾¤ç®¡ç†å‘˜ï¼šæ‹¥æœ‰æ‰€æœ‰é›†ç¾¤ç®¡ç†æƒé™ã€‚\nç”¨æˆ·ç®¡ç†å‘˜ï¼šæ‹¥æœ‰æ‰€æœ‰ç”¨æˆ·ç®¡ç†æƒé™ã€‚\nå¹³å°åªè¯»ç”¨æˆ·ï¼šæ‹¥æœ‰å…¨éƒ¨å¹³å°æŸ¥çœ‹æƒé™ã€‚\nç”¨æˆ·åˆ›å»ºå®Œæˆåï¼Œæ‚¨å¯ä»¥åœ¨ç”¨æˆ·è¯¦æƒ…é¡µé¢æŸ¥çœ‹ç”¨æˆ·è¯¦æƒ…ä¿¡æ¯ï¼Œå¹¶æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nç¼–è¾‘ï¼šç¼–è¾‘ç”¨æˆ·åˆ«åã€è§’è‰²ã€æ‰‹æœºå·ã€é‚®ç®±ä¿¡æ¯ã€‚\nç¼–è¾‘å¯†ç ï¼šç¼–è¾‘ç”¨æˆ·ç™»å½•å¯†ç ã€‚\nåˆ é™¤ï¼šåˆ é™¤ç”¨æˆ·ã€‚\nåœ¨ç”¨æˆ·è¯¦æƒ…é¡µé¢ï¼Œæ‚¨è¿˜å¯ä»¥æŸ¥çœ‹å½“å‰ç”¨æˆ·çš„ç™»å½•æ—¥å¿—åˆ—è¡¨ã€‚\næ‚¨å¯ä»¥ç¼–è¾‘å¹³å° /etc/kubeclipper-server/kubeclipper-server.yaml æ–‡ä»¶ï¼Œæ ¹æ®éœ€è¦è®¾ç½®ç”¨æˆ·ç™»å½•æ—¥å¿—çš„æœ€å¤§ä¿ç•™æ¡æ•°å’Œä¿ç•™æœŸé™ï¼Œæ¯ä¸ªç”¨æˆ·çš„ç™»å½•æ—¥å¿—è¶…è¿‡æœ€å¤§æ¡æ•°åï¼Œè¶…è¿‡æœ€å¤§æ¡æ•°å’ŒæœŸé™çš„æ—¥å¿—ä¼šè¢«è‡ªåŠ¨åˆ é™¤ï¼Œä»…è¶…è¿‡ä¿ç•™æœŸé™ä½†æœªè¶…è¿‡æœ€å¤§æ¡æ•°çš„æ—¥å¿—æ•°æ®å°†ä¸ä¼šè¢«åˆ é™¤ã€‚\nè‡ªå®šä¹‰è§’è‰² é™¤äº†ç³»ç»Ÿå†…ç½®è§’è‰²ï¼Œæ‚¨ä¹Ÿå¯ä»¥åˆ›å»ºè‡ªå®šä¹‰è§’è‰²ï¼Œä»¥æ»¡è¶³ä¸šåŠ¡éœ€è¦ã€‚\nç‚¹å‡»â€œè®¿é—®æ§åˆ¶â€\u003eâ€œè§’è‰²â€ï¼Œè¿›å…¥è§’è‰²ç®¡ç†é¡µé¢ï¼Œæ‚¨å¯ä»¥ç‚¹å‡»å·¦ä¸Šè§’â€œåˆ›å»ºè§’è‰²â€æŒ‰é’®ï¼Œåˆ›å»ºè‡ªå®šä¹‰è§’è‰²ã€‚\nåœ¨åˆ›å»ºè§’è‰²é¡µé¢ï¼Œæ‚¨éœ€è¦å¡«å†™è§’è‰²åç§°å’Œæè¿°ï¼Œå¹¶å‹¾é€‰è‡ªå®šä¹‰è§’è‰²æ‰€éœ€æƒé™ï¼Œä¸€äº›æƒé™ä¾èµ–äºå…¶ä»–æƒé™ï¼Œåœ¨é€‰æ‹©è¿™äº›æƒé™æ—¶ï¼Œå°†è‡ªåŠ¨é€‰ä¸­ä¾èµ–çš„æƒé™ã€‚\nåˆ›å»ºè‡ªå®šä¹‰è§’è‰²å®Œæˆåï¼Œæ‚¨å¯ä»¥åœ¨è§’è‰²è¯¦æƒ…é¡µé¢æŸ¥çœ‹è§’è‰²åŸºæœ¬ä¿¡æ¯ã€è§’è‰²æƒé™åˆ—è¡¨ã€æˆæƒç”¨æˆ·åˆ—è¡¨ï¼Œå¹¶å¯¹è‡ªå®šä¹‰è§’è‰²æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nç¼–è¾‘ï¼šç¼–è¾‘è‡ªå®šä¹‰è§’è‰²åˆ«åã€‚\nç¼–è¾‘æƒé™ï¼šç¼–è¾‘è‡ªå®šä¹‰è§’è‰²ä¸‹çš„æƒé™ã€‚\nåˆ é™¤ï¼šåˆ é™¤è‡ªå®šä¹‰è§’è‰²ï¼Œéœ€ç¡®ä¿æ²¡æœ‰ç”¨æˆ·ä½¿ç”¨å¾…åˆ é™¤è§’è‰²ã€‚\næ¥å…¥å¤–éƒ¨ç”¨æˆ· KubeClipper å¯ä»¥é€šè¿‡ OIDC åè®®ä½¿ç”¨å¤–éƒ¨ç”¨æˆ·ç™»å½•ã€‚\né¦–å…ˆï¼Œå¹³å°ç®¡ç†å‘˜éœ€è¦ç™»å½•å¹³å° server èŠ‚ç‚¹ï¼Œåœ¨ kubeclipepr-server.yaml æ–‡ä»¶ä¸­çš„ authentication ä¸‹æ’å…¥ä»¥ä¸‹ä¿¡æ¯ï¼š\noauthOptions: identityProviders: - name: keycloak type: OIDC mappingMethod: auto provider: clientID: kc clientSecret: EErn729BB1bKawdRtnZgrqj9Bx0]mzUs issuer: http://172.20.163.233:7777/auth/realms/kubeclipper scopes: - openid - email redirectURL: http://{kc-console-address}/oatuh2/redirect/{IDP-Name} å…¶ä¸­ï¼Œâ€œproviderâ€ ä¸‹éœ€è¦æ‚¨å¡«å†™è‡ªå·±çš„ OAuth2 æœåŠ¡çš„clientIDã€clientSecretã€issuerä¿¡æ¯ï¼Œä»¥ keycloack ä¸ºä¾‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\nredirectURLç¤ºä¾‹ï¼šhttp://172.0.0.90/oauth2/redirect/keycloack\nOAuth2 ç”¨æˆ·å¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤è®¿é—®å’Œä½¿ç”¨ KubeClipper å¹³å°ï¼š\nç‚¹å‡»ç™»å½•é¡µçš„ â€œOAuth2 ç™»å½•â€æŒ‰é’®ï¼Œè¿›å…¥ OAuth2 ç™»å½•é¡µé¢ï¼Œè¾“å…¥ç”¨æˆ·åå¯†ç ç™»å½•ï¼Œè¿›å…¥ KubeClipper å¹³å°ï¼Œé¦–æ¬¡ç™»å½•ï¼Œæ‚¨ä¼šå› æœªè¢«æˆäºˆæƒé™è€Œæ— æ³•è®¿é—®å¹³å°ã€‚ å¹³å°ç®¡ç†å‘˜æˆ–å…¶ä»–æ‹¥æœ‰ç”¨æˆ·ç®¡ç†æƒé™çš„ç”¨æˆ·ç™»å½• KubeClipperï¼Œåœ¨ç”¨æˆ·ç®¡ç†é¡µé¢ï¼Œæ‰¾åˆ°ç›®æ ‡ OAuth2 ç”¨æˆ·ï¼Œé€šè¿‡ç¼–è¾‘ç”¨æˆ·æŒ‡å®šç”¨æˆ·è§’è‰²ã€‚ OAuth2 ç”¨æˆ·é‡å¤ç¬¬ä¸€æ­¥ï¼Œç™»å½• KubeClipperï¼Œå°±å¯ä»¥æ­£å¸¸è®¿é—®å¹³å°å¹¶æ‰§è¡Œè§’è‰²æƒé™å†…æ“ä½œã€‚ ","categories":"","description":"KubeClipper è®¿é—®æ§åˆ¶åŠŸèƒ½ä½¿ç”¨æŒ‡å—ã€‚\n","excerpt":"KubeClipper è®¿é—®æ§åˆ¶åŠŸèƒ½ä½¿ç”¨æŒ‡å—ã€‚\n","ref":"/docs/tutorials/access-control/","tags":"","title":"è®¿é—®æ§åˆ¶"},{"body":"Please check KubeClipper Community\n","categories":"","description":"How to contribute to the docs\n","excerpt":"How to contribute to the docs\n","ref":"/en/docs/contribution-guidelines/","tags":"","title":"Contribution Guidelines"},{"body":"è¯·æŸ¥çœ‹ KubeClipper Community\n","categories":"","description":"å¦‚ä½•ä¸º kubeclipper åšè´¡çŒ®\n","excerpt":"å¦‚ä½•ä¸º kubeclipper åšè´¡çŒ®\n","ref":"/docs/contribution-guidelines/","tags":"","title":"è´¡çŒ®æŒ‡å—"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/docs/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"æ–‡æ¡£"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/blog/news/","tags":"","title":"News About Docsy"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/blog/releases/","tags":"","title":"New Releases"},{"body":" Welcome to Kubeclipper! Learn More Download Manage Kubernetes in the most light and simple way !\nKubeClipper is a lightweight, simple graphical interface Kubernetes cluster lifecycle management platform.\nIt is fully compatible with kubernetes, allows users to quickly deploy the kubernetes clusters required by the enterprise on customer-managed infrastructures through a friendly wizard-like Web UI, and provides continuous full life cycle management capabilities.\nSimple Provides friendly wizard graphical interface, allows beginners to quickly deploy a cluster and the required plug-ins.\nLightweight Simple architecture, few dependencies, only two command lines for platform deployment.\nProfessional Simple and professional, it supports rich cluster parameter configuration and plug-in management, meeting production-level cluster deployment requirements.\nQuick Start 1. Download kcctl 2. Deploy KubeClipper curl -sfL https://oss.kubeclipper.io/kcctl.sh | sh - # In China, you can add cn env, we use registry.aliyuncs.com/google_containers instead of k8s.gcr.io curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn sh - kcctl deploy [--user root] (--passwd SSH_PASSWD | --pk-file SSH_PRIVATE_KEY) ","categories":"","description":"","excerpt":" Welcome to Kubeclipper! Learn More Download Manage Kubernetes in the most light and simple way !\nKubeClipper is a lightweight, simple graphical interface Kubernetes cluster lifecycle management â€¦","ref":"/en/","tags":"","title":"Kubeclipper"},{"body":" æ¬¢è¿æ¥åˆ° Kubeclipper ! äº†è§£æ›´å¤š å…è´¹ä¸‹è½½ ç”¨æœ€ç®€å•çš„æ–¹å¼ç®¡ç† Kubernetes !\nKubeClipper æ˜¯ä¸€ä¸ªè½»é‡çº§ã€æ˜“ç”¨çš„å›¾å½¢ç•Œé¢ Kubernetes é›†ç¾¤ç”Ÿå‘½å‘¨æœŸç®¡ç†å¹³å°ã€‚\nå®ƒä¸ kubernetes å®Œå…¨å…¼å®¹ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡å‹å¥½çš„å‘å¯¼å¼ Web UIï¼Œåœ¨å®¢æˆ·ç®¡ç†çš„åŸºç¡€æ¶æ„ä¸Šå¿«é€Ÿéƒ¨ç½²ä¼ä¸šæ‰€éœ€çš„ kubernetes é›†ç¾¤ï¼Œå¹¶æä¾›æŒç»­çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†èƒ½åŠ›ã€‚\næ˜“ä½¿ç”¨ å‹å¥½çš„å‘å¯¼å¼å›¾å½¢åŒ–ç•Œé¢ï¼Œåˆå­¦è€…ä¹Ÿå¯ä»¥å¿«é€Ÿéƒ¨ç½²ä¸€ä¸ªç”Ÿäº§çº§é›†ç¾¤å¹¶å®‰è£…æ‰€éœ€æ’ä»¶ã€‚\næè½»é‡ æ¶æ„ç®€å•ï¼Œå°‘ä¾èµ–ï¼Œå¹³å°éƒ¨ç½²ä»…éœ€ä¸¤ä¸ªå‘½ä»¤è¡Œã€‚\nç”Ÿäº§çº§ æ˜“ç”¨æ€§å’Œä¸“ä¸šæ€§å…¼é¡¾ï¼Œæ”¯æŒä¸°å¯Œçš„é›†ç¾¤å‚æ•°é…ç½®å’Œæ’ä»¶ç®¡ç†ï¼Œæ»¡è¶³ç”Ÿäº§çº§é›†ç¾¤éƒ¨ç½²éœ€æ±‚ã€‚\nç«‹å³ä½“éªŒ 1. ä¸‹è½½ kcctl 2. éƒ¨ç½² KubeClipper curl -sfL https://oss.kubeclipper.io/kcctl.sh | sh - # In China, you can add cn env, we use registry.aliyuncs.com/google_containers instead of k8s.gcr.io curl -sfL https://oss.kubeclipper.io/kcctl.sh | KC_REGION=cn sh - kcctl deploy [--user root] (--passwd SSH_PASSWD | --pk-file SSH_PRIVATE_KEY) ","categories":"","description":"","excerpt":" æ¬¢è¿æ¥åˆ° Kubeclipper ! äº†è§£æ›´å¤š å…è´¹ä¸‹è½½ ç”¨æœ€ç®€å•çš„æ–¹å¼ç®¡ç† Kubernetes !\nKubeClipper æ˜¯ä¸€ä¸ªè½»é‡çº§ã€æ˜“ç”¨çš„å›¾å½¢ç•Œé¢ Kubernetes é›†ç¾¤ç”Ÿå‘½å‘¨æœŸç®¡ç†å¹³å°ã€‚\nå®ƒä¸ kubernetes å®Œå…¨å…¼å®¹ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡å‹å¥½çš„å‘å¯¼å¼ Web UIï¼Œåœ¨å®¢æˆ·ç®¡ç†çš„åŸºç¡€æ¶æ„ä¸Šå¿«é€Ÿéƒ¨ç½²ä¼ä¸šæ‰€éœ€çš„ kubernetes é›†ç¾¤ï¼Œå¹¶æä¾›æŒç»­çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†èƒ½åŠ›ã€‚\næ˜“ä½¿ç”¨ å‹å¥½ â€¦","ref":"/","tags":"","title":"Kubeclipper"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/cluster/","tags":"","title":"cluster"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/create/","tags":"","title":"create"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/faq/","tags":"","title":"FAQ"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/kcctl/","tags":"","title":"kcctl"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/tags/aio/","tags":"","title":"aio"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/aio/","tags":"","title":"aio"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/tags/docs/","tags":"","title":"docs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/docs/","tags":"","title":"docs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/categories/quickstart/","tags":"","title":"QuickStart"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/quickstart/","tags":"","title":"QuickStart"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/tags/sample/","tags":"","title":"sample"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/sample/","tags":"","title":"sample"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/tags/","tags":"","title":"Tags"},{"body":"This is a typical blog post that includes images.\nThe front matter specifies the date of the blog post, its title, a short description that will be displayed on the blog landing page, and its author.\nIncluding images Hereâ€™s an image (featured-sunset-get.png) that includes a byline and a caption.\nFetch and scale an image in the upcoming Hugo 0.43. Photo: Riona MacNamara / CC-BY-CA\nThe front matter of this post specifies properties to be assigned to all image resources:\nresources: - src: \"**.{png,jpg}\" title: \"Image #:counter\" params: byline: \"Photo: Riona MacNamara / CC-BY-CA\" To include the image in a page, specify its details like this:\nFetch and scale an image in the upcoming Hugo 0.43. Photo: Riona MacNamara / CC-BY-CA\nThe image will be rendered at the size and byline specified in the front matter.\n","categories":"","description":"The Docsy Hugo theme lets project maintainers and contributors focus on content, not on reinventing a website infrastructure from scratch","excerpt":"The Docsy Hugo theme lets project maintainers and contributors focus on content, not on reinventing a website infrastructure from scratch","ref":"/en/blog/2018/10/06/easy-documentation-with-docsy/","tags":"","title":"Easy documentation with Docsy"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","ref":"/en/blog/","tags":"","title":"Docsy Blog"},{"body":"Text can be bold, italic, or strikethrough. Links should be blue with no underlines (unless hovered over).\nThere should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs.\nThere should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs.\nThere should be no margin above this first sentence.\nBlockquotes should be a lighter gray with a border along the left side in the secondary color.\nThere should be no margin below this final sentence.\nFirst Header This is a normal paragraph following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nBacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nOn big screens, paragraphs and headings should not take up the full container width, but we want tables, code blocks and similar to take the full width.\nLorem markdownum tuta hospes stabat; idem saxum facit quaterque repetito occumbere, oves novem gestit haerebat frena; qui. Respicit recurvam erat: pignora hinc reppulit nos aut, aptos, ipsa.\nMeae optatos passa est Epiros utiliter Talibus niveis, hoc lata, edidit. Dixi ad aestum.\nHeader 2 This is a blockquote following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nHeader 3 This is a code block following a header. Header 4 This is an unordered list following a header. This is an unordered list following a header. This is an unordered list following a header. Header 5 This is an ordered list following a header. This is an ordered list following a header. This is an ordered list following a header. Header 6 What Follows A table A header A table A header A table A header Thereâ€™s a horizontal rule above and below this.\nHere is an unordered list:\nSalt-n-Pepa Bel Biv DeVoe Kid â€˜N Play And an ordered list:\nMichael Jackson Michael Bolton Michael BublÃ© And an unordered task list:\nCreate a sample markdown document Add task lists to it Take a vacation And a â€œmixedâ€ task list:\nSteal underpants ? Profit! And a nested list:\nJackson 5 Michael Tito Jackie Marlon Jermaine TMNT Leonardo Michelangelo Donatello Raphael Definition lists can be used with Markdown syntax. Definition terms are bold.\nName Godzilla Born 1952 Birthplace Japan Color Green Tables should have bold headings and alternating shaded rows.\nArtist Album Year Michael Jackson Thriller 1982 Prince Purple Rain 1984 Beastie Boys License to Ill 1986 If a table is too wide, it should scroll horizontally.\nArtist Album Year Label Awards Songs Michael Jackson Thriller 1982 Epic Records Grammy Award for Album of the Year, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R\u0026B Album, Brit Award for Best Selling Album, Grammy Award for Best Engineered Album, Non-Classical Wanna Be Startinâ€™ Somethinâ€™, Baby Be Mine, The Girl Is Mine, Thriller, Beat It, Billie Jean, Human Nature, P.Y.T. (Pretty Young Thing), The Lady in My Life Prince Purple Rain 1984 Warner Brothers Records Grammy Award for Best Score Soundtrack for Visual Media, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R\u0026B Album, Brit Award for Best Soundtrack/Cast Recording, Grammy Award for Best Rock Performance by a Duo or Group with Vocal Letâ€™s Go Crazy, Take Me With U, The Beautiful Ones, Computer Blue, Darling Nikki, When Doves Cry, I Would Die 4 U, Baby Iâ€™m a Star, Purple Rain Beastie Boys License to Ill 1986 Mercury Records noawardsbutthistablecelliswide Rhymin \u0026 Stealin, The New Style, Sheâ€™s Crafty, Posse in Effect, Slow Ride, Girls, (You Gotta) Fight for Your Right, No Sleep Till Brooklyn, Paul Revere, Hold It Now, Hit It, Brass Monkey, Slow and Low, Time to Get Ill Code snippets like var foo = \"bar\"; can be shown inline.\nAlso, this should vertically align with this and this.\nCode can also be shown in a block element.\nfoo := \"bar\"; bar := \"foo\"; Code can also use syntax highlighting.\nfunc main() { input := `var foo = \"bar\";` lexer := lexers.Get(\"javascript\") iterator, _ := lexer.Tokenise(nil, input) style := styles.Get(\"github\") formatter := html.New(html.WithLineNumbers()) var buff bytes.Buffer formatter.Format(\u0026buff, style, iterator) fmt.Println(buff.String()) } Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this. Inline code inside table cells should still be distinguishable.\nLanguage Code Javascript var foo = \"bar\"; Ruby foo = \"bar\"{ Small images should be shown at their actual size.\nLarge images should always scale down and fit in the content container.\nComponents Alerts This is an alert. Note: This is an alert with a title. This is a successful alert. This is a warning! Warning! This is a warning with a title! Sizing Add some sections here to see how the ToC looks like. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nParameters available Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsing pixels Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsing rem Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nMemory Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nRAM to use Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nMore is better Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsed RAM Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nThis is the final element on the page and there should be no margin below this. ","categories":"","description":"A short lead description about this content page. Text here can also be **bold** or _italic_ and can even be split over multiple paragraphs.\n","excerpt":"A short lead description about this content page. Text here can also be **bold** or _italic_ and can even be split over multiple paragraphs.\n","ref":"/en/blog/2018/10/06/the-second-blog-post/","tags":"","title":"The second blog post"},{"body":"Text can be bold, italic, or strikethrough. Links should be blue with no underlines (unless hovered over).\nThere should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs.\nThere should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs.\nThere should be no margin above this first sentence.\nBlockquotes should be a lighter gray with a border along the left side in the secondary color.\nThere should be no margin below this final sentence.\nFirst Header This is a normal paragraph following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nBacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nOn big screens, paragraphs and headings should not take up the full container width, but we want tables, code blocks and similar to take the full width.\nLorem markdownum tuta hospes stabat; idem saxum facit quaterque repetito occumbere, oves novem gestit haerebat frena; qui. Respicit recurvam erat: pignora hinc reppulit nos aut, aptos, ipsa.\nMeae optatos passa est Epiros utiliter Talibus niveis, hoc lata, edidit. Dixi ad aestum.\nHeader 2 This is a blockquote following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nHeader 3 This is a code block following a header. Header 4 This is an unordered list following a header. This is an unordered list following a header. This is an unordered list following a header. Header 5 This is an ordered list following a header. This is an ordered list following a header. This is an ordered list following a header. Header 6 What Follows A table A header A table A header A table A header Thereâ€™s a horizontal rule above and below this.\nHere is an unordered list:\nSalt-n-Pepa Bel Biv DeVoe Kid â€˜N Play And an ordered list:\nMichael Jackson Michael Bolton Michael BublÃ© And an unordered task list:\nCreate a sample markdown document Add task lists to it Take a vacation And a â€œmixedâ€ task list:\nSteal underpants ? Profit! And a nested list:\nJackson 5 Michael Tito Jackie Marlon Jermaine TMNT Leonardo Michelangelo Donatello Raphael Definition lists can be used with Markdown syntax. Definition terms are bold.\nName Godzilla Born 1952 Birthplace Japan Color Green Tables should have bold headings and alternating shaded rows.\nArtist Album Year Michael Jackson Thriller 1982 Prince Purple Rain 1984 Beastie Boys License to Ill 1986 If a table is too wide, it should scroll horizontally.\nArtist Album Year Label Awards Songs Michael Jackson Thriller 1982 Epic Records Grammy Award for Album of the Year, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R\u0026B Album, Brit Award for Best Selling Album, Grammy Award for Best Engineered Album, Non-Classical Wanna Be Startinâ€™ Somethinâ€™, Baby Be Mine, The Girl Is Mine, Thriller, Beat It, Billie Jean, Human Nature, P.Y.T. (Pretty Young Thing), The Lady in My Life Prince Purple Rain 1984 Warner Brothers Records Grammy Award for Best Score Soundtrack for Visual Media, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R\u0026B Album, Brit Award for Best Soundtrack/Cast Recording, Grammy Award for Best Rock Performance by a Duo or Group with Vocal Letâ€™s Go Crazy, Take Me With U, The Beautiful Ones, Computer Blue, Darling Nikki, When Doves Cry, I Would Die 4 U, Baby Iâ€™m a Star, Purple Rain Beastie Boys License to Ill 1986 Mercury Records noawardsbutthistablecelliswide Rhymin \u0026 Stealin, The New Style, Sheâ€™s Crafty, Posse in Effect, Slow Ride, Girls, (You Gotta) Fight for Your Right, No Sleep Till Brooklyn, Paul Revere, Hold It Now, Hit It, Brass Monkey, Slow and Low, Time to Get Ill Code snippets like var foo = \"bar\"; can be shown inline.\nAlso, this should vertically align with this and this.\nCode can also be shown in a block element.\nfoo := \"bar\"; bar := \"foo\"; Code can also use syntax highlighting.\nfunc main() { input := `var foo = \"bar\";` lexer := lexers.Get(\"javascript\") iterator, _ := lexer.Tokenise(nil, input) style := styles.Get(\"github\") formatter := html.New(html.WithLineNumbers()) var buff bytes.Buffer formatter.Format(\u0026buff, style, iterator) fmt.Println(buff.String()) } Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this. Inline code inside table cells should still be distinguishable.\nLanguage Code Javascript var foo = \"bar\"; Ruby foo = \"bar\"{ Small images should be shown at their actual size.\nLarge images should always scale down and fit in the content container.\nComponents Alerts This is an alert. Note: This is an alert with a title. This is a successful alert. This is a warning! Warning! This is a warning with a title! Sizing Add some sections here to see how the ToC looks like. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nParameters available Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsing pixels Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsing rem Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nMemory Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nRAM to use Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nMore is better Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsed RAM Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nThis is the final element on the page and there should be no margin below this. ","categories":"","description":"A short lead description about this content page. Text here can also be **bold** or _italic_ and can even be split over multiple paragraphs.\n","excerpt":"A short lead description about this content page. Text here can also be **bold** or _italic_ and can even be split over multiple paragraphs.\n","ref":"/en/blog/2018/01/04/another-great-release/","tags":"","title":"Another Great Release"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/en/community/","tags":"","title":"Community"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/categories/examples/","tags":"","title":"Examples"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/categories/placeholders/","tags":"","title":"Placeholders"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/en/tags/test/","tags":"","title":"test"},{"body":"Comming soonâ€¦\n","categories":"","description":"","excerpt":"Comming soonâ€¦\n","ref":"/blog/","tags":"","title":"KubeClipper Blog"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/community/","tags":"","title":"ç¤¾åŒº"}]